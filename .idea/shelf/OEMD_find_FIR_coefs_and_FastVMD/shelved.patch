Index: SVRRoot/OnlineSVR/src/online_emd.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#include \"online_emd.hpp\"\n#include \"util/StringUtils.hpp\"\n#include \"util/math_utils.hpp\"\n#include \"common/gpu_handler.h\"\n#include \"oemd_coefficients_search.hpp\"\n#include \"online_emd_impl.cuh\"\n\n#include <fftw3.h>\n#include <algorithm>\n#include <iostream>\n#include <sstream>\n#include <cmath>\n\n\nnamespace svr {\n\nstatic const size_t fir_search_start_size = 500;\nstatic const size_t fir_search_end_size = 20000;\nstatic const size_t fir_search_window_start = 0; // 10000000; // Set to 0 if tail is presented trimmed\nstatic const size_t fir_search_window_end = fir_search_window_start + fir_search_end_size * 20;\n\n\nvoid online_emd::find_fir_coefficients(const std::vector<double> &input)\n{\n    const auto oemd_levels = oemd_available_levels.find(levels);\n    if (oemd_levels == oemd_available_levels.end())\n        THROW_EX_FS(std::runtime_error, \"Inappropriate number chosen for level parameter \" << levels);\n    svr::oemd_search::oemd_coefs_search(\n            input, fir_search_start_size, fir_search_end_size, fir_search_window_start,\n            std::min(input.size(), fir_search_window_end), levels, p_oemd_coef->mask, p_oemd_coef->siftings);\n}\n\n\nvoid online_emd::init_oemd()\n{\n#ifdef OEMD_CUDA\n    return;\n#endif\n    if (p_oemd_coef) {\n        LOG4_TRACE(\"Filter coefficients already initialized.\");\n        return;\n    }\n    const auto oemd_levels = oemd_available_levels.find(levels);\n    if (oemd_levels == oemd_available_levels.end())\n        THROW_EX_FS(std::runtime_error, \"Inappropriate number chosen for level parameter \" << levels);\n\n    const double stretch_ratio =  1. / stretch_coef;\n    LOG4_DEBUG (\"Initializing OEMD coefficients.\");\n    p_oemd_coef = std::make_shared<oemd_coefficients>(oemd_levels->second);\n    PFORi(0, p_oemd_coef->mask.size(), // TODO Different compute in case of stretch coef < 1\n        std::vector<double> stretch_mask(p_oemd_coef->mask[i].size() * stretch_coef, 0.);\n        for (size_t t = 0; t < stretch_mask.size(); ++t)\n            stretch_mask[t] = p_oemd_coef->mask[i][t * stretch_ratio] * stretch_ratio;\n        p_oemd_coef->mask[i] = stretch_mask;\n    )\n}\n\nonline_emd::online_emd(const size_t _levels, const double _stretch_coef)\n        : spectral_transform(std::string(\"oemd\"), _levels), levels(_levels), stretch_coef(_stretch_coef)\n{\n    const auto oemd_levels = oemd_available_levels.find(levels);\n    if (oemd_levels == oemd_available_levels.end())\n        THROW_EX_FS(std::runtime_error, \"Inappropriate number chosen for level parameter \" << levels);\n}\n\n\n#ifndef OEMD_CUDA\n\nstatic void\noemd_mean_compute(\n        const std::vector<double> &x,\n        const std::vector<double> &mask,\n        std::vector<double> &rx)\n{\n    printf(\"pre %lu:%f:%f\\n\", 100ul, x[100], rx[100]);\n    printf(\"pre %lu:%f:%f\\n\", 1000ul, x[1000], rx[1000]);\n    cilk_for (size_t t = mask.size() - 1; t < x.size(); ++t) {\n        rx[t] = 0;\n        for (size_t m = 0; m < mask.size(); ++m) {\n            rx[t] += mask[m] * x[t - mask.size() + m + 1];\n        }\n    }\n\n#ifdef OEMD_TAIL_COMPUTE\n    const size_t lim = mask.size() - 1 < x.size() ? mask.size() - 1 : x.size();\n    cilk_for (size_t t = 0; t < lim; ++t) {\n        rx[t] = 0;\n        double sum = 0;\n        for (size_t j = 0; j <= t; j++) {\n            rx[t] += mask[mask.size() - 1 - t + j] * x[j];\n            sum += mask[mask.size() - 1 - t + j];\n        }\n        rx[t] = rx[t] / sum;\n    }\n    printf(\"post %lu:%f:%f\\n\", 100ul, x[100], rx[100]);\n    printf(\"post %lu:%f:%f\\n\", 1000ul, x[1000], rx[1000]);\n    fflush(stdout);\n    fflush(stderr);\n#endif\n}\n\n#endif\n\n\n#if 0\nstatic int\noemd_fast_mean_compute(const std::vector<double> &x, const double *mask, int mask_size, std::vector<double> &rx)\n{\n    int len = x.size();\n    fftw_plan forward_plan;\n    fftw_plan backward_plan;\n    fftw_complex *output = (fftw_complex *) fftw_malloc(sizeof(fftw_complex) * (len / 2 + 1));\n    fftw_complex *mult = (fftw_complex *) fftw_malloc(sizeof(fftw_complex) * (len / 2 + 1));\n    forward_plan = fftw_plan_dft_r2c_1d(len, &rx[0], output, FFTW_ESTIMATE);\n    backward_plan = fftw_plan_dft_c2r_1d(len, output, &rx[0], FFTW_ESTIMATE);\n    for (int i = 0; i < len; i++) {\n        rx[i] = i < mask_size ? mask[mask_size - 1 - i] : 0.;\n    }\n    fftw_execute(forward_plan);\n    for (int i = 0; i < len / 2 + 1; i++) {\n        mult[i][0] = output[i][0];\n        mult[i][1] = output[i][1];\n    }\n    for (int i = 0; i < len; i++) {\n        rx[i] = x[i];\n    }\n    fftw_execute(forward_plan);\n    for (int i = 0; i < len / 2 + 1; i++) {\n        double o_real = output[i][0] * mult[i][0] - output[i][1] * mult[i][1];\n        double o_imag = output[i][0] * mult[i][1] + output[i][1] * mult[i][0];\n        output[i][0] = o_real;\n        output[i][1] = o_imag;\n    }\n    fftw_execute(backward_plan);\n    for (int i = 0; i < mask_size - 1; i++) {\n        rx[i] = 0.;\n        double sum = 0.;\n        for (int j = 0; j <= i; j++) {\n            rx[i] += mask[mask_size - 1 - i + j] * x[j];\n            sum += mask[mask_size - 1 - i + j];\n        }\n        rx[i] = rx[i] / sum;\n    }\n    for (int i = mask_size - 1; i < len; i++) {\n        rx[i] = rx[i] / len;\n    }\n    fftw_free(output);\n    fftw_free(mult);\n    fftw_destroy_plan(forward_plan);\n    fftw_destroy_plan(backward_plan);\n    return 0;\n}\n\noemd_fptr online_emd::select_method(size_t level, size_t input_length) const\n{\n    return &oemd_mean_compute;\n    /*\n    if (level < 2) {\n        return &oemd_mean_compute;\n    } else {\n        if (input_length < p_oemd_coef->mask[level].size()){\n            return &oemd_mean_compute;\n        }else{\n            return &oemd_fast_mean_compute;\n        }\n    }\n\t*/\n}\n#endif\n\n\nvoid\nonline_emd::transform(\n        const std::vector<double> &input,\n        std::vector<std::vector<double>> &decon,\n        const size_t padding = 0)\n{\n#ifdef OEMD_CUDA\n    if (input.size() < get_residuals_length())\n        LOG4_ERROR(\"Input size \" << input.size() << \" too short, needed \" << get_residuals_length());\n    else\n        LOG4_DEBUG(\"Input size \" << input.size());\n    const auto oemd_levels = oemd_available_levels.find(levels);\n    if (oemd_levels == oemd_available_levels.end())\n        THROW_EX_FS(std::runtime_error, \"Inappropriate number chosen for level parameter \" << levels);\n\n#ifdef CUDA_OEMD_MULTIGPU\n    std::vector<std::shared_ptr<common::gpu_context>> gpu_ctxs;\n    std::vector<int> gpu_ids;\n    const auto free_gpus_ct = common::gpu_handler::get_instance().get_free_gpus();\n    for (size_t i = 0; i < free_gpus_ct; ++i) {\n        auto p_ctx = std::make_shared<common::gpu_context>();\n        gpu_ctxs.push_back(p_ctx);\n        gpu_ids.push_back(p_ctx->id());\n    }\n#endif\n\n    common::gpu_context ctx;\n    svr::cuoemd::transform(\n            input, decon,\n#ifdef CUDA_OEMD_MULTIGPU\n            gpu_ids,\n#else\n            ctx.id(),\n#endif\n            oemd_levels->second.siftings,\n            oemd_levels->second.mask,\n            stretch_coef,\n            levels);\n#else\n    init_oemd();\n\n    size_t input_length = input.size();\n    LOG4_TRACE(\"Size of input is \" << input_length);\n    std::vector<double> remainder = input;\n    std::vector<double> rx = remainder;\n    std::vector<double> rx2(input_length, 0.);\n    if (decon.size() != input_length) decon.resize(input_length);\n    for (size_t l = 0; l < levels - 1; l++) {\n        //oemd_fptr mean_compute = select_method(l, input_length);\n        for (size_t j = 0; j < p_oemd_coef->siftings[l]; ++j) {\n            oemd_mean_compute(rx, p_oemd_coef->mask[l], rx2);\n            for (size_t t = 0; t < input_length; ++t) {\n                rx[t] -= rx2[t];\n            }\n        }\n        cilk_for (size_t t = 0; t < input_length; ++t) {\n            if (decon[t].size() != levels) decon[t].resize(levels, 0.);\n            //result[k][l+1] = rx[k];\n            decon[t][levels - l - 1] = rx[t];\n            remainder[t] -= rx[t];\n            rx[t] = remainder[t];\n        }\n    }\n    for (size_t t = 0; t < input_length; ++t) {\n        decon[t][0] = rx[t];\n    }\n\n#if 0 // Debugging\n    {\n        std::stringstream ss;\n        for (size_t i = 0; i < decon.size(); ++i) {\n            for (size_t j = 0; j < decon[i].size(); ++j)\n                ss << \", \" << decon[i][j];\n            ss << std::endl;\n        }\n        LOG4_FILE(\"oemd_decon.txt\", ss.str().c_str());\n        exit(0);\n    }\n#endif\n#endif\n}\n\n\nvoid online_emd::inverse_transform(\n        const std::vector<double> &decon,\n        std::vector<double> &recon,\n        const size_t padding = 0) const\n{\n    const size_t input_size = decon.size() / levels;\n    recon = std::vector<double>(input_size, 0.);\n\n    //by rows  --> decon_column_values[row_index + level_ix * frame_size]\n    PFORi(0, input_size,\n        double recon_i = 0;\n        for (size_t j = 0; j < levels; ++j)\n            recon_i += decon[i + j * input_size];\n        recon[i] = recon_i;\n    )\n}\n\n\nsize_t online_emd::get_residuals_length(const oemd_coefficients &coefs, const double stretch_coef)\n{\n    //return coefs.mask.back().size(); // Minimum\n    //return coefs.mask.back().size() * p_oemd_coef->siftings.back(); // Tradeoff\n    //return 6 * svr::common::next_power_of_two(coefs.mask.back().size() * coefs.siftings.back()); // Assured time invariance first\n    return common::max_size(coefs.mask) * stretch_coef * common::max(coefs.siftings) * 7; /* time invariance 1: * oemd_level_coefs->second.siftings.back() * 7 */ //\n}\n\n\nsize_t online_emd::get_residuals_length(const size_t levels)\n{\n    LOG4_ERROR(\"Getting flat residuals length!\");\n    const auto oemd_level_coefs = oemd_available_levels.find(levels);\n    if (levels < 2 or oemd_level_coefs == oemd_available_levels.end())\n        LOG4_THROW(\"Unsupported number of levels \" << levels << \" requested for OEMD.\");\n    return get_residuals_length(oemd_level_coefs->second);\n}\n\n\nsize_t online_emd::get_residuals_length()\n{\n#ifdef OEMD_CUDA\n    const auto oemd_level_coefs = oemd_available_levels.find(levels);\n    if (levels < 2 or oemd_level_coefs == oemd_available_levels.end())\n        LOG4_THROW(\"Unsupported number of levels \" << levels << \" requested for OEMD decomposition.\");\n    return get_residuals_length(oemd_level_coefs->second, stretch_coef);\n#else\n    if (!p_oemd_coef) init_oemd();\n    return p_oemd_coef->mask.back().size();\n#endif\n}\n\n\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- SVRRoot/OnlineSVR/src/online_emd.cpp	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ SVRRoot/OnlineSVR/src/online_emd.cpp	(date 1672583484456)
@@ -10,32 +10,31 @@
 #include <iostream>
 #include <sstream>
 #include <cmath>
+#include <appcontext.hpp>
 
 
 namespace svr {
 
 static const size_t fir_search_start_size = 500;
 static const size_t fir_search_end_size = 20000;
-static const size_t fir_search_window_start = 0; // 10000000; // Set to 0 if tail is presented trimmed
+static const size_t fir_search_window_start = 0; // 10000000; // Tail size, set to 0 if tail is presented trimmed
 static const size_t fir_search_window_end = fir_search_window_start + fir_search_end_size * 20;
 
 
-void online_emd::find_fir_coefficients(const std::vector<double> &input)
+void online_emd::find_fir_coefficients(const std::vector<double> &input, const size_t use_last_n_samples)
 {
     const auto oemd_levels = oemd_available_levels.find(levels);
     if (oemd_levels == oemd_available_levels.end())
         THROW_EX_FS(std::runtime_error, "Inappropriate number chosen for level parameter " << levels);
+
     svr::oemd_search::oemd_coefs_search(
-            input, fir_search_start_size, fir_search_end_size, fir_search_window_start,
-            std::min(input.size(), fir_search_window_end), levels, p_oemd_coef->mask, p_oemd_coef->siftings);
+            {input.begin() + input.size() - use_last_n_samples, input.end()},
+            fir_search_start_size, fir_search_end_size, fir_search_window_start, std::min(input.size(), fir_search_window_end), levels, p_oemd_coef->mask, p_oemd_coef->siftings);
 }
 
 
 void online_emd::init_oemd()
 {
-#ifdef OEMD_CUDA
-    return;
-#endif
     if (p_oemd_coef) {
         LOG4_TRACE("Filter coefficients already initialized.");
         return;
@@ -44,15 +43,8 @@
     if (oemd_levels == oemd_available_levels.end())
         THROW_EX_FS(std::runtime_error, "Inappropriate number chosen for level parameter " << levels);
 
-    const double stretch_ratio =  1. / stretch_coef;
     LOG4_DEBUG ("Initializing OEMD coefficients.");
     p_oemd_coef = std::make_shared<oemd_coefficients>(oemd_levels->second);
-    PFORi(0, p_oemd_coef->mask.size(), // TODO Different compute in case of stretch coef < 1
-        std::vector<double> stretch_mask(p_oemd_coef->mask[i].size() * stretch_coef, 0.);
-        for (size_t t = 0; t < stretch_mask.size(); ++t)
-            stretch_mask[t] = p_oemd_coef->mask[i][t * stretch_ratio] * stretch_ratio;
-        p_oemd_coef->mask[i] = stretch_mask;
-    )
 }
 
 online_emd::online_emd(const size_t _levels, const double _stretch_coef)
@@ -61,6 +53,8 @@
     const auto oemd_levels = oemd_available_levels.find(levels);
     if (oemd_levels == oemd_available_levels.end())
         THROW_EX_FS(std::runtime_error, "Inappropriate number chosen for level parameter " << levels);
+    init_oemd();
+    fir_coefs_initialized = !PROPS.get_oemd_find_fir_coefficients();
 }
 
 
@@ -180,9 +174,6 @@
         LOG4_ERROR("Input size " << input.size() << " too short, needed " << get_residuals_length());
     else
         LOG4_DEBUG("Input size " << input.size());
-    const auto oemd_levels = oemd_available_levels.find(levels);
-    if (oemd_levels == oemd_available_levels.end())
-        THROW_EX_FS(std::runtime_error, "Inappropriate number chosen for level parameter " << levels);
 
 #ifdef CUDA_OEMD_MULTIGPU
     std::vector<std::shared_ptr<common::gpu_context>> gpu_ctxs;
@@ -203,8 +194,8 @@
 #else
             ctx.id(),
 #endif
-            oemd_levels->second.siftings,
-            oemd_levels->second.mask,
+            p_oemd_coef->siftings,
+            p_oemd_coef->mask,
             stretch_coef,
             levels);
 #else
@@ -263,8 +254,7 @@
     //by rows  --> decon_column_values[row_index + level_ix * frame_size]
     PFORi(0, input_size,
         double recon_i = 0;
-        for (size_t j = 0; j < levels; ++j)
-            recon_i += decon[i + j * input_size];
+        for (size_t j = 0; j < levels; ++j) recon_i += decon[i + j * input_size];
         recon[i] = recon_i;
     )
 }
@@ -281,7 +271,7 @@
 
 size_t online_emd::get_residuals_length(const size_t levels)
 {
-    LOG4_ERROR("Getting flat residuals length!");
+    LOG4_WARN("Getting default residuals length!");
     const auto oemd_level_coefs = oemd_available_levels.find(levels);
     if (levels < 2 or oemd_level_coefs == oemd_available_levels.end())
         LOG4_THROW("Unsupported number of levels " << levels << " requested for OEMD.");
@@ -292,10 +282,9 @@
 size_t online_emd::get_residuals_length()
 {
 #ifdef OEMD_CUDA
-    const auto oemd_level_coefs = oemd_available_levels.find(levels);
-    if (levels < 2 or oemd_level_coefs == oemd_available_levels.end())
+    if (levels < 2)
         LOG4_THROW("Unsupported number of levels " << levels << " requested for OEMD decomposition.");
-    return get_residuals_length(oemd_level_coefs->second, stretch_coef);
+    return get_residuals_length(*p_oemd_coef, stretch_coef);
 #else
     if (!p_oemd_coef) init_oemd();
     return p_oemd_coef->mask.back().size();
Index: SVRRoot/OnlineSVR/include/online_emd.hpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#pragma once\n\n#include \"spectral_transform.hpp\"\n#include \"oemd_coefficients.hpp\"\n#include <unordered_map>\n\n#include <common/Logging.hpp>\n\n#define OEMD_TAIL_COMPUTE\n#define OEMD_CUDA\n\nnamespace svr {\n\nconst double oemd_epsilon = 0.0000011;\nconst double oemd_mask_sum = 1.00000;\n\nusing oemd_fptr =  void (*)(const std::vector<double> &, const std::vector<double> &, std::vector<double> &);\n\nclass online_emd : public spectral_transform\n{\n    void init_oemd();\n\npublic:\n    void find_fir_coefficients(const std::vector<double> &input);\n\n    explicit online_emd(const size_t levels, const double stretch_coef = 1);\n\n    virtual ~online_emd() final\n    {}\n\n    virtual void transform(const std::vector<double> &input, std::vector<std::vector<double> > &decon,\n                           const size_t padding /* = 0 */) override;\n\n    virtual void inverse_transform(const std::vector<double> &decon, std::vector<double> &recon,\n                                   const size_t padding /* = 0 */) const override;\n\n    static size_t get_residuals_length(const oemd_coefficients &coefs, const double stretch_coef = 1);\n    static size_t get_residuals_length(const size_t levels);\n    size_t get_residuals_length();\n\n    static size_t get_frame_size(const size_t transformation_levels, const size_t max_lag_count = 1)\n    {\n        return 1;\n    }\n\n    //oemd_fptr select_method(size_t level, size_t input_length) const;\nprivate:\n    const size_t levels;\n    const double stretch_coef;\n    std::shared_ptr<oemd_coefficients> p_oemd_coef;\n};\n\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- SVRRoot/OnlineSVR/include/online_emd.hpp	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ SVRRoot/OnlineSVR/include/online_emd.hpp	(date 1672580133156)
@@ -19,9 +19,12 @@
 class online_emd : public spectral_transform
 {
     void init_oemd();
+    bool fir_coefs_initialized = false;
 
 public:
-    void find_fir_coefficients(const std::vector<double> &input);
+    bool get_fir_coefs_initialized() { return fir_coefs_initialized; }
+
+    void find_fir_coefficients(const std::vector<double> &input, const size_t use_last_n_samples);
 
     explicit online_emd(const size_t levels, const double stretch_coef = 1);
 
Index: SVRRoot/SVRBusiness/include/DeconQueueService.hpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#pragma once\n\n#include <memory>\n#include <vector>\n#include <model/DataRow.hpp>\n#include <model/vektor.h>\n#include <cvmd.hpp>\n\n\nnamespace svr { namespace dao { class DeconQueueDAO; }}\n\nnamespace svr {\nnamespace datamodel {\nclass DeconQueue;\n\nclass InputQueue;\n\nclass Dataset;\n}\n}\nusing DeconQueue_ptr = std::shared_ptr<svr::datamodel::DeconQueue>;\nusing InputQueue_ptr = std::shared_ptr<svr::datamodel::InputQueue>;\nusing Dataset_ptr = std::shared_ptr<svr::datamodel::Dataset>;\n\nnamespace svr { namespace business { class InputQueueService; }}\n\nnamespace svr {\nnamespace business {\n\nclass DeconQueueService\n{\n    svr::dao::DeconQueueDAO &decon_queue_dao;\n    svr::business::InputQueueService &input_queue_service;\n\npublic:\n    DeconQueueService(svr::dao::DeconQueueDAO &deconQueueDao,\n                      svr::business::InputQueueService &input_queue_service)\n            :\n            decon_queue_dao(deconQueueDao),\n            input_queue_service(input_queue_service)\n    {}\n\n    DeconQueue_ptr get_by_table_name(const std::string &table_name);\n\n    DeconQueue_ptr get_queue_metadata(const std::string &table_name);\n\n    size_t load_latest_decon_data(const DeconQueue_ptr &p_decon_queue, const bpt::ptime &time_to, size_t limit);\n\n    size_t load_decon_data(\n            const DeconQueue_ptr &decon_queue, const bpt::ptime &time_from = bpt::min_date_time,\n            const bpt::ptime &time_to = bpt::max_date_time, const size_t limit = 0);\n\n    static std::vector<DeconQueue_ptr>\n    extract_data(const Dataset_ptr &p_dataset, const boost::posix_time::time_period &period);\n\n    void save(const DeconQueue_ptr &p_decon_queue, const boost::posix_time::ptime &start_time = boost::posix_time::min_date_time);\n\n    bool exists(const DeconQueue_ptr &p_decon_queue);\n\n    bool exists(const std::string &decon_queue_table_name);\n\n    int remove(const DeconQueue_ptr &p_decon_queue);\n\n    int clear(const DeconQueue_ptr &p_decon_queue);\n\n    long count(const DeconQueue_ptr &decon_queue);\n\n    static DeconQueue_ptr &\n    find_decon_queue(\n            std::vector<DeconQueue_ptr> &decon_queues,\n            const std::string &input_queue_table_name,\n            const std::string &input_queue_column_name);\n\n    static const DeconQueue_ptr &\n    find_decon_queue(\n            const std::vector<DeconQueue_ptr> &decon_queues,\n            const std::string &input_queue_table_name,\n            const std::string &input_queue_column_name);\n\n    std::vector<DeconQueue_ptr>\n    deconstruct(\n            const InputQueue_ptr &p_input_queue,\n            const Dataset_ptr &p_dataset,\n            const bool get_data_from_database = false);\n\n    DeconQueue_ptr\n    deconstruct(\n            const InputQueue_ptr &p_input_queue,\n            const Dataset_ptr &p_dataset,\n            const std::string &column_name,\n            const bool get_data_from_database = false);\n\n    void deconstruct(\n            const InputQueue_ptr &p_input_queue,\n            const Dataset_ptr &p_dataset,\n            const std::string &column_name,\n            svr::datamodel::DataRow::container &decon_out,\n            const bool get_data_from_database = true);\n\n    void deconstruct_ticks(\n            const InputQueue_ptr &p_input_queue,\n            const Dataset_ptr &p_dataset,\n            const std::string &column_name,\n            svr::datamodel::DataRow::container &decon_data);\n\n#if 0\n    void\n    deconstruct_batch(\n            const InputQueue_ptr &p_input_queue,\n            const Dataset_ptr &p_dataset,\n            const std::string &column_name,\n            svr::datamodel::DataRow::container &decon_data);\n#endif\n\n    static data_row_container\n    reconstruct(\n            const svr::datamodel::datarow_range &data,\n            const std::string &transformation_name,\n            const size_t n_decomposition_levels);\n\n    static void\n    reconstruct(\n            const svr::datamodel::datarow_range &decon_queue,\n            const std::string &transformation_name,\n            const size_t n_decomposition_levels,\n            data_row_container &output);\n\n    static std::vector<double>\n    get_actual_values(\n            const data_row_container &data,\n            const data_row_container::const_iterator &target_iter);\n\n    static const DeconQueue_ptr\n    decon_queue_delta(const DeconQueue_ptr &p_original_decon_queue,\n                      const bool leave_anchor);\n\n    static DeconQueue_ptr\n    decon_queue_undelta(const DeconQueue_ptr &p_delta_decon_queue);\n\nprivate:\n    static void\n    copy_decon_data_to_container(\n            datamodel::DataRow::container &decon_out,\n            const datamodel::DataRow::container &input_data,\n            std::vector<std::vector<double>> &decon,\n            std::vector<std::vector<double>> &phase_series,\n            const boost::posix_time::time_duration &resolution);\n\n    static void\n    copy_recon_frame_to_container(\n            const svr::datamodel::DataRow::container &decon_data,\n            const std::set<boost::posix_time::ptime> &times,\n            svr::datamodel::DataRow::container &recon_data,\n            const std::vector<double> &reconstructed_values,\n            size_t limit = std::numeric_limits<size_t>::max());\n\n    void\n    deconstruct_cvmd(const Dataset_ptr &p_dataset, const InputQueue_ptr &p_input_queue, const std::string &column_name,\n                     const std::vector<double> &column_values,\n                     std::vector<std::vector<double>> &raw_deconstructed_data,\n                     std::vector<std::vector<double>> &phase_series,\n                     const bool do_batch = false) const;\n\npublic: size_t test_start_cvmd_pos = 0;\n};\n\n} /* namespace business */\n} /* namespace svr */\n\nusing DeconQueueService_ptr = std::shared_ptr<svr::business::DeconQueueService>;\n\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- SVRRoot/SVRBusiness/include/DeconQueueService.hpp	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ SVRRoot/SVRBusiness/include/DeconQueueService.hpp	(date 1672558358291)
@@ -2,9 +2,10 @@
 
 #include <memory>
 #include <vector>
-#include <model/DataRow.hpp>
-#include <model/vektor.h>
-#include <cvmd.hpp>
+
+#include "model/DataRow.hpp"
+#include "model/vektor.h"
+#include "fast_cvmd.hpp"
 
 
 namespace svr { namespace dao { class DeconQueueDAO; }}
Index: SVRRoot/SVRModel/src/Dataset.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#include <model/Dataset.hpp>\n#include <OnlineSVR.h>\n\n#include \"appcontext.hpp\"\n\n#include <SVRParametersService.hpp>\n\n#include \"online_emd.hpp\"\n#include \"short_term_fourier_transform.hpp\"\n#include \"spectral_transform.hpp\"\n#include \"cvmd.hpp\"\n\n\nnamespace svr {\nnamespace datamodel {\n\nvoid Dataset::init_transform()\n{\n    p_oemd_transformer_fat = std::unique_ptr<svr::online_emd>(new svr::online_emd(transformation_levels_ / 4, OEMD_STRETCH_COEF));\n    oemd_transformer_thin = std::unique_ptr<svr::online_emd>(new svr::online_emd(transformation_levels_ / 4, OEMD_COMPRESS_COEF));\n    p_cvmd_transformer = std::unique_ptr<svr::cvmd>(new svr::cvmd(transformation_levels_ / 2));\n}\n\nDataset::Dataset(\n        bigint id,\n        const std::string &dataset_name,\n        const std::string &user_name,\n        InputQueue_ptr p_input_queue,\n        const std::vector<InputQueue_ptr> &aux_input_queues,\n        const Priority &priority,\n        const std::string &description,\n        const size_t transformation_levels,\n        const std::string &transformation_name,\n        const bpt::time_duration &max_lookback_time_gap,\n        const std::vector<Ensemble_ptr> &ensembles,\n        bool is_active,\n        const std::vector<IQScalingFactor_ptr> iq_scaling_factors,\n        const dq_scaling_factor_container_t dq_scaling_factors\n)\n        : Entity(id),\n          dataset_name_(dataset_name),\n          user_name_(user_name),\n          priority_(priority),\n          description_(description),\n          transformation_levels_(transformation_levels),\n          transformation_name_(transformation_name),\n          max_lookback_time_gap_(max_lookback_time_gap),\n          ensembles_(svr::common::clone_shared_ptr_elements(ensembles)),\n          is_active_(is_active),\n          iq_scaling_factors_(svr::common::clone_shared_ptr_elements(iq_scaling_factors)),\n          dq_scaling_factors_(svr::common::clone_shared_ptr_elements(dq_scaling_factors))\n{\n    if (!p_input_queue) THROW_EX_FS(std::logic_error, \"Input queue cannot be null.\");\n\n    input_queue_.set_obj(p_input_queue);\n\n    for (const auto &p_aux_input_queue: aux_input_queues)\n        aux_input_queues_.push_back(p_aux_input_queue);\n\n    init_transform();\n}\n\nDataset::Dataset(\n        bigint id,\n        const std::string &dataset_name,\n        const std::string &user_name,\n        const std::string &input_queue_table_name,\n        const std::vector<std::string> &aux_input_queue_table_names,\n        const Priority &priority,\n        const std::string &description, /* This is description */\n        const size_t transformation_levels,\n        const std::string &transformation_name,\n        const bpt::time_duration &max_lookback_time_gap,\n        const std::vector<Ensemble_ptr> &ensembles,\n        bool is_active,\n        const std::vector<IQScalingFactor_ptr> iq_scaling_factors,\n        const dq_scaling_factor_container_t dq_scaling_factors\n)\n        : Entity(id),\n          dataset_name_(dataset_name),\n          user_name_(user_name),\n          priority_(priority),\n          description_(description),\n          transformation_levels_(transformation_levels),\n          transformation_name_(transformation_name),\n          max_lookback_time_gap_(max_lookback_time_gap),\n          ensembles_(ensembles),\n          is_active_(is_active),\n          iq_scaling_factors_(svr::common::clone_shared_ptr_elements(iq_scaling_factors)),\n          dq_scaling_factors_(svr::common::clone_shared_ptr_elements(dq_scaling_factors))\n{\n    if (input_queue_table_name.empty()) THROW_EX_FS(std::logic_error, \"Input queue table name cannot be empty\");\n\n    input_queue_.set_id(input_queue_table_name);\n\n    for (const auto &aux_input_queue_table_name: aux_input_queue_table_names)\n        aux_input_queues_.push_back(aux_input_queue_table_name);\n\n    init_transform();\n}\n\nDataset::Dataset(Dataset const &dataset) :\n        Dataset(dataset.get_id(),\n                dataset.dataset_name_,\n                dataset.user_name_,\n                dataset.input_queue_.get_obj(),\n                dataset.get_aux_input_queues(),\n                dataset.priority_,\n                dataset.description_,\n                dataset.transformation_levels_,\n                dataset.transformation_name_,\n                dataset.max_lookback_time_gap_,\n                dataset.ensembles_,\n                dataset.is_active_,\n                dataset.iq_scaling_factors_,\n                dataset.dq_scaling_factors_)\n{\n    set_ensemble_svr_parameters_deep(dataset.get_ensemble_svr_parameters());\n}\n\n\nbool Dataset::operator==(const Dataset &other) const\n{\n    return get_id() == other.get_id()\n           && get_dataset_name() == other.get_dataset_name()\n           && get_user_name() == other.get_user_name()\n           && input_queue_.get_id() == other.input_queue_.get_id()\n           && get_priority() == other.get_priority()\n           && get_transformation_levels() == other.get_transformation_levels()\n           && get_transformation_name() == other.get_transformation_name()\n           && get_max_lookback_time_gap() == other.get_max_lookback_time_gap()\n           //          && ensembles_.size() == other.get_ensembles().size()\n           //                && std::equal(ensembles.begin(), ensembles.end(),\n           //                                other.get_ensembles().begin())\n           && get_is_active() == other.get_is_active();\n}\n\n\nvoid Dataset::on_set_id()\n{\n    for (Ensemble_ptr &p_ensemble : ensembles_)\n        p_ensemble->set_dataset_id(get_id());\n\n    for (auto &vec_svr_parameters : ensemble_svr_parameters_)\n        for (auto svr_parameters : vec_svr_parameters.second)\n            svr_parameters->set_dataset_id(get_id());\n}\n\n\nstd::string Dataset::get_dataset_name() const\n{ return dataset_name_; }\n\nvoid Dataset::set_dataset_name(const std::string &dataset_name)\n{ Dataset::dataset_name_ = dataset_name; }\n\nstd::string Dataset::get_user_name() const\n{ return user_name_; }\n\nvoid Dataset::set_user_name(const std::string &user_name)\n{ this->user_name_ = user_name; }\n\n//const InputQueue_ptr &Dataset::get_input_queue() const { return input_queue_.get_obj(); }\n\nInputQueue_ptr Dataset::get_input_queue()\n{ return input_queue_.get_obj(); }\n\n\nvoid Dataset::set_input_queue(InputQueue_ptr p_input_queue)\n{ input_queue_.set_obj(p_input_queue); }\n\n\nstd::vector<InputQueue_ptr> Dataset::get_aux_input_queues() const\n{\n    std::vector<InputQueue_ptr> result;\n    for (const auto &relation_aux_input_queue: aux_input_queues_)\n        result.push_back(relation_aux_input_queue.get_obj());\n    return result;\n}\n\n\nInputQueue_ptr Dataset::get_aux_input_queue(const size_t idx) const\n{\n    return aux_input_queues_[idx].get_obj();\n}\n\n\nstd::vector<std::string> Dataset::get_aux_input_table_names() const\n{\n    std::vector<std::string> res;\n    res.reserve(aux_input_queues_.size());\n    std::transform(aux_input_queues_.begin(), aux_input_queues_.end(),\n                   std::back_inserter(res),\n                   [](const iq_relation &inque_rel) { return inque_rel.get_obj()->get_table_name(); });\n    return res;\n}\n\nPriority const &Dataset::get_priority() const\n{ return priority_; }\n\nvoid Dataset::set_priority(Priority const &priority)\n{ this->priority_ = priority; }\n\nstd::string Dataset::get_description() const\n{ return description_; }\n\nvoid Dataset::set_description(const std::string &description)\n{ this->description_ = description; }\n\nsize_t Dataset::get_transformation_levels() const\n{ return transformation_levels_; }\n\nsize_t Dataset::get_transformation_levels_cvmd() const\n{ return transformation_levels_ / 2; }\n\nsize_t Dataset::get_transformation_levels_oemd() const\n{ return transformation_levels_ / 4; }\n\nvoid Dataset::set_transformation_levels(const size_t transformation_levels)\n{ this->transformation_levels_ = transformation_levels; }\n\nstd::string Dataset::get_transformation_name() const\n{ return this->transformation_name_; }\n\nvoid Dataset::set_transformation_name(const std::string &transformation_name)\n{\n    assert(validate_transformation_name(transformation_name));\n    this->transformation_name_ = transformation_name;\n}\n\nbool Dataset::validate_transformation_name(const std::string &transformation_name) const\n{\n    return std::find(transformation_names.begin(), transformation_names.end(), transformation_name) !=\n           transformation_names.end();\n}\n\nconst bpt::time_duration &Dataset::get_max_lookback_time_gap() const\n{ return max_lookback_time_gap_; }\n\nvoid Dataset::set_max_lookback_time_gap(const bpt::time_duration &max_lookback_time_gap)\n{ this->max_lookback_time_gap_ = max_lookback_time_gap; }\n\nstd::vector<Ensemble_ptr> &Dataset::get_ensembles()\n{ return ensembles_; }\n\nEnsemble_ptr Dataset::get_ensemble(const std::string &column_name)\n{\n    for (auto &p_ensemble: ensembles_)\n        if (p_ensemble->get_decon_queue()->get_input_queue_column_name() == column_name)\n            return p_ensemble;\n    LOG4_WARN(\"Ensemble for column \" << column_name << \" not found!\");\n    return null_ensemble;\n}\n\nconst std::map<std::pair<std::string, std::string>, DeconQueue_ptr>\nDataset::get_decon_queues() const\n{\n    std::map<std::pair<std::string, std::string>, DeconQueue_ptr> result;\n    for (const auto &p_ensemble: ensembles_) {\n        result[{p_ensemble->get_decon_queue()->get_input_queue_table_name(), p_ensemble->get_decon_queue()->get_input_queue_column_name()}] = p_ensemble->get_decon_queue();\n        for (auto &p_decon_queue: p_ensemble->get_aux_decon_queues())\n            result[{p_decon_queue->get_input_queue_table_name(), p_decon_queue->get_input_queue_column_name()}] = p_decon_queue;\n    }\n    return result;\n}\n\nvoid Dataset::clear_data()\n{\n    for (auto &p_decon_queue: get_decon_queues())\n        p_decon_queue.second->get_data().clear();\n    input_queue_.get_obj()->get_data().clear();\n    for (auto &p_input_queue: aux_input_queues_)\n        p_input_queue.get_obj()->get_data().clear();\n}\n\nDeconQueue_ptr Dataset::get_decon_queue(const InputQueue_ptr &p_input_queue, const std::string &column_name)\n{\n    for (const auto &p_ensemble: ensembles_) {\n        if (p_ensemble->get_decon_queue()->get_input_queue_table_name() == p_input_queue->get_table_name() and p_ensemble->get_decon_queue()->get_input_queue_column_name() == column_name)\n            return p_ensemble->get_decon_queue();\n        for (auto &p_decon_queue: p_ensemble->get_aux_decon_queues())\n            if (p_decon_queue->get_input_queue_table_name() == p_input_queue->get_table_name() and p_decon_queue->get_input_queue_column_name() == column_name)\n                return p_decon_queue;\n    }\n\n    LOG4_ERROR(\"Decon queue for input table \" << p_input_queue->get_table_name() << \" and input column name \" << column_name << \" not found!\");\n\n    return nullptr;\n}\n\nEnsemble_ptr Dataset::get_ensemble(const size_t idx)\n{\n    return ensembles_[idx];\n}\n\nvoid Dataset::set_ensembles(const std::vector<Ensemble_ptr> &ensembles)\n{\n    this->ensembles_ = ensembles;\n    for (const Ensemble_ptr &p_ensemble: this->ensembles_) p_ensemble->set_dataset_id(get_id());\n}\n\nbool Dataset::get_is_active() const\n{ return is_active_; }\n\nvoid Dataset::set_is_active(bool is_active)\n{ this->is_active_ = is_active; }\n\nstd::vector<IQScalingFactor_ptr> Dataset::get_iq_scaling_factors()\n{ return iq_scaling_factors_; }\n\nvoid Dataset::set_iq_scaling_factors(const std::vector<IQScalingFactor_ptr> &iq_scaling_factors)\n{ iq_scaling_factors_ = iq_scaling_factors; }\n\nsvr::datamodel::dq_scaling_factor_container_t Dataset::get_dq_scaling_factors()\n{\n    std::lock_guard<std::mutex> l(dq_scaling_factors_mutex);\n    return dq_scaling_factors_;\n}\n\nvoid Dataset::set_dq_scaling_factors(const svr::datamodel::dq_scaling_factor_container_t &dq_scaling_factors)\n{\n    std::lock_guard<std::mutex> l(dq_scaling_factors_mutex);\n    dq_scaling_factors_ = dq_scaling_factors;\n}\n\nconst double\nDataset::get_dq_scaling_factor_mul(const std::string &input_queue_table_name,\n                                   const std::string &input_queue_column_name, const size_t decon_level) const\n{\n    for (const auto &p_dq_scaling_factor: dq_scaling_factors_)\n        if (p_dq_scaling_factor->get_input_queue_table_name() == input_queue_table_name and\n            p_dq_scaling_factor->get_input_queue_column_name() == input_queue_column_name and\n            p_dq_scaling_factor->get_wavelet_level() == decon_level)\n            return p_dq_scaling_factor->get_scaling_factor();\n    LOG4_WARN(\n            \"Scaling multiplier for \" << input_queue_table_name << \" \" << input_queue_column_name << \" \" << decon_level\n                                      << \" not found.\");\n    return 0;\n}\n\nconst double\nDataset::get_dq_scaling_factor_add(const std::string &input_queue_table_name,\n                                   const std::string &input_queue_column_name, const size_t decon_level) const\n{\n    for (const auto &p_dq_scaling_factor: dq_scaling_factors_)\n        if (p_dq_scaling_factor->get_input_queue_table_name() == input_queue_table_name and\n            p_dq_scaling_factor->get_input_queue_column_name() == input_queue_column_name and\n            p_dq_scaling_factor->get_wavelet_level() == decon_level)\n            return p_dq_scaling_factor->get_mean_value();\n    LOG4_WARN(\"Scaling mean for \" << input_queue_table_name << \" \" << input_queue_column_name << \" \" << decon_level\n                                  << \" not found.\");\n    return 0;\n}\n\n\nensemble_svr_parameters_t Dataset::get_ensemble_svr_parameters() const\n{\n    std::lock_guard<std::mutex> scoped_lock(svr_params_mutex);\n    return ensemble_svr_parameters_;\n}\n\n\nSVRParameters_ptr\nDataset::get_svr_parameters(\n        const std::string &table_name,\n        const std::string &column_name,\n        const size_t level_number) const\n{\n    std::lock_guard<std::mutex> scoped_lock(svr_params_mutex);\n    const auto key_pair = std::make_pair(table_name, column_name);\n    return ensemble_svr_parameters_.at(key_pair).at(level_number);\n}\n\n\nvoid Dataset::set_ensemble_svr_parameters(ensemble_svr_parameters_t ensemble_svr_parameters)\n{\n    max_decremental_distance_cache_ = 0;\n    max_lag_count_cache_ = 0;\n#if 0\n    for (auto &new_svr_params: ensemble_svr_parameters) {\n        size_t decon_level = 0;\n        for (auto &new_svr_param : new_svr_params.second) {\n            new_svr_param->set_dataset_id(get_id());\n            if (decon_level % 2 && transformation_name_ == \"cvmd\") new_svr_param->set_skip(true);\n            //new_svr_param->set_decon_level(new_svr_params.second++);\n            new_svr_param->set_input_queue_table_name(new_svr_params.first.first);\n            new_svr_param->set_input_queue_column_name(new_svr_params.first.second);\n        }\n    }\n#endif\n    std::lock_guard<std::mutex> scoped_lock(svr_params_mutex);\n    ensemble_svr_parameters_ = ensemble_svr_parameters;\n}\n\nvoid Dataset::set_ensemble_svr_parameters_deep(ensemble_svr_parameters_t ensemble_svr_parameters)\n{\n    std::lock_guard<std::mutex> scoped_lock(svr_params_mutex);\n    max_decremental_distance_cache_ = 0;\n    max_lag_count_cache_ = 0;\n    ensemble_svr_parameters_t::const_iterator it;\n    ensemble_svr_parameters_t ensemble_svr_parameters_copy;\n    for (it = ensemble_svr_parameters.begin(); it != ensemble_svr_parameters.end(); it++) {\n        std::vector<SVRParameters_ptr> element = it->second;\n        std::vector<SVRParameters_ptr> element_copy;\n        for (auto it2 = element.begin(); it2 < element.end(); it2++)\n            element_copy.push_back(std::make_shared<svr::datamodel::SVRParameters>(**it2));\n\n        ensemble_svr_parameters_copy.insert(make_pair(it->first, element_copy));\n    }\n\n#if 0\n    for (auto &new_svr_params : ensemble_svr_parameters_copy) {\n        size_t decon_level = 0;\n        for (auto &new_svr_param : new_svr_params.second) {\n            new_svr_param->set_dataset_id(get_id());\n            new_svr_param->set_decon_level(decon_level++);\n            new_svr_param->set_input_queue_table_name(new_svr_params.first.first);\n            new_svr_param->set_input_queue_column_name(new_svr_params.first.second);\n        }\n    }\n#endif\n\n    ensemble_svr_parameters_ = ensemble_svr_parameters_copy;\n}\n\n\n/*\n *  TODO for this, and every other parameter  \n    Possibly have a boolean flag for IS_GIVEN (but not tuned)  \n    that will read the parameter, instead of leaving it at the default value,  \n    but do not use it for empty iterations of optimization.  \n    The current solution of checking for nan is unsafe.  \n*/\n\n#define CHECK_PARAM_SET(INDEX, PARAM_NAME) \\\n    if (bounds[model_number].is_tuned.PARAM_NAME)  \\\n    {  \\\n        if (parameter_values[(INDEX)] < bounds[model_number].min_bounds.get_##PARAM_NAME())  \\\n            p_svr_params->set_##PARAM_NAME(bounds[model_number].min_bounds.get_##PARAM_NAME());  \\\n        else if (parameter_values[(INDEX)] > bounds[model_number].max_bounds.get_##PARAM_NAME())  \\\n            p_svr_params->set_##PARAM_NAME(bounds[model_number].max_bounds.get_##PARAM_NAME());  \\\n        else  \\\n            p_svr_params->set_##PARAM_NAME(parameter_values[(INDEX)]);  \\\n    } else {  \\\n        if (!std::isnan(parameter_values[(INDEX)]))  \\\n            p_svr_params->set_##PARAM_NAME(parameter_values[(INDEX)]);  \\\n            else  \\\n                LOG4_WARN(  \\\n                    #PARAM_NAME \" parameter for \" << column_name << \" level \" << model_number <<  \\\n                                      \" left at default value \" << p_svr_params->get_##PARAM_NAME());  \\\n    }\n\nvoid Dataset::set_tuned_svr_parameters(\n        const std::vector<double> &parameter_values,\n        const size_t model_number,\n        const std::vector<datamodel::Bounds> &bounds,\n        const std::string &column_name)\n{\n    ensemble_svr_parameters_t ensemble_svr_params = get_ensemble_svr_parameters();\n    max_decremental_distance_cache_ = 0;\n    max_lag_count_cache_ = 0;\n\n    std::vector<SVRParameters_ptr> &vec_svr_parameters =\n            ensemble_svr_params[std::make_pair(get_input_queue()->get_table_name(), column_name)];\n\n    SVRParameters_ptr p_svr_params = vec_svr_parameters[model_number];\n\n    CHECK_PARAM_SET(0, svr_C);\n    CHECK_PARAM_SET(1, svr_epsilon);\n    CHECK_PARAM_SET(2, svr_kernel_param);\n    CHECK_PARAM_SET(3, svr_kernel_param2);\n    CHECK_PARAM_SET(4, svr_decremental_distance);\n    CHECK_PARAM_SET(5, svr_adjacent_levels_ratio);\n    CHECK_PARAM_SET(6, lag_count);\n\n    set_ensemble_svr_parameters_deep(ensemble_svr_params);\n}\n\nsize_t Dataset::get_max_lag_count()\n{\n    if (max_lag_count_cache_ != 0) {\n        LOG4_DEBUG(\"Returning cached value \" << max_lag_count_cache_ + 1);\n        return max_lag_count_cache_ + 1;\n    }\n\n    std::lock_guard<std::mutex> scoped_lock(svr_params_mutex);\n    if (ensemble_svr_parameters_.empty())\n        THROW_EX_FS(std::logic_error, \"get_max_lag_count called with empty SVR parameters.\");\n\n    size_t lag_count = 0;\n    for (auto const &ens_svr_params : ensemble_svr_parameters_)\n        for (auto const &svr_param : ens_svr_params.second)\n            lag_count = std::max(lag_count, svr_param->get_lag_count());\n    max_lag_count_cache_ = lag_count;\n    LOG4_DEBUG(\"Returning non-cached value \" << max_lag_count_cache_ + 1);\n    return lag_count + 1; // Add one because of the anchor row TODO Separate logic\n}\n\nsize_t Dataset::get_max_decrement()\n{\n    if (max_decremental_distance_cache_ != 0) return max_decremental_distance_cache_;\n    std::lock_guard<std::mutex> scoped_lock(svr_params_mutex);\n    if (ensemble_svr_parameters_.empty())\n        throw std::logic_error(\"get_max_decrement called with empty SVR parameters.\");\n\n    size_t max_decremental_distance = 0;\n    for (auto const &ens_svr_params : ensemble_svr_parameters_)\n        for (auto const &svr_param : ens_svr_params.second)\n            max_decremental_distance = std::max(max_decremental_distance, svr_param->get_svr_decremental_distance());\n    max_decremental_distance_cache_ = max_decremental_distance;\n    return max_decremental_distance;\n}\n\nsize_t Dataset::calculate_max_residuals_count() const\n{\n    if (ensembles_.empty()) LOG4_THROW(\"EVMD needs ensembles initialized to calculate residuals count.\");\n\n    size_t result = 0;\n    for (const auto &p_ensemble: ensembles_) {\n        size_t res_count = get_residuals_count(p_ensemble->get_decon_queue()->get_table_name());\n        if (res_count > result) result = res_count;\n    }\n    return result;\n}\n\nsize_t Dataset::get_residuals_count(const std::string &decon_queue_table_name) const\n{\n    return std::max(\n            p_cvmd_transformer->get_residuals_length(decon_queue_table_name),\n            p_oemd_transformer_fat->get_residuals_length());\n}\n\nstd::string Dataset::to_string() const\n{\n    std::stringstream ss;\n\n    ss << \"DatasetId: \" << get_id()\n       << \", DatasetName: \" << get_dataset_name()\n       << \", QueueTableName: \" << input_queue_.get_id()\n       << \", UserName: \" << get_user_name()\n       << \", Priority: \" << svr::datamodel::to_string(get_priority())\n       << \", Description: \" << get_description()\n       << \", TransformationLevels: \" << get_transformation_levels()\n       << \", TransformationWaveletName: \" << get_transformation_name()\n       << \", Max Lookback Time Gap: \" << bpt::to_simple_string(get_max_lookback_time_gap())\n       << \", is active: \" << get_is_active();\n\n    return ss.str();\n}\n\nstd::string Dataset::parameters_to_string() const\n{\n    std::lock_guard<std::mutex> scoped_lock(svr_params_mutex);\n\n    std::string s{\"{\"};\n\n    s += \"\\\"transformation_levels\\\":\\\"\" + std::to_string(transformation_levels_) + \"\\\",\";\n    s += \"\\\"transformation_name\\\":\\\"\" + transformation_name_ + \"\\\",\";\n\n    // ensembles[0] is used since each ensemble has the same parameters\n    const std::vector<SVRParameters_ptr> &vec_parameters{ensemble_svr_parameters_.begin()->second};\n    size_t model_number{0};\n\n    for (auto &parameters : vec_parameters)\n        s += parameters->to_options_string(model_number++) + \",\";\n\n    // remove last character, i.e. \",\"\n    s.pop_back();\n\n    return s + \"}\";\n}\n\n}   //end of datamodel namespace\n}   //end of svr\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- SVRRoot/SVRModel/src/Dataset.cpp	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ SVRRoot/SVRModel/src/Dataset.cpp	(date 1672559513343)
@@ -1,14 +1,14 @@
-#include <model/Dataset.hpp>
-#include <OnlineSVR.h>
+#include "model/Dataset.hpp"
+#include "OnlineSVR.h"
 
 #include "appcontext.hpp"
 
-#include <SVRParametersService.hpp>
+#include "SVRParametersService.hpp"
 
 #include "online_emd.hpp"
 #include "short_term_fourier_transform.hpp"
 #include "spectral_transform.hpp"
-#include "cvmd.hpp"
+#include "fast_cvmd.hpp"
 
 
 namespace svr {
@@ -18,7 +18,7 @@
 {
     p_oemd_transformer_fat = std::unique_ptr<svr::online_emd>(new svr::online_emd(transformation_levels_ / 4, OEMD_STRETCH_COEF));
     oemd_transformer_thin = std::unique_ptr<svr::online_emd>(new svr::online_emd(transformation_levels_ / 4, OEMD_COMPRESS_COEF));
-    p_cvmd_transformer = std::unique_ptr<svr::cvmd>(new svr::cvmd(transformation_levels_ / 2));
+    p_cvmd_transformer = std::unique_ptr<svr::fast_cvmd>(new svr::fast_cvmd(transformation_levels_ / 2));
 }
 
 Dataset::Dataset(
Index: SVRRoot/OnlineSVR/src/cvmd.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>//\n// Created by zarko on 19.12.20 ?..\n//\n#include <iostream>\n#include <algorithm>\n#include <cmath>\n#include <vector>\n#include <cstring>\n#include <cstdlib>\n#include <unistd.h>\n#include <types.h>\n#include <complex>\n#include \"cvmd.hpp\"\n\n#include \"common/Logging.hpp\"\n#include \"common/gpu_handler.h\"\n\n#ifdef NEW_FAST_CVMD\n#include \"fast_cvmd.hpp\"\n#endif\n\n#ifdef DEBUG_CVMD\n#undef cilk_for\n#define cilk_for for\n#else\n#include <cilk/cilk.h>\n#include <cilk/reducer_opadd.h>\n#endif\n\n#include \"osqp.h\"\n#undef MAX_ITER\n#include \"common.hpp\"\n\n// maximum number of iterations. 500 seems to be enough\n\n#define MAX_VMD_ITERATIONS 500\n\nnamespace svr {\n\nstruct cvmd_frequency_outputs {\n    arma::mat       u;\n    arma::cx_mat    u_hat;\n    arma::mat       omega;\n    std::vector<double> last_y = {};\n    OSQPSolver *p_solver = nullptr;\n};\n\n\nOSQPSettings *init_osqp_settings(const svr::common::gpu_context &gtx)\n{\n    /* Set default settings */\n    auto settings = (OSQPSettings *) malloc(sizeof(OSQPSettings));\n    if (settings) osqp_set_default_settings(settings);\n    settings->polish = 1;\n    settings->max_iter = 4000;\n    settings->eps_abs = 1.0e-05;\n    settings->eps_rel = 1.0e-05;\n    settings->alpha = 0.6;\n\n    settings->eps_prim_inf = 1.0e-06;\n    settings->eps_dual_inf = 1.0e-06;\n    settings->polish_refine_iter = 3;\n    settings->deviceId = gtx.id();\n\n    // settings->delta = 1e-06;\n#ifdef DEBUG_CVMD\n    settings->verbose = 1;\n#else\n    settings->verbose = 0;\n#endif\n    return settings;\n}\n\nvoid do_vmd_freqs(\n        const arma::mat &signal, const double alpha, const double tau, const int K, const int DC, const int init, const double tol,\n        /*outputs */ arma::mat &u, arma::cx_mat &u_hat, arma::mat &omega_plus)\n{\n    //Initialize u, w, lambda, n\n    int save_T = signal.n_elem;\n\n    int T = save_T;\n    if (T & 1) LOG4_THROW(\"Input data size \" << T << \" must be even!\");\n\n    //create the mirrored signal\n    arma::mat f_mirror = arma::zeros(1,2 * T);\n\n    PFORi(0, T/2, f_mirror(0, i) = signal(0, T / 2 - 1 - i))\n    PFORi(0, T, f_mirror(0, T / 2 + i) = signal(0, i))\n    PFORi(0, T/2, f_mirror(0, 3 * T / 2 + i) = signal(0, T-1-i))\n\n    arma::mat f = f_mirror;\n    T = 2 * T;\n\n    arma::mat Alpha = alpha * arma::ones(1, K);//provision to use different alpha for the different frequences, at a later stage\n\n    const double fs = 1./ double(save_T);//step\n\n    const int N_max = MAX_VMD_ITERATIONS;//max number of iterations\n\n    u = arma::zeros(T,K);\n    const double eps = 2.220446049250313e-16;\n    //this may or may not work instead. double eps=std::numeric_limits<T>::epsilon();\n\n    // Time Domain 0 to T (of mirrored signal)\n    arma::mat t(1, T);\n    PFORi(0, T, t(0,i) = (double(i) + 1.) / double(T))\n    // Spectral Domain discretization\n    arma::mat freqs = t - 0.5 - 1. / double(T);\n    omega_plus = arma::zeros(K, 1);\n    arma::cx_mat f_hat = common::fftshift(common::matlab_fft(f));\n    arma::cx_mat f_hat_plus = f_hat;\n\n    PFORi(0, T / 2, f_hat_plus(0, i) = 0)\n\n    switch (init) {\n        case 1:{\n            PFORi(0, K, omega_plus(i, 0) = .5 / K * i);\n            break;\n        }\n        case 2:{\n            arma::mat real_ran (K,1);\n            PFORi(0, K, real_ran(i, 0) = exp(log(fs) + (log(0.5) - log(fs)) * common::randouble()));\n            real_ran = arma::sort(real_ran);\n            PFORi(0, K, omega_plus(i, 0) = real_ran(i, 0));\n            break;\n        }\n        case 0:{\n            //PFORi(0, K, omega_plus[i] = 0);\n            break;\n        }\n        default:{\n            LOG4_THROW(\"Init should be 0,1 or 2!\");\n        }\n    }\n    if (DC == 1) { //if DC component, then first frequency is 0!\n        omega_plus(0,0) = 0;\n    }\n    /* completed initialization of frequencies */\n    arma::cx_mat lambda_hat( arma::zeros(1, freqs.n_elem), arma::zeros(1, freqs.n_elem)); // keeping track of the evolution of lambda_hat with the iterations\n    arma::cx_mat u_hat_plus(arma::zeros(T,K), arma::zeros(T,K));\n    arma::cx_mat u_hat_plus_old = u_hat_plus;\n\n#ifdef DEBUG_CVMD\n    double uDiff{tol+eps};\n#else\n    double uDiff = tol + eps; //tol+eps must be different from just tol, that is why eps should not be too small\n#endif\n\n    arma::cx_mat sum_uk(arma::zeros(1,T),arma::zeros(1, T));\n    int n_iter = 0;\n#ifdef DEBUG_CVMD\n    while  ((n_iter < N_max) && (uDiff > tol)) {\n#else\n    while(n_iter < N_max && uDiff > tol) {\n#endif\n        //% update first mode accumulator\n        PFORi(0, T, sum_uk(0, i) = u_hat_plus_old(i, K-1) + sum_uk(0, i) - u_hat_plus_old(i, 0));\n\n        //% update spectrum of first mode through Wiener filter of residuals\n        int k = 0;\n        PFORi(0, T,\n            u_hat_plus(i, k) = (f_hat_plus(0,i) - sum_uk(0,i) - lambda_hat(0,i)/2.)/(1.+Alpha(0,k) * std::pow((freqs(0,i) - omega_plus[k]), 2));\n        )\n\n        if (DC == 0) {\n            //when DC==1, the first frequency can not be changed. that is why this cycle only for DC==0.\n#ifdef DEBUG_CVMD\n            double sum_up = 0.;\n            double sum_down = 0.;\n            for (int i=0; i < T/2; ++i) {\n                sum_up += freqs(0,T/2+i)*std::norm(u_hat_plus(T/2+i,k));\n                sum_down += std::norm(u_hat_plus(T/2+i,k));\n            }\n            omega_plus(0,0) = sum_up / sum_down;\n#else\n            double clk_sum_up = 0;\n            double clk_sum_down = 0;\n            for (int i=0; i < T / 2; ++i) {\n                const auto norm_uhat_plus = std::norm(u_hat_plus(T / 2 + i, k));\n                clk_sum_up += freqs(0,T/2+i) * norm_uhat_plus;\n                clk_sum_down += norm_uhat_plus;\n            }\n            omega_plus(0, 0) = clk_sum_up / clk_sum_down;\n#endif\n        }\n\n        // update of any other mode (k from 1 to K-1), after the first\n        for (k=1; k < K; ++k) {\n            // accumulator\n            PFORi(0, T, sum_uk(0, i) = u_hat_plus(i, k - 1) + sum_uk(0, i) - u_hat_plus_old(i, k))\n            // mode spectrum\n            PFORi(0, T, u_hat_plus(i, k) = (f_hat_plus(0, i) - sum_uk(0, i) - lambda_hat(0, i)/2.)/(1.+Alpha(0, k)*std::pow(freqs(0, i) - omega_plus[k], 2)))\n\n            //re-compute center frequencies\n#ifdef DEBUG_CVMD\n            double sum_up = 0.;\n            double sum_down = 0.;\n            for (int i = 0; i < T / 2; ++i) {\n                sum_up += freqs(0, T / 2 + i) * std::norm(u_hat_plus(T / 2 + i, k));\n                sum_down += std::norm(u_hat_plus(T / 2 + i, k));\n            }\n            omega_plus(k, 0) = sum_up / sum_down;\n#else\n            double clk_sum_up = 0;\n            double clk_sum_down = 0;\n            for (int i = 0; i < T / 2; ++i) {\n                const double u_hat_plus_norm = std::norm(u_hat_plus(T / 2 + i, k));\n                clk_sum_up += freqs(0, T / 2 + i) * u_hat_plus_norm;\n                clk_sum_down += u_hat_plus_norm;\n            }\n            omega_plus(k, 0) = clk_sum_up / clk_sum_down;\n#endif\n        }\n        // Dual ascent\n        arma::cx_mat sum_u_hat_plus = arma::sum(u_hat_plus.t());\n\n        PFORi(0, T, lambda_hat(0, i) += tau * (sum_u_hat_plus(0, i) - f_hat_plus(0, i)) )\n        // loop counter\n        ++n_iter;\n\n        //compute uDiff\n#ifdef DEBUG_CVMD\n        uDiff = 0.;\n#else\n        uDiff = 0;\n#endif\n        for (int i = 0; i < K; ++i) {\n            double s = 0;\n            double s_norm_old = 0;\n            for (int j = 0; j < T; ++j) {\n                s += std::norm(u_hat_plus(j,i) - u_hat_plus_old(j,i));\n                s_norm_old += std::norm(u_hat_plus_old(j,i));\n            }\n            uDiff += (s / s_norm_old);\n        }\n        u_hat_plus_old = u_hat_plus;\n    }\n    //%------ Postprocessing and cleanup\n    //% discard empty space if converged early - this step is not used here\n    //N = min(N,n);\n    //omega = omega_plus(1:N,:);\n    // - this not needed, since we do not keep all omega, only the latest!\n\n    // Signal reconstruction\n    arma::cx_mat zmat (arma::zeros(T, K), arma::zeros(T, K));\n    u_hat = zmat;\n    PFORi(0, T / 2,\n        for (int k = 0; k < K; ++k)\n            u_hat(T / 2 + i, k) = u_hat_plus(T / 2 + i, k) )\n    // here it is not clear why, but T/2 is set both above and below. Instead, the 0 is set to conj of T-1\n    PFORi(0, T / 2, for (int k=0; k < K; ++k) u_hat(T / 2 - i, k) = std::conj(u_hat_plus(T / 2 + i, k)) )\n    for (int k = 0; k < K; ++k) u_hat(0, k) = std::conj(u_hat(T - 1, k));\n\n    arma::mat u_big = arma::zeros(K, t.n_elem);\n    PFOR(k, 0, K, u_big.rows(k, k) = arma::trans(arma::real(common::matlab_ifft(common::ifftshift(u_hat.cols(k, k))))); )\n    u = arma::zeros(K,T/2);\n    PFORi(0, T / 2, for (int k = 0; k < K; ++k) u(k, i) = u_big(k, T / 4 + i); )\n    //recompute spectrum\n    //clear u_hat;\n    u_hat = arma::cx_mat(arma::zeros(K,T/2),arma::zeros(K,T/2));\n    PFOR(k, 0, K, u_hat.rows(k, k) = common::fftshift(common::matlab_fft(u.rows(k,k))) )\n    omega_plus /= CVMD_FREQ_ADJUST;\n\n    LOG4_TRACE(\"Omega is \" << omega_plus);\n}\n\n// TODO Add column and table name\ncvmd::cvmd(const size_t _levels)\n        : spectral_transform(std::string(\"cvmd\"), _levels), levels(_levels)\n{\n    if (levels < 2 or levels % 2) LOG4_THROW(\"Invalid number of levels \" << levels);\n}\n\ncvmd::~cvmd()\n{\n    uninitialize(true);\n}\n\ncvmd_frequency_outputs\ncalculate_vmd_frequencies(const std::vector<double> &input, const size_t levels_half)\n{\n    LOG4_DEBUG(\"Calculating VMD frequencies for \" << levels_half << \" half levels.\");\n    arma::rowvec x_signal;\n    if (input.size() % 2) LOG4_WARN(\"Odd signal length \" << input.size() << \", trimming first value.\");\n    x_signal = input.size() % 2 ? arma::rowvec(&*std::next(input.begin()), input.size() - 1) : input;\n    x_signal *= CVMD_INPUT_MULTIPLIER;\n\n    /* constants */\n    const double alpha = ALPHA_BINS;//bands\n    const double tau = TAU_FIDELITY;//fidelity - 0 means no strict enforcement of decomposition. In reality we should use something like 0.1 or higher.\n    const int DC = 0; //has a DC component or not.\n    const int K = levels_half; //number of modes/frequencies. because of DC=1 we use 1 more than the natural number of frequencies (3 in the signal above).\n    const int init = 1; //kind of initialization, let's use 1 for now.\n    const double tol = 1e-7; //some tolerance\n    /* end constants*/\n    /* outputs*/\n    arma::mat u;\n    arma::cx_mat u_hat;\n    arma::mat omega;\n    /* end outputs*/\n\n    do_vmd_freqs(x_signal, alpha, tau, K, DC, init, tol, u, u_hat, omega);\n#ifdef DEBUG_CVMD\n    {\n        std::stringstream ss_input;\n        for (size_t i = 0; i < T; ++i) ss_input << x_signal(0, i) << \", \";\n        LOG4_FILE(\"cvmd_input.csv\", ss_input.str());\n    }\n    {\n        std::stringstream ss_omega;\n        for (size_t i = 0; i < omega.n_rows; ++i) ss_omega << omega(i, 0) << \", \";\n        LOG4_FILE(\"cvmd_omega.csv\", ss_omega.str());\n    }\n#endif\n\n    return {u, u_hat, omega};\n}\n\ndouble\nobject_compute(\n        int N, int levels,\n        std::vector<std::vector<double>> &f_u_mult, std::vector<std::vector<double>> &f_v_mult,\n        double *test_sol, double *f_lambda, bool use_left,\n        const std::vector<double> &left_u_values, const std::vector<double> &left_v_values)\n{\n    double object0=0.;\n    for(int i=(use_left?-1:0);i<N-1;i++){\n        double s0=0.;\n        for (int j=0 ; j<levels; ++j){\n            double um1 = (use_left && (i==-1)) ? left_u_values[j] : test_sol[2*(i+j*N)+0 ];\n            double vm1 = (use_left && (i==-1)) ? left_v_values[j] : test_sol[2*(i+j*N)+1 ];\n            int ip1=i + 1;\n\n            double u = test_sol[2*(ip1+j*N) + 0];\n            double v = test_sol[2*(ip1+j*N) + 1];\n\n            std::complex<double> xm1{um1, vm1};\n            std::complex<double> x{u, v};\n            std::complex<double> xm1_adjusted = xm1 * std::complex<double>(f_u_mult[j][i+(use_left?1:0)], f_v_mult[j][i+(use_left?1:0)]);\n            std::complex<double> x_adjusted = x * std::complex<double>(f_u_mult[j][i+1+(use_left?1:0)], f_v_mult[j][i+1+(use_left?1:0)]);\n\n            double diff_norm = std::norm( x_adjusted - xm1_adjusted);\n            double quant = f_lambda[j]*diff_norm;\n            s0+=quant;\n        }\n        object0+=s0;\n    }\n    return object0;\n}\n\n//interface without armadillo\nint\nvmd_decomp(const size_t T, const double *signal, double alpha, const double tau, const size_t K, int DC, int init , double tol,\n        /*outputs */ double* decomposition_u ,/*complex*/ double*decomposition_u_hat, double * decomposition_omega)\n{\n    /*caller must allocate K*T*sizeof(double) for decomposition_u, 2*K*T*sizeof(double) for decomposition_u_hat (which is complex), K*sizeof(double) for decomposition_omega_plus*/\n\n    arma::mat x_signal(1, T);\n    for (size_t i=0;i<T;i++) {\n        x_signal(0,i)=signal[i];\n    }\n    arma::mat u;\n    arma::cx_mat u_hat;\n    arma::mat omega;\n    do_vmd_freqs(x_signal, alpha, tau, K, DC, init, tol, u, u_hat, omega);\n    cilk_for(size_t k=0;k<K;k++){\n        for(size_t i=0;i<T;i++){\n            decomposition_u[k*T+i] = u(k,i);\n        }\n    }\n    cilk_for (size_t k=0;k<K;k++){\n        for(size_t i=0;i<T;i++){\n            decomposition_u_hat[2*(k*T+i)+0] = std::real(u_hat(k,i));\n            decomposition_u_hat[2*(k*T+i)+1] = std::imag(u_hat(k,i));\n        }\n    }\n    cilk_for(size_t k=0;k<K;k++){\n        decomposition_omega[k]=omega(k,0);\n    }\n    return 0;\n}\n\nvoid reset_solver(OSQPSolver *p_solver)\n{\n    OSQPVectorf_set_scalar(p_solver->work->x_prev, 0);\n    OSQPVectorf_set_scalar(p_solver->work->z_prev, 0);\n    OSQPVectorf_set_scalar(p_solver->work->z, 0);\n    OSQPVectorf_set_scalar(p_solver->work->D_temp, 0);\n    OSQPVectorf_set_scalar(p_solver->work->D_temp_A, 0);\n    OSQPVectorf_set_scalar(p_solver->work->E_temp, 0);\n    OSQPVectorf_set_scalar(p_solver->work->xz_tilde, 0);\n    OSQPVectorf_set_scalar(p_solver->work->xtilde_view, 0);\n    OSQPVectorf_set_scalar(p_solver->work->ztilde_view, 0);\n    OSQPVectorf_set_scalar(p_solver->work->delta_y, 0);\n    OSQPVectorf_set_scalar(p_solver->work->Atdelta_y, 0);\n    OSQPVectorf_set_scalar(p_solver->work->delta_x, 0);\n    OSQPVectorf_set_scalar(p_solver->work->Pdelta_x, 0);\n    OSQPVectorf_set_scalar(p_solver->work->Adelta_x, 0);\n    OSQPVectorf_set_scalar(p_solver->work->scaling->D, 0);\n    OSQPVectorf_set_scalar(p_solver->work->scaling->Dinv, 0);\n    OSQPVectorf_set_scalar(p_solver->work->scaling->E, 0);\n    OSQPVectorf_set_scalar(p_solver->work->scaling->Einv, 0);\n    p_solver->work->linsys_solver->reset(p_solver->work->linsys_solver);\n}\n\nvoid\ndo_problem(\n#ifdef USE_CUDA\n        OSQPSolver *&p_solver, const OSQPSettings *p_settings,\n#endif\n        const size_t levels_half,\n        const std::vector<std::vector<double>> &phase_series,\n        const std::vector<double> &x_series,\n        const size_t N, // Number of time steps does not need to equal x_series.size()\n#ifdef DEBUG_CVMD\n        const std::vector<std::vector<double>> &u_series, const std::vector<std::vector<double>> &v_series,\n#endif\n        std::vector<std::vector<double>> &decon,\n        cvmd_frequency_outputs &found_freqs,\n        const std::vector<double> &prev_decon = {}\n)\n{\n    if (not prev_decon.empty() and x_series.size() != 1)\n        THROW_EX_FS(std::invalid_argument, \"Online VMD should only be done with 1 row per call!\"); // TODO For now, improve\n\n    std::vector<std::vector<double>> f_u_mult(levels_half), f_v_mult(levels_half);\n    //const std::vector<double>  f_lambda(levels_half, 1.);\n    /*\n    for(size_t i = 0; i < levels_half;i++){\n        //f_lambda[i]=pow(0.5,2*i); this was good\n        f_lambda[i]=1.;\n    }\n    */\n\n#if 0\n    std::vector<std::vector<double>>  f_mu(levels_half);\n    for (size_t i = 0; i<levels_half; ++i) {\n        f_mu[i].resize(N, 0.);\n        /*\n        for(int j = 0; j<N; ++j){\n            f_mu[i][j]=0.;//not used for now\n        }\n         */\n    }\n#endif\n    const auto levels = 2 * levels_half;\n    cilk_for(size_t l = 0; l < levels_half; ++l) {\n        f_u_mult[l].resize(N + 1); // 2*M_PI*omega\n        f_v_mult[l].resize(N + 1);\n    }\n    // Phase_series is computed on basis of the omega. In fact, it is not necessary to know the exact phase at a\n    // given point, knowing the omega, i.e., difference in phase, is enough for this computation\n    // further enhancement can be achieved with varying the phases or the differences between phases - for future work.\n    cilk_for(size_t l = 0; l < levels_half; ++l) {\n        for (size_t t = 0; t < N + 1; ++t) {\n            f_u_mult[l][t] = cos(-phase_series[t][l]);\n            f_v_mult[l][t] = sin(-phase_series[t][l]);\n        }\n    };\n\n    std::vector<double> B_matrix_val;\n    std::vector<int> B_matrix_i;\n    std::vector<int> B_matrix_j;\n\n    // u and v are the unknowns,\n    // total number is levels_half * 2 * N\n    //\n    const size_t total_number = levels * N;\n    for (size_t cntr = 0; cntr < total_number; ++cntr){\n        const int timestep = (cntr / 2 ) % N; //which timestep\n        const int level = (cntr / 2) / N;\n        double val;\n        if ((size_t) timestep == N-1) {\n            B_matrix_i.push_back(cntr);\n            B_matrix_j.push_back(cntr);\n            val = 1.;//1.*f_lambda[level]+1.*f_mu[level][timestep];\n            B_matrix_val.push_back(val);\n            continue;\n        }\n\n        if (cntr  % 2 == 0) {//u\n            B_matrix_i.push_back(cntr);\n            B_matrix_j.push_back(cntr);\n            val = f_u_mult[level][timestep]*f_u_mult[level][timestep] + f_v_mult[level][timestep]*f_v_mult[level][timestep];\n            //val+= 1.*f_mu[level][timestep];\n            if (timestep > 0 or not prev_decon.empty()) { //changed here to be able to deal with left values\n                val += 1.; //this should be simply 1., no need to compute cos^2+sin^2\n            }\n            B_matrix_val.push_back(val);//*f_lambda[level]);\n            B_matrix_i.push_back(cntr);//itself\n            B_matrix_j.push_back(cntr+2);//u+1 for this u\n            val = -2 * f_u_mult[level][timestep+1]*f_u_mult[level][timestep];\n            val += -2 * f_v_mult[level][timestep+1]*f_v_mult[level][timestep];\n            B_matrix_val.push_back(val*0.5);//f_lambda[level]/2.);//due to the symmetry\n            B_matrix_i.push_back(cntr);//itself\n            B_matrix_j.push_back(cntr+3);//v+1 for this u\n            val = 2* f_u_mult[level][timestep]*f_v_mult[level][timestep+1];\n            val += -2* f_v_mult[level][timestep]*f_u_mult[level][timestep+1];\n            B_matrix_val.push_back(val*0.5);//f_lambda[level]/2);//symmetry\n        } else {\n            B_matrix_i.push_back(cntr);\n            B_matrix_j.push_back(cntr);\n            val = f_v_mult[level][timestep] * f_v_mult[level][timestep] + f_u_mult[level][timestep] * f_u_mult[level][timestep];//==1.\n            //val+= 1.*f_mu[level][timestep];\n            if (timestep > 0 or not prev_decon.empty()) {//changed here to be able to deal with left values\n                val += 1.;\n            }\n            B_matrix_val.push_back(val);//*f_lambda[level]);\n            /*\n             with the corresponding u - is 0 by conjugates\n             */\n            B_matrix_i.push_back(cntr);//itself\n            B_matrix_j.push_back(cntr+1);//u+1 for this v\n            val = 2 * f_u_mult[level][timestep+1] * f_v_mult[level][timestep];\n            val += -2 * f_v_mult[level][timestep+1] * f_u_mult[level][timestep];\n            B_matrix_val.push_back(val * 0.5);//f_lambda[level]/2.);//symmetry\n            B_matrix_i.push_back(cntr);//itself\n            B_matrix_j.push_back(cntr + 2);//v+1 for this v\n            val = -2 * f_v_mult[level][timestep] * f_v_mult[level][timestep+1] ;\n            val += -2 * f_u_mult[level][timestep] * f_u_mult[level][timestep+1];\n            B_matrix_val.push_back(val * 0.5);//f_lambda[level]/2.);//symmetry\n        }\n    }\n    std::vector<int> index(B_matrix_j.size());\n    std::iota(index.begin(),index.end(),0); //Initializing\n    std::sort(index.begin(),index.end(), [&](int i, int j) { return B_matrix_j[i]<B_matrix_j[j]; } );\n\n    std::vector<c_int> C_matrix_i(B_matrix_i.size());\n    std::vector<c_float> C_matrix_val(B_matrix_val.size()); // P_x_vector\n    std::vector<c_int> C_matrix_j;//empty\n    int col = -1;\n    for (size_t i = 0; i < B_matrix_i.size(); ++i) {\n        if (B_matrix_j[index[i]] != col){\n            if ((col - B_matrix_j[index[i]])!=-1)\n                THROW_EX_FS(std::runtime_error, \"CVMD Error \" << col << \" \" << B_matrix_j[index[i]]);\n            col = B_matrix_j[index[i]];\n            C_matrix_j.push_back(i);\n        }\n        C_matrix_i[i]=B_matrix_i[index[i]];\n        C_matrix_val[i]=B_matrix_val[index[i]];\n    }\n    C_matrix_j.push_back(B_matrix_i.size());\n\n    //c_int P_nnz = C_matrix_val.size();\n    c_int n = total_number;\n\n    //c_int *P_p = C_matrix_j.data();\n    //c_int *P_i = C_matrix_i.data();\n    //c_float *P_x = C_matrix_val.data();\n    //the real parts of the first elements are to be fixed to their matlab generated decomposed u\n    //for this fixing we need conditions, to set them equal to the matlab results.\n    //for the corresponding sums, we can not fix them to the x_series , because matlab does not solve exactly\n\n    c_int A_nnz = levels_half * N; //this does not change , only the number of equations change. instead of one, we have many separate\n    std::vector<c_int> pre_A_i_vector(A_nnz);\n    std::vector<c_float> pre_A_x_vector(A_nnz,1.);\n    std::vector<c_int> pre_A_j_vector(A_nnz);\n    cilk_for(size_t i = 0; i < (decltype(i))A_nnz; ++i) {\n        const int timestep = i % N  ; //which timestep\n        const int level = i / N ;\n        pre_A_i_vector[i] = timestep;\n        //pre_A_x_vector [i]=1.; - already done\n        pre_A_j_vector[i] = (2 * timestep + 0) + 2 * N * level;\n        //std::cout <<  \"preA \" << pre_A_i_vector[i] << \" \"<< pre_A_j_vector[i]<< std::endl;\n    };\n\n    std::vector<c_int> A_i_vector(A_nnz);\n    std::vector<c_float> A_x_vector(A_nnz,1.);\n    std::vector<c_int> A_p_vector;\n\n    index.resize(A_nnz);\n    std::iota(index.begin(), index.end(),0); //Initializing\n    std::sort(index.begin(), index.end(),[&](int i,int j){return pre_A_j_vector[i]<pre_A_j_vector[j];} );\n\n    col = -1;\n    for (size_t i = 0; i < pre_A_i_vector.size(); ++i) {\n        if (pre_A_j_vector[index[i]] != col) {\n            for (int filler = col+1; filler < pre_A_j_vector[index[i]]; ++filler) {\n                A_p_vector.push_back(i);\n            }\n            col = pre_A_j_vector[index[i]];\n            A_p_vector.push_back(i);\n        }\n        A_i_vector[i]=pre_A_i_vector[index[i]];\n        A_x_vector[i]=pre_A_x_vector[index[i]];\n    }\n\n    A_p_vector.push_back(A_nnz);\n    A_p_vector.push_back(A_nnz);\n\n    //c_int *A_i = A_i_vector.data();\n    //c_float *A_x = A_x_vector.data();\n    //c_int *A_p = A_p_vector.data();\n    std::vector<c_float> lo_vector(N);\n    std::vector<c_float> up_vector(N);\n    cilk_for(size_t i = 0; i < N; ++i) {\n        lo_vector[i] = CVMD_INPUT_MULTIPLIER * x_series[i] - EPSI_TOL_VMD;\n        up_vector[i] = CVMD_INPUT_MULTIPLIER * x_series[i] + EPSI_TOL_VMD;\n    };\n    //c_float *lo = lo_vector.data();\n    //c_float *up = up_vector.data();\n    std::vector<c_float> q_vector(total_number,0.);\n\n    // second place where there is difference because of left values\n    if (not prev_decon.empty()) {\n        std::vector<double> cos_delta_phi(levels_half, 0.);\n        std::vector<double> sin_delta_phi(levels_half, 0.);\n        cilk_for (size_t l = 0; l < levels_half; ++l){\n            // in principle fromN-1 and fromN should be used, but sometimes function can be invoked with fromN equal to 0. Only the difference in phases at the start is needed here.\n            cos_delta_phi[l] = cos(phase_series[1][l] - phase_series[0][l]); // in principle fromN-1 and fromN should be used, but sometimes function can be invoked with fromN =0.\n            sin_delta_phi[l] = sin(phase_series[1][l] - phase_series[0][l]); // TODO Verify with Emanouil\n        }\n        cilk_for (size_t t = 0; t < total_number; ++t) {\n            if ((t / 2) % N == 0) {\n                const auto level = (t / 2) / N;\n                if (t % 2 == 0) {\n                    q_vector[t] = -2. * prev_decon[2 * level] * cos_delta_phi[level] + 2. * prev_decon[2 * level + 1] * sin_delta_phi[level];\n                } else {\n                    q_vector[t] = -2. * prev_decon[2 * level] * sin_delta_phi[level] - 2. * prev_decon[2 * level + 1] * cos_delta_phi[level];\n                }\n                q_vector[t] = q_vector[t] / 2.;\n            }\n        }\n    }\n\n    //c_float *q = q_vector.data();\n\n#ifdef DEBUG_CVMD\n    {  /* little testing perhaps */\n        std::vector<double> test_sol(total_number);\n        for(size_t i=0;i<total_number;i++){\n            int timestep = (i / 2 ) % N  ; //which timestep\n            int u_or_v =  i  % 2;\n            int level = (i / 2) / N ;\n            if (u_or_v==0){\n                if (fromN+timestep < u_series[level].size()){\n                    test_sol[i]=u_series[level][fromN+timestep];\n                }else{\n                    test_sol[i]=u_series[level][ u_series[level].size()-1];\n                }\n            }else{\n                if (fromN+timestep < v_series[level].size()){\n                    test_sol[i]=v_series[level][fromN+timestep];\n                }else{\n                    test_sol[i]=v_series[level][ v_series[level].size()-1];\n                }\n            }\n        }\n#if 0\n        {\n            std::stringstream ss;\n            for (const auto i: test_sol) ss << \", \" << i;\n            LOG4_FILE(\"cvmd_ptest_sol.txt\", ss.str().c_str());\n        }\n        {\n            std::stringstream ss;\n            for (size_t j = 0; j < M; ++j) {\n                ss << \"\\nLevel \" << j;\n                for (const auto i: u_series[j]) ss << \", \" << i;\n            }\n            LOG4_FILE(\"cvmd_u_series.txt\", ss.str().c_str());\n        }\n        {\n            std::stringstream ss;\n            for (size_t j = 0; j < M; ++j) {\n                ss << \"\\nLevel \" << j;\n                for (const auto i: f_u_mult[j]) ss << \", \" << i;\n            }\n            LOG4_FILE(\"cvmd_f_u_mult.txt\", ss.str().c_str());\n        }\n        {\n            std::stringstream ss;\n            for (size_t j = 0; j < M; ++j) {\n                ss << \"\\nLevel \" << j;\n                for (const auto i: f_v_mult[j]) ss << \", \" << i;\n            }\n            LOG4_FILE(\"cvmd_f_v_mult.txt\", ss.str().c_str());\n        }\n        {\n            std::stringstream ss;\n            for (const auto i: B_matrix_val) ss << \", \" << i;\n            LOG4_FILE(\"cvmd_B_matrix_val.txt\", ss.str().c_str());\n        }\n        {\n            std::stringstream ss;\n            for (const auto i: B_matrix_i) ss << \", \" << i;\n            LOG4_FILE(\"cvmd_B_matrix_i.txt\", ss.str().c_str());\n        }\n        {\n            std::stringstream ss;\n            for (const auto i: B_matrix_j) ss << \", \" << i;\n            LOG4_FILE(\"cvmd_B_matrix_j.txt\", ss.str().c_str());\n        }\n#endif\n        double object0=object_compute( N, levels_half, f_u_mult,f_v_mult, test_sol.data(),f_lambda.data(), use_left, left_u_values, left_v_values);\n        std::cout << \"object0\" << object0<<std::endl;\n\n\n        //how to multiply as x' * P  * x + q*x\n\n        double object1=0;\n        std::vector<double> p_times_x(total_number,0.);\n        for(size_t i=0;i<total_number;i++){\n            for(int elem_ptr = P_p[i];elem_ptr < P_p[i+1];elem_ptr++){\n                double val_elem = P_x[elem_ptr];\n                int    row_elem = P_i[elem_ptr];\n                if (row_elem > (int) i) throw std::runtime_error(svr::common::formatter() << \"row_elem > i\" << row_elem << \" > \" << i);\n                double product = val_elem * test_sol [i];\n\n                if (row_elem < (int) i){\n                    p_times_x [row_elem] += product;\n                    product = val_elem * test_sol[row_elem];\n                    p_times_x [i] += product;\n                }else{\n                    p_times_x [row_elem] += product;\n                }\n            }\n        }\n        for(int i=0;i<(int) total_number;i++){\n            object1+= test_sol[i]*  p_times_x [i];\n        }\n        if (use_left){\n            //double s0=0.;\n            for(size_t i=0;i<total_number;i++){\n                //int timestep = (i / 2 ) % N  ; //which timestep. In reality if timestep is >=1, the q_vector is 0\n                //int u_or_v =  i  % 2;\n                int level = (i / 2) / N ;\n\n                object1+= test_sol[i]* q_vector[i]*f_lambda[level]*2;//be careful - this had to be multiplied by 2. to make object0 and object1 equal.\n            }\n            for(size_t i=0;i<levels_half;i++){\n                object1+=pow(left_u_values[i],2)*f_lambda[i];\n                object1+=pow(left_v_values[i],2)*f_lambda[i];\n            }\n        }\n        std::cout << \"object1 must be the same as object0 - this is just to see the matrix is right\"<<std::endl;\n        std::cout << \"object1\" << object1<<std::endl;\n        if (fabs(object1-object0) > 0.00000001)\n            throw std::runtime_error(svr::common::formatter() <<\n                    \"Object1 must be the same as object0 - this is just to see the matrix is right object1 \" <<\n                    object1 << \" object0 \" << object0);\n#if 0\n        for(int i=0;i<total_number;i++){\n            int timestep = (i / 2 ) % N  ;\n            int u_or_v =  i  % 2;\n            int level = (i / 2) / N ;\n            if (u_or_v ==0) {\n                test_sol[i]=x_series[timestep]/levels_half;\n            }else{\n                test_sol[i]=1.;//just for the test, !=0\n            }\n        }\n        //multiply by A\n        std::vector<double> a_times_x(num_equations,0.);\n        for(int i=0;i<total_number;i++){\n            for(int elem_ptr = A_p[i];elem_ptr < A_p[i+1];elem_ptr++){\n                double val_elem = A_x[elem_ptr];\n                int    row_elem = A_i[elem_ptr];\n                double product = val_elem * test_sol [i];\n                a_times_x [row_elem] += product;\n            }\n        }\n#endif // 0\n    }\n#endif // DEBUG_CVMD\n\n#ifdef USE_CUDA\n    csc *P = nullptr, *A = nullptr;\n    //bool cleanup_solver = false;\n    if (p_solver == nullptr or prev_decon.empty()) {\n    //    cleanup_solver = true;\n\n        /* Workspace, p_settings, matrices */\n        P = (csc *) malloc(sizeof(csc));\n        A = (csc *) malloc(sizeof(csc));\n\n        /* Populate matrices */\n        csc_set_data(A, N, n, A_nnz, A_x_vector.data(), A_i_vector.data(), A_p_vector.data());\n        csc_set_data(P, n, n, C_matrix_val.size(), C_matrix_val.data(), C_matrix_i.data(), C_matrix_j.data());\n\n        if (not p_settings) LOG4_THROW(\"OSQP settings not initialized.\");\n        /* Setup workspace */\n        if (p_solver) osqp_cleanup(p_solver);\n        const auto osqp_err = osqp_setup(&p_solver, P, q_vector.data(), A, lo_vector.data(), up_vector.data(), N, n, p_settings);\n        if (osqp_err) THROW_EX_FS(std::runtime_error, \"OSQP setup terminated with error \" << osqp_err);\n    } else if (not prev_decon.empty()) {\n        osqp_update_P_A(p_solver, C_matrix_val.data(), C_matrix_i.data(), C_matrix_val.size(), A_x_vector.data(), A_i_vector.data(), A_x_vector.size());\n        osqp_update_lin_cost(p_solver, q_vector.data());\n        osqp_update_bounds(p_solver, lo_vector.data(), up_vector.data());\n        //if (found_freqs.last_y.empty()) LOG4_WARN(\"Last Y is empty!\");\n        osqp_warm_start(p_solver, prev_decon.data(), found_freqs.last_y.empty() ? OSQP_NULL : found_freqs.last_y.data());\n    }\n\n/* TODO - 1/2. not implemented - careful if adding q */\n    /* Solve Problem */\n    //PROFILE_EXEC_TIME(osqp_solve(p_solver), \"osqp_solve of size \" << C_matrix_val.size() << \" \" << A_x_vector.size());\n    osqp_solve(p_solver);\n\n    c_float *real_solution = p_solver->solution->x;\n    if (decon.size() != N) decon.resize(N);\n    //we write inside of it\n    for (size_t t = 0; t < N; ++t) { // timestep\n        if (t == N - 1 or prev_decon.empty()) {\n            decon[t].resize(levels);\n            cilk_for (size_t l = 0; l < levels_half; ++l) {\n                decon[t][2 * l] = real_solution[2 * t + 0 + 2 * l * N];\n                decon[t][2 * l + 1] = real_solution[2 * t + 1 + 2 * l * N];\n            }\n        }\n    }\n\n#ifdef FAST_CVMD\n    if (not prev_decon.empty() or N > 1) {\n        if (found_freqs.last_y.size() != levels) found_freqs.last_y.resize(levels);\n        //BOOST_ASSERT(sizeof(double) == sizeof(c_float));\n        memcpy(found_freqs.last_y.data(), p_solver->solution->y + 2 * (N - 1) * levels, found_freqs.last_y.size() * sizeof(double));\n    }\n\n/* Clean workspace */\n    if (prev_decon.empty())\n#endif\n    {\n        osqp_cleanup(p_solver);\n        p_solver = nullptr;\n    }\n    if (A) {\n        free(A);\n        free(P);\n    }\n#else // Do it on CPU // TODO Fix build and test!\n    // Workspace structures\n    OSQPWorkspace *work = nullptr;\n    auto p_settings = (OSQPSettings *)c_malloc(sizeof(OSQPSettings));\n    auto data     = (OSQPData *)c_malloc(sizeof(OSQPData));\n\n    // Populate data\n    if (data) {\n        data->n = n;\n        data->m = m;\n        data->P = csc_matrix(data->n, data->n, P_nnz, P_x, P_i, P_p);\n        data->q = q;\n        data->A = csc_matrix(data->m, data->n, A_nnz, A_x, A_i, A_p);\n        data->l = lo;\n        data->u = up;\n    }\n\n    // Define solver p_settings as default\n    if (p_settings) {\n        osqp_set_default_settings(p_settings);\n#ifdef DEBUG_CVMD\n        p_settings->verbose = 1;\n#else\n        p_settings->verbose = 0;\n#endif\n        p_settings->polish = 0;\n        p_settings->max_iter = 4000;\n        p_settings->eps_abs = 1.0e-05;\n        p_settings->eps_rel = 1.0e-05;\n        p_settings->alpha=0.6;\n        p_settings->eps_prim_inf = 1.0e-06;\n        p_settings->eps_dual_inf = 1.0e-06;\n    }\n\n    // Setup workspace\n    exitflag = osqp_setup(&work, data, p_settings);\n    if (exitflag) throw std::runtime_error(svr::common::formatter() << \"OSQP terminated with error \" << exitflag);\n    // Solve Problem\n    osqp_solve(work);\n    OSQPSolution *sol = work->solution;\n    c_float *real_solution = sol->x;\n\n    sol_u_series.resize(levels_half);\n    sol_v_series.resize(levels_half);\n    //we write inside of it\n    cilk_for (size_t i = 0; i < levels_half; ++i){\n        sol_u_series[i].resize(N);\n        sol_v_series[i].resize(N);\n        cilk_for (size_t j=0;j<N;++j) {//timestep\n            if (j == N-1 || !use_left){\n                sol_u_series[i][j] = real_solution[2 * j + 0 + 2 * i * N];\n                sol_v_series[i][j] = real_solution[2 * j + 1 + 2 * i * N];\n            }\n        }\n    }\n\n    // Cleanup\n    if (data) {\n        if (data->A) c_free(data->A);\n        if (data->P) c_free(data->P);\n        c_free(data);\n    }\n    if (p_settings) c_free(p_settings);\n#endif // USE_CUDA\n}\n\nbool cvmd::initialized(const std::string &decon_queue_table_name)\n{\n    const auto freq_key = freq_key_t(decon_queue_table_name, levels);\n    return not vmd_frequencies.empty() and vmd_frequencies.find(freq_key) != vmd_frequencies.end();\n}\n\n#define SOLVER_FILE_NAME SAVE_OUTPUT_LOCATION << \"/\" << std::get<0>(f.first) << \"_solver.state\"\n\nvoid cvmd::load_solvers_file()\n{\n#if 0\n    for (const auto &f: vmd_frequencies)\n        osqp_load_solver(f.second.p_solver, std::string{svr::common::formatter() << SOLVER_FILE_NAME}.c_str());\n#endif\n}\n\nvoid cvmd::initialize(const std::vector<double> &input, const std::string &decon_queue_table_name, const bool load_solvers)\n{\n    LOG4_DEBUG(\"Initializing omega on \" << input.size() << \" rows, for \" << levels << \" levels, \" << decon_queue_table_name << \" table.\");\n    const auto freq_key = freq_key_t(decon_queue_table_name, levels);\n    static std::mutex mx;\n    if (vmd_frequencies.empty() or vmd_frequencies.find(freq_key) == vmd_frequencies.end()) {\n        const auto freqs = calculate_vmd_frequencies(input, levels / 2);\n        const std::lock_guard<std::mutex> lg(mx);\n        vmd_frequencies[freq_key] = freqs;\n    }\n    if (load_solvers) load_solvers_file();\n}\n\nvoid cvmd::uninitialize(const bool save)\n{\n#if 0\n    if (save)\n        for (const auto &f: vmd_frequencies)\n            osqp_save_solver(f.second.p_solver, std::string{svr::common::formatter() << SOLVER_FILE_NAME}.c_str());\n#endif\n\n    vmd_frequencies.clear();\n}\n\nvoid cvmd::transform(\n        const std::vector<double> &input,\n        std::vector<std::vector<double>> &decon,\n        const size_t padding = 0)\n{\n    THROW_EX_FS(std::logic_error, \"Not implemented!\");\n}\n\n// Online VMD transform\nvoid cvmd::transform(\n        const std::vector<double> &input,\n        std::vector<std::vector<double>> &decon,\n        const std::string &decon_queue_table_name,\n        const std::vector<double> &prev_decon,\n        std::vector<std::vector<double>> &phase_series,\n        const std::vector<double> &start_phase)\n{\n    if (vmd_frequencies.empty()) LOG4_THROW(\"VMD frequencies empty!\");\n    const auto found_freqs = vmd_frequencies.find(freq_key_t(decon_queue_table_name, levels));\n    if (found_freqs == vmd_frequencies.end())\n        LOG4_THROW(\"VMD frequencies not found!\");\n    const size_t levels_half = levels / 2;\n    if (start_phase.size() != levels_half)\n        LOG4_THROW(\"Phase start size is not correct \" << start_phase.size());\n\n    const size_t T = input.size();\n    LOG4_DEBUG(\"Online input size \" << T << \", levels count \" << levels_half);\n\n    const auto &omega = found_freqs->second.omega;\n    if (phase_series.size() != T + 1) phase_series.resize(T + 1);\n    cilk_for (size_t t = 1; t < T + 1; ++t) {\n        phase_series[t].resize(levels_half);\n    };\n    phase_series[0] = start_phase; // This is correct with the current setup and not: + omega[l] * 2. * M_PI;\n    cilk_for (size_t l = 0; l < levels_half; ++l) {\n        for (size_t t = 1; t < T + 1; ++t) {\n            phase_series[t][l] = phase_series[t - 1][l] + omega[l] * 2. * M_PI;\n        }\n    };\n\n#ifdef FASTCVMD\n    const OSQPSettings *p_osqp_settings = nullptr;\n#else\n    svr::common::gpu_context gtx;\n    const OSQPSettings *p_osqp_settings = init_osqp_settings(gtx);\n#endif\n    OSQPSolver *p_solver = nullptr;\n    if (not decon.empty()) decon.clear();\n    std::vector<std::vector<double>> decon_slice(1, std::vector<double>(levels));\n    do_problem(\n            p_solver /* found_freqs->second.p_solver */, p_osqp_settings,\n            levels_half, {phase_series[0], phase_series[1]}, {input[0]}, 1,\n            decon_slice, found_freqs->second, prev_decon);\n    decon.emplace_back(decon_slice[0]);\n    for (size_t t = 1; t < T; ++t) {\n        do_problem(\n                p_solver /* found_freqs->second.p_solver */, p_osqp_settings,\n                levels_half, {phase_series[t], phase_series[t + 1]}, {input[t]}, 1,\n                decon_slice, found_freqs->second, decon[t - 1]);\n        decon.emplace_back(decon_slice[0]);\n    }\n    osqp_cleanup(p_solver);\n\n#if 0\n    {\n        static size_t call_ct;\n        std::stringstream ss;\n        std::stringstream ss_file_name;\n        ss_file_name << \"cvmd_decon_online_\" << call_ct++ << \".csv\";\n        for (size_t i = 0; i < decon.size(); ++i) { // i = timesteps\n            for (size_t j = 0; j < decon[i].size(); ++j) // j = levels\n                ss << \", \" << decon[i][j];\n            ss << std::endl;\n        }\n        LOG4_FILE(ss_file_name.str().c_str(), ss.str().c_str());\n    }\n#endif\n    if (p_osqp_settings) free((void *) p_osqp_settings);\n}\n\n#ifdef SAVE_DECON\n\nsize_t\nload_decon(\n        std::vector<std::vector<double>> &decon,\n        std::vector<std::vector<double>> &phase_series,\n        const std::string &table_name,\n        const size_t levels_half)\n{\n    std::ifstream ifs(common::formatter() << SAVE_OUTPUT_LOCATION << table_name << \"_decon_values_phases.tsv\");\n    if (ifs.fail()) return 0;\n    LOG4_DEBUG(\"Loading \" << levels_half << \" levels of data for decon queue \" << table_name << \" from file.\");\n    std::string line;\n    size_t t = 0;\n    phase_series.clear();\n    decon.clear();\n    while (std::getline(ifs, line))\n    {\n        std::vector<std::string> row_values;\n        common::split(line, '\\t', row_values);\n        if (row_values.size() < 3 * levels_half) continue;\n        size_t col_ix =  0;\n        decon.emplace_back(std::vector<double>(levels_half * 2));\n        phase_series.emplace_back(std::vector<double>(levels_half));\n        try {\n            for (size_t l = 0; l < levels_half * 2; ++l)\n                decon.back()[l] = stold(row_values[col_ix++]);\n            for (size_t l = 0; l < levels_half; ++l)\n                phase_series.back()[l] = stold(row_values[col_ix++]);\n        } catch (const std::exception &ex) {\n            LOG4_ERROR(\"Failed parsing \" << row_values[--col_ix] << \" last good row \" << t);\n        }\n        ++t;\n    }\n    LOG4_DEBUG(\"Loaded \" << t << \" values\");\n    return t;\n}\n\n#endif\n\n#define MAX_GPU_SIZE 65536\n\n// Batch transform\nvoid cvmd::transform(\n        const std::vector<double> &input,\n        std::vector<std::vector<double>> &decon,\n        const std::string &table_name,\n        std::vector<std::vector<double>> &phase_series,\n        const size_t count_from_start)\n{\n    if (vmd_frequencies.empty()) THROW_EX_FS(std::runtime_error, \"Empty VMD frequencies!\");\n\n    const auto T = input.size();\n    const size_t levels_half = levels / 2;\n    const size_t R = get_residuals_length(\"__DUMMY__\") > MAX_GPU_SIZE ? MAX_GPU_SIZE : get_residuals_length(\"__DUMMY__\"); // Limit imposed by GPU RAM\n\n    if (T < R) THROW_EX_FS(std::invalid_argument, \"Input size \" << T << \" must contain at least \" << R << \" rows.\");\n\n    const auto found_freqs = vmd_frequencies.find({table_name, levels});\n    if (found_freqs == vmd_frequencies.end())\n        THROW_EX_FS(std::runtime_error, \"VMD frequencies not found!\");\n\n    const auto &omega = found_freqs->second.omega;\n\n    LOG4_DEBUG(\"Input size \" << T << \", levels count \" << levels_half << \", residuals length \" << R << \" count from start \" << count_from_start << \", omega \" << omega);\n\n#ifndef USE_CUDA\n    const auto &decomposition_u_series = vmd_frequencies[freq_key].u;\n#endif\n\n    // levels should be organized\n    // u 0\n    // v 0\n    // u 1\n    // v 1\n    // 32 levels for 16 frequencies\n\n    // Now do it batch and then online, by first computing without left values for half of the time and then continue with online\n    svr::common::gpu_context gtx;\n    auto p_osqp_settings = init_osqp_settings(gtx);\n\n#ifdef SAVE_DECON\n    auto loaded_decon = load_decon(decon, phase_series, table_name, levels_half);\n    if (loaded_decon > T) {\n        LOG4_ERROR(\"Loaded decon \" << loaded_decon << \" is larger than expected \" << T << \", discarding loaded values.\");\n\n        decon.clear();\n        phase_series.clear();\n        loaded_decon = 0;\n    }\n#else\n    size_t loaded_decon = 0;\n#endif\n\n    if (loaded_decon < 1 or phase_series.size() != T + 1 or phase_series[0].size() != levels_half) {\n        LOG4_DEBUG(\"Initializing phase series of length \" << T + 1 << \", half levels \" << levels_half);\n\n        std::vector<double> phase_start(levels_half, 0.);\n        size_t t_phase_start = 0;\n        if (phase_series.size() > 0 and phase_series[0].size() == levels_half) {\n            LOG4_DEBUG(\"Taking loaded phase series start.\");\n            t_phase_start = phase_series.size();\n            for (size_t l = 0; l < levels_half; ++l) phase_start[l] = phase_series[t_phase_start - 1][l];\n        } else if (count_from_start) {\n            cilk_for (size_t l = 0; l < levels_half; ++l) {\n                for (size_t t = 0; t < count_from_start; ++t) {\n                    phase_start[l] += omega[l] * 2. * M_PI;\n                }\n            }\n        }\n\n        if (phase_series.size() != T + 1) phase_series.resize(T + 1);\n        // u_series will be initialized, v_series - not!\n        cilk_for(size_t t = t_phase_start; t < phase_series.size(); ++t) {\n            phase_series[t].resize(levels_half);\n        }\n        cilk_for (size_t l = 0; l < levels_half; ++l) {\n            phase_series[t_phase_start][l] = phase_start[l] + omega(l, 0) * 2. * M_PI;\n        }\n\n        cilk_for (size_t l = 0; l < levels_half;  ++l) {\n            for (size_t t = t_phase_start + 1; t < phase_series.size(); ++t) {\n                phase_series[t][l] = phase_series[t - 1][l] + omega(l, 0) * 2. * M_PI;\n            }\n        };\n    }\n#ifdef SAVE_DECON\n    if (loaded_decon) goto __loaded_decon;\n#endif\n\n#ifdef USE_CUDA\n    PROFILE_EXEC_TIME(do_problem(\n            found_freqs->second.p_solver, p_osqp_settings, levels_half, phase_series, input, R, decon, found_freqs->second),\n                    \"Tail transform of \" << levels << \" levels\");\n#else // USE_CUDA\n    // since CPU osqp does not work for the matrix that appears in B, we have to simply use the matlab result and continue from there\n    // there is some danger when N is even to have some slight miss, should be checked.\n    cilk_for (size_t l = 0; l < levels_half; ++l) {\n        cilk_for (size_t t = 0; t < T; ++t) {\n            sol_u_series[l][t] = decomposition_u_series[t + levels_half * l]; // u_series[i][j];\n            sol_v_series[l][t] = 0.; // should be v_series[i][j] somehow, but because the way matlab code is done, v_series comes out as 0, so we can't do anything different here.\n        }\n    }\n    // let's make sure the sum is exactly right, not approximately.\n    cilk_for (size_t t = 0; t < R; ++t) {\n        cilk::reducer_opadd<double> u_sum{0.};\n        cilk_for (size_t l = 0; l < levels_half; ++l) {\n            u_sum += sol_u_series[l][t];\n        }\n        cilk_for (size_t l = 0; l < levels_half; ++l) {\n            sol_u_series[l][t] = sol_u_series[l][t] * input[t] / u_sum.get_value();\n        }\n    }\n    // the first 1000 2000 after this part should be skipped for training, some time is needed for the decomposition\n    // to adjust itself.\n#endif // USE_CUDA\n\n#ifdef SAVE_DECON\n__loaded_decon:\n    std::ofstream of;\n    of.open(common::formatter() << SAVE_OUTPUT_LOCATION << table_name << \"_decon_values_phases.tsv\",\n            std::ofstream::out | std::ofstream::app);\n    of.precision(std::numeric_limits<double>::max_digits10);\n    if (loaded_decon < 1) {\n        for (size_t t = 0; t < R; ++t) {\n            for (size_t l = 0; l < levels; ++l) of << decon[t][l] << \"\\t\";\n            for (size_t l = 0; l < levels_half; ++l) of << phase_series[t][l] << \"\\t\";\n            of << std::endl;\n        }\n    }\n#endif\n\n    // Now do online VMD\n    std::vector<std::vector<double>> decon_slice(1, std::vector<double>(levels));\n    for (size_t t = R > loaded_decon ? R : loaded_decon; t < T; ++t) {\n        LOG4_TRACE(\"Doing problem \" << t << \" values \" << input[t] << \" phases \" << svr::common::deep_to_string(phase_series[t+1]));\n        do_problem(\n                found_freqs->second.p_solver, p_osqp_settings,\n                levels_half, {phase_series[t], phase_series[t + 1]}, {input[t]}, 1,\n                decon_slice, found_freqs->second, decon.back());\n        decon.emplace_back(decon_slice[0]);\n#ifdef SAVE_DECON\n        for (size_t l = 0; l < levels; ++l) of << decon[t][l] << \"\\t\";\n        for (size_t l = 0; l < levels_half; ++l) of << phase_series[t][l] << \"\\t\";\n        of << std::endl;\n#endif\n    }\n#ifdef SAVE_DECON\n    of.flush();\n    of.close();\n#endif\n\n#if 0 // DEBUG\n    {\n        static size_t call_ct;\n        std::stringstream ss;\n        std::stringstream ss_file_name;\n        ss_file_name << \"cvmd_decon_batch_\" << call_ct++ << \".csv\";\n        for (size_t i = 0; i < decon.size(); ++i) { // i = timesteps\n            for (size_t j = 0; j < decon[i].size(); ++j) // j = levels\n                ss << \", \" << decon[i][j];\n            ss << std::endl;\n        }\n        LOG4_FILE(ss_file_name.str().c_str(), ss.str().c_str());\n    }\n#endif\n    free(p_osqp_settings);\n}\n\nvoid\ncvmd::inverse_transform(\n        const std::vector<double> &decon,\n        std::vector<double> &recon,\n        const size_t padding) const\n{\n    const size_t input_size = decon.size() / levels;\n    recon = std::vector<double>(input_size, 0.);\n    PFOR(t, 0, input_size,\n        recon[t] = 0;\n        for (size_t l = 0; l < levels / 2; ++l) recon[t] += decon[t + 2 * l * input_size];\n        recon[t] = recon[t] / CVMD_INPUT_MULTIPLIER;\n    )\n}\n\nsize_t cvmd::get_residuals_length(const std::string &decon_queue_table_name)\n{\n    LOG4_DEBUG(\"Getting residuals length for \" << decon_queue_table_name << \" \" << levels << \" levels.\");\n    const auto freq_key = freq_key_t(decon_queue_table_name, levels);\n    const auto vmd_freq_iter = vmd_frequencies.find(freq_key);\n    if (vmd_freq_iter != vmd_frequencies.end()) return 0; // Already initialized, in online mode we have no tail length\n    else {\n        size_t res_len = std::pow(levels / 2, 4);\n        if (res_len % 2) ++res_len;\n        return res_len;\n    }\n}\n\n// TODO Test\nstd::vector<double> cvmd::calculate_phases(const size_t count_from_start, const std::string &decon_queue_table_name) const\n{\n    LOG4_INFO(\"Recalculating phases for \" << decon_queue_table_name << \", starting \" << count_from_start << \", levels \" << levels);\n\n    const auto freq_key = freq_key_t(decon_queue_table_name, levels);\n    const auto vmd_freq_iter = vmd_frequencies.find(freq_key);\n\n    if (vmd_freq_iter == vmd_frequencies.end()) LOG4_THROW(\"Decon queue \" << decon_queue_table_name << \" levels \" << levels << \" omega not found.\");\n\n    const auto omega = vmd_freq_iter->second.omega;\n    std::vector<double> phase_start(levels / 2, 0.);\n    cilk_for(size_t l = 0; l < levels / 2; ++l) {\n        for (size_t t = 0; t < count_from_start; ++t) {\n            phase_start[l] += omega[l] * 2. * M_PI;\n        }\n    }\n\n    LOG4_DEBUG(\"Returning \" << svr::common::deep_to_string(phase_start));\n    return phase_start;\n}\n\n\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- SVRRoot/OnlineSVR/src/cvmd.cpp	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ SVRRoot/OnlineSVR/src/cvmd.cpp	(date 1672558644783)
@@ -15,10 +15,6 @@
 #include "common/Logging.hpp"
 #include "common/gpu_handler.h"
 
-#ifdef NEW_FAST_CVMD
-#include "fast_cvmd.hpp"
-#endif
-
 #ifdef DEBUG_CVMD
 #undef cilk_for
 #define cilk_for for
Index: SVRRoot/SVRBusiness/src/InputQueueService.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#include <future>\n\n#include <appcontext.hpp>\n\n#include <DAO/InputQueueDAO.hpp>\n#include <util/ValidationUtils.hpp>\n#include <DAO/ScopedTransaction.hpp>\n\n#include <BidAskSpread.hpp>\n#include <InterprocessReader.hpp>\n#include <online_emd.hpp>\n#include <cvmd.hpp>\n#include <short_term_fourier_transform.hpp>\n\nusing namespace std;\nusing namespace bpt;\nusing namespace svr::common;\nusing namespace svr::datamodel;\n\nnamespace svr {\nnamespace business {\n\nInputQueueService::InputQueueService(svr::dao::InputQueueDAO &input_queue_dao)\n        : input_queue_dao(input_queue_dao)\n{}\n\nInputQueueService::~InputQueueService()\n{}\n\nInputQueue_ptr\nInputQueueService::get_queue_metadata(\n        const string &user_name,\n        const string &logical_name,\n        const time_duration &resolution)\n{\n    return input_queue_dao.get_queue_metadata(user_name, logical_name, resolution);\n}\n\nInputQueue_ptr\nInputQueueService::get_queue_metadata(const string &input_queue_table_name)\n{\n    return input_queue_dao.get_queue_metadata(input_queue_table_name);\n}\n\nsvr::datamodel::DataRow::container InputQueueService::get_queue_data(\n        const string &table_name,\n        const ptime &time_from,\n        const ptime &time_to,\n        size_t limit)\n{\n    PROFILE_EXEC_TIME(\n            return input_queue_dao.get_queue_data_by_table_name(table_name, time_from, time_to, limit),\n            \"Getting queue data from DAO\");\n}\n\nsize_t\nInputQueueService::get_count_from_start(const InputQueue_ptr &p_input_queue, const boost::posix_time::ptime &time)\n{\n    return input_queue_dao.get_count_from_start(p_input_queue->get_table_name(), time);\n}\n\ndata_row_container\nInputQueueService::get_latest_queue_data_from_mmf(\n        InputQueue_ptr const &input_queue,\n        const bpt::ptime &last_time)\n{\n    data_row_container result;\n#ifndef BUILD_WITHOUT_SVR_FIX\n    if (not input_queue->get_uses_fix_connection()) return result;\n\n    svr::fix::mm_file_reader::bid_ask_spread_container values;\n\n    try {\n        svr::fix::mm_file_reader reader(input_queue->get_logical_name());\n        values = reader.read_new(last_time);\n    }\n    catch (std::runtime_error const &) {\n        return result;\n    }\n    catch (boost::interprocess::interprocess_exception &) {\n        return result;\n    }\n\n    if (last_time < values.front().time - input_queue->get_resolution())\n        return result;\n\n    for (const auto &bas :values)\n        result.push_back(std::make_shared<svr::datamodel::DataRow>(bas.time, bas.time, 0,\n                                                                   std::vector<double>{bas.ask_px, double(bas.ask_qty), bas.bid_px,\n                                                                    double(bas.bid_qty)}, std::vector<double>{}));\n#endif //BUILD_WITHOUT_SVR_FIX\n    return result;\n}\n\n\ndata_row_container\nInputQueueService::get_latest_queue_data(\n        InputQueue_ptr const &input_queue,\n        const size_t limit,\n        const bpt::ptime &last_time)\n{\n    // TODO: This method takes last_time inclusively, and the specification for that is not clear.\n    // Because of that, callers that want to exclude this last time must make sure to subtract a small amount of time from that parameter.\n    LOG4_DEBUG(\"Getting \" << limit << \" rows until \" << last_time << \" from \" << input_queue->get_table_name());\n\n    auto result = get_latest_queue_data_from_mmf(input_queue, last_time);\n\n    if (!result.empty()) goto __bail;\n\n    result = input_queue_dao.get_latest_queue_data_by_table_name(input_queue->get_table_name(), limit, last_time);\n\n    __bail:\n    LOG4_DEBUG(\"Got \" << result.size() << \" rows successfully.\");\n    return result;\n}\n\nDataRow_ptr\nInputQueueService::get_nth_last_row(const InputQueue_ptr &input_queue, const size_t position, const bpt::ptime target_time)\n{\n    LOG4_DEBUG(\"Getting \" << position << \"th row before \" << target_time << \" from \" << input_queue->get_table_name());\n    return input_queue_dao.get_nth_last_row(input_queue->get_table_name(), position, target_time);\n}\n\ndata_row_container\nInputQueueService::get_queue_data(\n        const InputQueue_ptr &p_input_queue,\n        const size_t tail_length,\n        const bpt::time_period &range)\n{\n    // TODO: This method takes last_time inclusively, and the specification for that is not clear.\n    // Because of that, callers that want to exclude this last time must make sure to subtract a small amount of time from that parameter.\n    LOG4_DEBUG(\"Getting \" << tail_length << \" rows during \" << range << \" from \" << p_input_queue->get_table_name());\n\n    data_row_container data, result = get_latest_queue_data_from_mmf(p_input_queue, range.begin());\n// TODO update for MMF\n    if (not result.empty()) goto __bail;\n    result = input_queue_dao.get_latest_queue_data_by_table_name(p_input_queue->get_table_name(), tail_length, range.begin());\n    if (!result.empty() and result.back()->get_value_time() == range.begin()) result.pop_back();\n    // Get range between last train and most current data\n    data = input_queue_dao.get_queue_data_by_table_name(p_input_queue->get_table_name(), range.begin(), range.end());\n    result.insert(result.end(), data.begin(), data.end());\n\n    __bail:\n    LOG4_DEBUG(\"Got \" << result.size() << \" rows successfully, starting \" << result.front()->get_value_time() << \" until \" << result.back()->get_value_time());\n    return result;\n}\n\nlong InputQueueService::save(const InputQueue_ptr &p_input_queue)\n{\n    return input_queue_dao.save(p_input_queue);\n}\n\n\nbool InputQueueService::exists(\n        const std::string &user_name,\n        const std::string &logical_name,\n        const bpt::time_duration &resolution)\n{\n    return input_queue_dao.exists(user_name, logical_name, resolution);\n}\n\n\nint InputQueueService::remove(const InputQueue_ptr &p_input_queue)\n{\n    reject_nullptr(p_input_queue);\n    return input_queue_dao.remove(p_input_queue);\n}\n\nint InputQueueService::clear(const InputQueue_ptr &p_input_queue)\n{\n    reject_nullptr(p_input_queue);\n    return input_queue_dao.clear(p_input_queue);\n}\n\n\n/* TODO Optimize! */\nbpt::ptime InputQueueService::adjust_time_on_grid(\n        const InputQueue_ptr &p_input_queue,\n        const bpt::ptime &value_time)\n{\n    ptime epoch = from_time_t(0);\n    time_duration duration_since_epoch = value_time - epoch;\n\n    // check whether value_time may be present in two different timegrid slots\n    // Hint: this can(should) be caught on object construction time.\n    if (p_input_queue->get_resolution().total_seconds() / 2\n        < p_input_queue->get_legal_time_deviation().total_seconds()) {\n        throw invalid_argument(\n                \"Invalid Resolution/Legal time deviation arguments!\"\n                        \"Cannot calculate time on grid because value_time may be valid on two different timegrid slots!\");\n    }\n\n    long seconds_on_grid_since_epoch = 0;\n\n    // check if the value_time can fit on the previous time grid slot\n    if ((duration_since_epoch.total_seconds() % p_input_queue->get_resolution().total_seconds())\n        <= p_input_queue->get_legal_time_deviation().total_seconds()) {\n        seconds_on_grid_since_epoch = duration_since_epoch.total_seconds()\n                                      - (duration_since_epoch.total_seconds() %\n                                         p_input_queue->get_resolution().total_seconds());\n        // else check if the value_time can fit on the next timegrid slot\n    } else if (((\n                        seconds_on_grid_since_epoch =\n                                duration_since_epoch.total_seconds() +\n                                p_input_queue->get_legal_time_deviation().total_seconds()\n                ) % p_input_queue->get_resolution().total_seconds())\n               < p_input_queue->get_legal_time_deviation().total_seconds()) {\n        seconds_on_grid_since_epoch -= seconds_on_grid_since_epoch\n                                       % p_input_queue->get_resolution().total_seconds();\n    } else\n        return not_a_date_time;\n\n    return from_time_t(0) + seconds(seconds_on_grid_since_epoch);\n}\n\n\nbool\nInputQueueService::add_row(\n        InputQueue_ptr &p_input_queue,\n        DataRow_ptr p_row,\n        bool concatenate)\n{\n    reject_nullptr(p_input_queue);\n    reject_nullptr(p_row);\n\n    const auto adjusted_value_time = adjust_time_on_grid(p_input_queue, p_row->get_value_time());\n    if (adjusted_value_time == not_a_date_time) {\n        LOG4_DEBUG(\"The following row doesn't fit in the queue: \" << p_row->to_string());\n        return false;\n    }\n\n    if (p_row->get_value_time() != adjusted_value_time) p_row->set_value_time(adjusted_value_time);\n\n    auto &data = p_input_queue->get_data();\n    if (data.back()->get_value_time() <= adjusted_value_time)\n        data.erase(lower_bound(data, adjusted_value_time), data.end());\n    data.push_back(p_row);\n    return true;\n}\n\n\nInputQueue_ptr\nInputQueueService::clone_with_data(\n        const InputQueue_ptr &p_input_queue,\n        const time_period &time_range,\n        const size_t minimum_rows_count)\n{\n    auto result_queue = p_input_queue->clone_empty(); // TODO Why do we clone empty when we clone with data?\n    result_queue->set_data(input_queue_dao.get_queue_data_by_table_name(\n            p_input_queue->get_table_name(), time_range.begin(), time_range.end()));\n\n    if (result_queue->get_data().size() < minimum_rows_count)\n        THROW_EX_FS(insufficient_data,\n                \"Not enough data in inputQueue in time range \" << time_range << \" number of observations is lesser than \" << minimum_rows_count);\n\n    return result_queue;\n}\n\n\ndata_row_container\nInputQueueService::get_column_data(\n        const InputQueue_ptr &queue,\n        const string &column_name)\n{\n    LOG4_BEGIN();\n\n    DataRow::container &column_data = queue->get_data();\n    const size_t column_index = get_value_column_index(queue, column_name);\n    DataRow::container result;\n\n    if (column_data.empty()) {\n        LOG4_ERROR(\"Column data is empty. Aborting.\");\n        return result;\n    }\n\n    if (column_data.front()->get_values().size() <= column_index || column_index < 0) {\n        LOG4_ERROR(\"Column index out of bounds \" << column_index << \", columns in input queue \" <<\n                                                 column_data.front()->get_values().size() << \". Aborting.\");\n        return result;\n    }\n\n    for (auto &row: column_data) {\n        if (!row) {\n            LOG4_ERROR(\"Invalid row. Skipping.\");\n            continue;\n        }\n        result.push_back(std::make_shared<DataRow>(\n                DataRow(row->get_value_time(),\n                        row->get_update_time(),\n                        row->get_tick_volume(),\n                        {row->get_values()[column_index]})));\n    }\n\n    LOG4_END();\n\n    return result;\n}\n\nstd::vector<std::string>\nInputQueueService::get_db_table_column_names(const InputQueue_ptr &queue)\n{\n    const auto db_all_columns = input_queue_dao.get_db_table_column_names(queue);\n\n    std::vector<std::string> result;\n\n    auto iut = std::find_if(db_all_columns.begin(), db_all_columns.end(), [](std::shared_ptr<std::string> const &col)\n    { return *col == \"tick_volume\"; });\n    if (iut == db_all_columns.end())\n        return result;\n\n    iut += 1;\n\n    result.reserve(std::distance(iut, db_all_columns.end()));\n\n    for (auto ir = result.begin(); iut != db_all_columns.end(); ++iut, ++ir)\n        result.push_back(**iut);\n\n    return result;\n}\n\n\nsize_t\nInputQueueService::get_value_column_index(\n        const InputQueue_ptr &p_input_queue,\n        const std::string &column_name)\n{\n    const auto &cols = p_input_queue->get_value_columns();\n    const auto pos = find(cols.begin(), cols.end(), column_name);\n    if (pos == cols.end())\n        THROW_EX_FS(std::invalid_argument, \"Column \" << column_name << \" is not part of input queue \" << p_input_queue->get_table_name());\n\n    return (size_t) std::abs(std::distance(cols.begin(), pos));\n}\n\n\nDataRow_ptr\nInputQueueService::find_oldest_record(const InputQueue_ptr &queue)\n{\n    reject_nullptr(queue);\n\n    return input_queue_dao.find_oldest_record(queue);\n}\n\nDataRow_ptr\nInputQueueService::find_newest_record(const InputQueue_ptr &queue)\n{\n    reject_nullptr(queue);\n\n    return input_queue_dao.find_newest_record(queue);\n}\n\n\nstd::vector<InputQueue_ptr>\nInputQueueService::get_all_user_queues(const std::string &user_name)\n{\n    return input_queue_dao.get_all_user_queues(user_name);\n}\n\n\nstd::vector<InputQueue_ptr> InputQueueService::get_all_queues_with_sign(const bool uses_fix_connector)\n{\n    return input_queue_dao.get_all_queues_with_sign(uses_fix_connector);\n}\n\n\nsize_t InputQueueService::save_data(const InputQueue_ptr &queue, const bpt::ptime &start_time)\n{\n    reject_nullptr(queue);\n    reject_empty(queue->get_data());\n\n    return input_queue_dao.save_data(queue, start_time);\n}\n\n\nsvr::dao::OptionalTimeRange\nInputQueueService::get_missing_hours(const InputQueue_ptr &queue, svr::dao::TimeRange const &fromRange) const\n{\n    return input_queue_dao.get_missing_hours(queue, fromRange);\n}\n\n\nvoid InputQueueService::purge_missing_hours(InputQueue_ptr const &queue)\n{\n    input_queue_dao.purge_missing_hours(queue);\n}\n\n\nboost::posix_time::ptime\nInputQueueService::compare_to_decon_queue(\n        const boost::posix_time::time_period &range,\n        const InputQueue_ptr &p_input_queue,\n        const DeconQueue_ptr &p_decon_queue)\n{\n    // boost::posix_time::max_date_time is don't decompose anything, min_date_time means decompose all data from the input queue\n    LOG4_BEGIN();\n    if (p_decon_queue->get_data().empty())\n        return boost::posix_time::min_date_time;\n\n    if (p_input_queue->is_tick_queue())\n        return p_input_queue->get_data().front()->get_value_time() > p_decon_queue->get_data().front()->get_value_time() or p_input_queue->get_data().rbegin()->get()->get_value_time() < p_decon_queue->get_data().rbegin()->get()->get_value_time() ? boost::posix_time::min_date_time : boost::posix_time::max_date_time;\n\n    if (std::find(p_input_queue->get_value_columns().begin(), p_input_queue->get_value_columns().begin(), p_decon_queue->get_input_queue_column_name()) == p_input_queue->get_value_columns().end()) {\n        LOG4_ERROR(\"Input queue column \" << p_decon_queue->get_input_queue_column_name().c_str() << \" is missing in \" << deep_to_string(p_input_queue->get_value_columns()));\n        return boost::posix_time::min_date_time;\n    }\n    for (auto p_input_row_iter = lower_bound(p_input_queue->get_data(), range.begin()); p_input_row_iter != p_input_queue->get_data().end(); ++p_input_row_iter)\n        if (find(p_decon_queue->get_data(), p_input_row_iter->get()->get_value_time()) == p_decon_queue->get_data().end()) {\n            LOG4_DEBUG(\"Input row at \" << p_input_row_iter->get()->get_value_time() << \" not found in decon queue \" << p_decon_queue->get_input_queue_table_name() << \" \" << p_decon_queue->get_input_queue_column_name());\n            return p_input_row_iter->get()->get_value_time();\n        }\n    LOG4_END();\n    return boost::posix_time::max_date_time;\n}\n\n\nvoid\nInputQueueService::prepare_queues(\n        Dataset_ptr &p_dataset,\n        const boost::posix_time::time_period &range,\n        const bool trim /* false */)\n{\n    LOG4_DEBUG(\"Preparing input queue \" << p_dataset->get_input_queue()->get_table_name() << \" for \" << range);\n    // Keep this here in front because of variable residuals count for VMD depending on time of call, add per table queries in the future\n#ifdef DEBUG_PREPARE\n    if (p_dataset->get_ensembles().empty()) LOG4_DEBUG(\"Dataset ensembles are empty!\");\n    for (auto &p_ensemble: p_dataset->get_ensembles())\n    {\n        static size_t call_counter;\n        std::stringstream ss;\n        using namespace svr::common;\n\t    LOG4_DEBUG(\"Decon queue \" << p_ensemble->get_decon_queue()->get_table_name() << \" rows count \" <<\n\t                p_ensemble->get_decon_queue()->get_data().size() << \".\");\n        ss <<\n           \"pre_decon_queue_\" << p_ensemble->get_decon_queue()->get_table_name() <<\n           \"_call_\" << call_counter++ << \".out\";\n        std::ofstream of(ss.str());\n        of.precision(std::numeric_limits<double>::max_digits10);\n        for (const auto &row: p_ensemble->get_decon_queue()->get_data()) {\n            of << row->get_value_time() << \", \";\n            for (const auto value: row.get()->get_values()) of << value << \", \";\n            if (row.get()->is_anchor()) of << \"anchor\";\n            of << \"\\n\";\n        }\n        of.flush();\n    }\n#endif\n    // First prepare input data\n    prepare_input_data(p_dataset, range);\n    bpt::ptime first_new_row_time = bpt::max_date_time;\n    std::mutex mx;\n    TPFOR(size_t, ix, 0, p_dataset->get_ensembles().size(),\n        const auto &p_ensemble = p_dataset->get_ensemble(ix); // Compare main queue only\n        const auto res = compare_to_decon_queue(range, p_dataset->get_input_queue(), p_ensemble->get_decon_queue());\n        std::lock_guard<std::mutex> l(mx);\n        if (res < first_new_row_time) first_new_row_time = res;\n    )\n    if (first_new_row_time == boost::posix_time::max_date_time) {\n        LOG4_DEBUG(\"Decon queues already have the latest data, bailing.\");\n        return;\n    }\n\n#ifdef DEBUG_PREPARE\n    {\n        static size_t call_counter;\n        std::stringstream ss;\n        using namespace svr::common;\n        ss <<\n           \"input_queue_\" << p_dataset->get_input_queue()->get_table_name() <<\n           \"_call_\" << call_counter++ << \".out\";\n        std::ofstream of(ss.str());\n        of.precision(std::numeric_limits<double>::max_digits10);\n        for (const auto &row: p_dataset->get_input_queue()->get_data()) {\n            of << row->get_value_time() << \", \";\n            for (const auto value: row.get()->get_values()) of << value << \", \";\n            of << \"\\n\";\n        }\n        of.flush();\n    }\n#endif\n    {\n        std::vector<InputQueue_ptr> new_input_queues;\n        new_input_queues.push_back(p_dataset->get_input_queue());\n        auto aux_input_queues = p_dataset->get_aux_input_queues();\n        new_input_queues.insert(new_input_queues.end(), aux_input_queues.begin(), aux_input_queues.end());\n\n        std::vector<DeconQueue_ptr> new_decon_queues;\n        //std::mutex ins_mx;\n        TPFORi(size_t, 0, new_input_queues.size(),\n               APP.decon_queue_service.deconstruct(*std::next(new_input_queues.begin(), i), p_dataset); )\n\n    }\n#ifdef DEBUG_PREPARE\n    for (auto &p_ensemble: p_dataset->get_ensembles()) {\n    \tLOG4_DEBUG(\"Ensemble \" << p_ensemble->get_decon_queue()->get_table_name() << \" data rows count \" << p_ensemble->get_decon_queue()->get_data().size());\n        {\n            static size_t call_counter;\n            std::stringstream ss;\n            using namespace svr::common;\n            ss <<\n               \"post_decon_queue_\" << p_ensemble->get_decon_queue()->get_table_name() <<\n               \"_call_\" << call_counter++ << \".out\";\n            std::ofstream of(ss.str());\n            of.precision(std::numeric_limits<double>::max_digits10);\n            for (const auto &row: p_ensemble->get_decon_queue()->get_data()) {\n                of << row->get_value_time() << \", \";\n                for (const auto value: row.get()->get_values()) of << value << \", \";\n                if (row.get()->is_anchor()) of << \"anchor\";\n                of << \"\\n\";\n            }\n            of.flush();\n        }\n    }\n#endif\n    static bool first_run = 0;\n    if (PROPS.get_tune_parameters() || first_run) {\n        std::vector<std::thread> th;\n        for (const auto &p_ensemble: p_dataset->get_ensembles()) {\n            th.emplace_back([&](){APP.decon_queue_service.save(p_ensemble->get_decon_queue(), first_new_row_time);});\n            for (const auto &p_aux_decon_decon_queue: p_ensemble->get_aux_decon_queues())\n                th.emplace_back([&](){APP.decon_queue_service.save(p_aux_decon_decon_queue, first_new_row_time);});\n        }\n        for (auto &t: th) t.join();\n        first_run = 0;\n    }\n    LOG4_END();\n}\n\nvoid InputQueueService::prepare_input_data(Dataset_ptr &p_dataset, const time_period &range, const InputQueue_ptr &p_input_queue)\n{\n    const auto corrected_range = p_input_queue->get_data().empty() ? range : time_period{p_input_queue->get_data().rbegin()->get()->get_value_time(), range.end()};\n    const auto latest_data = APP.input_queue_service.get_queue_data(p_input_queue, p_input_queue->get_data().empty() ? std::numeric_limits<int>::max() : 0, {corrected_range.begin(), bpt::hours(LOTSA_ROWS)}); // Blackbox test hack to get all aux data on the first train\n    p_input_queue->update_data(latest_data, true);\n    LOG4_DEBUG(\"Input queue begin time \" << p_input_queue->get_data().front()->get_value_time() << \", end time \" <<\n                     p_input_queue->get_data().back()->get_value_time() << \" latest data size \" << latest_data.size() << \" value columns count \" <<\n                     p_input_queue->get_data().front()->get_values().size());\n}\n\nvoid InputQueueService::prepare_input_data(Dataset_ptr &p_dataset, const time_period &range)\n{\n    LOG4_BEGIN();\n    prepare_input_data(p_dataset, range, p_dataset->get_input_queue());\n    TPFORi (size_t, 0, p_dataset->get_aux_input_queues().size(),\n        auto p_aux_input_queue = *std::next(p_dataset->get_aux_input_queues().begin(), i);\n        prepare_input_data(p_dataset, range, p_aux_input_queue);\n    )\n\n    LOG4_END();\n}\n\n/*\ndata_row_container\nInputQueueService::shift_times_forward(const data_row_container &data, const bpt::time_duration &resolution)\n{\n    data_row_container new_data_cont;\n    for (size_t ix = 0; ix < data.size() - 1; ++ix) {\n        if (ix == 0) {\n            auto new_data_row = std::make_shared<DataRow>(*data.begin()->get());\n            new_data_cont.insert({new_data_row->get_value_time() - resolution, new_data_row});\n        } else {\n            auto data_row = std::next(data.begin(), ix);\n            auto data_row_next = std::next(data_row);\n            auto new_data_row = std::make_shared<DataRow>(*data_row_next->get());\n            new_data_row->set_value_time(data_row->get()->get_value_time());\n            new_data_cont.insert({new_data_row->get_value_time(), new_data_row});\n        }\n    }\n    return new_data_cont;\n}\n*/\n\n} /* namespace business */\n} /* namespace svr */\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- SVRRoot/SVRBusiness/src/InputQueueService.cpp	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ SVRRoot/SVRBusiness/src/InputQueueService.cpp	(date 1672558451339)
@@ -1,16 +1,16 @@
 #include <future>
 
-#include <appcontext.hpp>
+#include "appcontext.hpp"
 
-#include <DAO/InputQueueDAO.hpp>
-#include <util/ValidationUtils.hpp>
-#include <DAO/ScopedTransaction.hpp>
+#include "DAO/InputQueueDAO.hpp"
+#include "util/ValidationUtils.hpp"
+#include "DAO/ScopedTransaction.hpp"
 
-#include <BidAskSpread.hpp>
-#include <InterprocessReader.hpp>
-#include <online_emd.hpp>
-#include <cvmd.hpp>
-#include <short_term_fourier_transform.hpp>
+#include "BidAskSpread.hpp"
+#include "InterprocessReader.hpp"
+#include "online_emd.hpp"
+#include "fast_cvmd.hpp"
+#include "short_term_fourier_transform.hpp"
 
 using namespace std;
 using namespace bpt;
Index: SVRRoot/OnlineSVR/src/spectral_transform.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#include \"spectral_transform.hpp\"\n#include <algorithm>\n#include <cmath>\n#include <stdexcept>\n\n#include \"short_term_fourier_transform.hpp\"\n#include \"online_emd.hpp\"\n#include \"cvmd.hpp\"\n#include \"sw_transform.hpp\"\n#include \"../include/modwt_transform.hpp\"\n\n#include <util/math_utils.hpp>\n\n#include \"common/Logging.hpp\"\n\n\nstd::unique_ptr<svr::spectral_transform> svr::spectral_transform::create(const std::string& transformation_name, const size_t levels, const double stretch_coef)\n{\n    LOG4_DEBUG(\"Request to create a \\\"\"<<transformation_name<<\"\\\" transformer.\");\n\n    if(transformation_name.find(\"fk\") != std::string::npos)\n    {\n        auto fkfo = svr::spectral_transform::modwt_filter_order_from(transformation_name);\n        return std::unique_ptr<svr::spectral_transform>(new svr::modwt_transform(fkfo, levels, false));\n    }\n\n    if (transformation_name == \"stft\")\n        return std::unique_ptr<svr::spectral_transform>(new svr::short_term_fourier_transform(levels));\n    if (transformation_name == \"stft_cpu\")\n        return std::unique_ptr<svr::spectral_transform>(new svr::short_term_fourier_transform_cpu(levels));\n#ifdef VIENNACL_WITH_OPENCL\n    if (transformation_name == \"stft_ocl\")\n        return std::unique_ptr<svr::spectral_transform>(new svr::short_term_fourier_transform_opencl(levels));\n#endif\n    if (transformation_name == \"oemd\")\n        return std::unique_ptr<svr::spectral_transform>(new svr::online_emd(levels, stretch_coef));\n    if (transformation_name == \"cvmd\")\n        return std::unique_ptr<svr::spectral_transform>(new svr::cvmd(levels));\n\n\n    return std::unique_ptr<svr::spectral_transform>(new svr::sw_transform(transformation_name, levels));\n}\n\nsize_t svr::spectral_transform::get_min_frame_length(\n        const size_t transformation_levels,\n        const size_t max_lag_count,\n        const size_t filter_order,\n        const std::string &transformation_name)\n{\n    size_t min_frame_length = 0;\n    if (transformation_name == \"stft\")\n        min_frame_length = transformation_levels + 1;\n    else if (transformation_name == \"oemd\")\n        min_frame_length = svr::online_emd::get_frame_size(transformation_levels, max_lag_count);\n    else if (transformation_name == \"cvmd\")\n        min_frame_length = svr::online_emd::get_frame_size(transformation_levels, max_lag_count);\n    else\n        min_frame_length = svr::spectral_transform::modwt_levels_to_frame_length(transformation_levels, filter_order);\n\n    return min_frame_length;\n}\n\nsvr::spectral_transform::spectral_transform(const std::string &transformation_name, const size_t& levels)\n: transformation_name_(std::move(transformation_name)), levels_(levels)\n{\n}\n\nsvr::spectral_transform::~spectral_transform()\n{\n\n}\nvoid svr::spectral_transform::summary() const\n{\n\n}\n\nsize_t svr::spectral_transform::modwt_levels_to_frame_length(const size_t modwt_levels, const size_t wavelet_order)\n{\n    return size_t(wavelet_order * std::pow(2, modwt_levels + 1));\n}\n\nsize_t svr::spectral_transform::modwt_residuals_length(const size_t modwt_levels)\n{\n    return size_t(std::pow(2, modwt_levels) * 1.5);\n}\n\n//returns existing filter order for MODWT, otherwise return 0\nsize_t svr::spectral_transform::modwt_filter_order_from(const std::string &filter_order)\n{\n    const char *c;\n    for (c = filter_order.c_str(); *c == '\\0'; ++c) if (*c >= '0' && *c <= '9') break;\n    return *c == '\\0' ? 0 : (unsigned) atol(c);\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- SVRRoot/OnlineSVR/src/spectral_transform.cpp	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ SVRRoot/OnlineSVR/src/spectral_transform.cpp	(date 1672559513331)
@@ -5,7 +5,7 @@
 
 #include "short_term_fourier_transform.hpp"
 #include "online_emd.hpp"
-#include "cvmd.hpp"
+#include "fast_cvmd.hpp"
 #include "sw_transform.hpp"
 #include "../include/modwt_transform.hpp"
 
@@ -35,7 +35,7 @@
     if (transformation_name == "oemd")
         return std::unique_ptr<svr::spectral_transform>(new svr::online_emd(levels, stretch_coef));
     if (transformation_name == "cvmd")
-        return std::unique_ptr<svr::spectral_transform>(new svr::cvmd(levels));
+        return std::unique_ptr<svr::spectral_transform>(new svr::fast_cvmd(levels));
 
 
     return std::unique_ptr<svr::spectral_transform>(new svr::sw_transform(transformation_name, levels));
Index: SVRRoot/SVRBusiness/src/DQScalingFactorService.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#include \"DQScalingFactorService.hpp\"\n#include \"appcontext.hpp\"\n#include <DAO/DQScalingFactorDAO.hpp>\n#include <spectral_transform.hpp>\n#include <cvmd.hpp>\n#include <online_emd.hpp>\n\n#ifdef CUDA_SCALING_FACTORS\n#include \"dq_scaling_factors_service_impl.cuh\"\n#endif\n\nusing namespace svr::common;\nusing namespace svr::context;\n\n// TODO Rewrite, remove scale input queue and the calling scale dataset\n\nnamespace svr {\nnamespace business {\n\nbool DQScalingFactorService::exists(const DQScalingFactor_ptr &dq_scaling_factor)\n{\n    return dq_scaling_factor_dao.exists(dq_scaling_factor);\n}\n\n\nint DQScalingFactorService::save(const DQScalingFactor_ptr &p_dq_scaling_factor)\n{\n    if (p_dq_scaling_factor->get_id() == 0) p_dq_scaling_factor->set_id(dq_scaling_factor_dao.get_next_id());\n    return dq_scaling_factor_dao.save(p_dq_scaling_factor);\n}\n\n\nint DQScalingFactorService::remove(const DQScalingFactor_ptr &dq_scaling_factor)\n{\n    return dq_scaling_factor_dao.remove(dq_scaling_factor);\n}\n\n\nsvr::datamodel::dq_scaling_factor_container_t\nDQScalingFactorService::find_all_by_dataset_id(const bigint dataset_id)\n{\n    return dq_scaling_factor_dao.find_all_by_dataset_id(dataset_id);\n}\n\nnamespace {\n\nstruct nth_max\n{\n    std::vector<double> cont;\n    size_t const n;\n\n    nth_max(size_t n)\n            : cont(n, 0.0), n(n)\n    {}\n\n    double const &get() const\n    {\n        return cont.back();\n    }\n\n    void add(double const &val)\n    {\n        double v = std::abs(val);\n\n        if (v <= cont.back())\n            return;\n\n        cont.back() = v;\n        std::sort(cont.begin(), cont.end(), std::greater<double>());\n    }\n};\n\nstruct scaling_components\n{\n    std::vector<double> scaling_component;\n    std::vector<double> mean_component;\n};\n\nscaling_components\nget_nth_max(svr::datamodel::DataRow::container const &rows, const size_t n)\n{\n    const size_t levels = rows.front()->get_values().size();\n#ifdef CUDA_SCALING_FACTORS\n    // TODO Implement in THRUST\n    std::vector<double> rows_matrix;\n    rows_matrix.reserve(rows.size() * levels);\n    for (auto const &row: rows) rows_matrix.insert(rows_matrix.end(), row.second->get_values().begin(), row.second->get_values().end());\n    scaling_components result;\n    gpu_context ctx;\n    svr::business::cu_get_nth_max(rows_matrix, n, levels, rows.size(), result.mean_component, result.scaling_component, ctx.id());\n    return result;\n#else\n    //const size_t rows_length = rows.size();\n    std::vector<double> level_means(levels, 0.);\n    std::vector<std::vector<double>> data_by_rows;// (rows_length, std::vector(levels, 0.0));\n    for (auto const &row: rows) data_by_rows.push_back(row->get_values());\n    auto data_by_levels = transpose_matrix(data_by_rows);\n\n    scaling_components result;\n    result.mean_component.resize(levels);\n    result.scaling_component.resize(levels);\n    PFOR(l, 0, levels,\n        /*\n        std::nth_element(data_by_levels.begin() + i * rows_length, data_by_levels.begin() + i * rows_length + n,\n                         data_by_levels.begin() + i * rows_length + rows_length);\n        double min_range_value = data_by_levels[i * rows_length + n];\n\n        std::nth_element(data_by_levels.begin() + i * rows_length,\n                         data_by_levels.begin() + i * rows_length + (rows_length - 1 - n),\n                         data_by_levels.begin() + i * rows_length + rows_length);\n        double max_range_value = data_by_levels[i * rows_length + (rows_length - 1 - n)];\n        // TODO Level means buggy, rewrite\n\n        size_t count = 0;\n        for (size_t j = 4096; j < rows_length; j++) {\n            double elem = data_by_levels[i * rows_length + j];\n            if ((elem > min_range_value) && (elem < max_range_value)) {\n                level_means[i] += data_by_levels[i * rows_length + j];\n                count++;\n            }\n        }\n        */\n        //level_means[i]=level_means[i]/(double)count;\n        level_means[l] = 0;\n        //if (i == 0) level_means[i] = 0;\n        //result.scaling_component[i] = (max_range_value - min_range_value) / 2.;\n        for (size_t r = 0; r < data_by_levels[l].size(); ++r) data_by_levels[l][r] = std::abs(data_by_levels[l][r]);\n        std::sort(data_by_levels[l].begin(), data_by_levels[l].end());\n        result.scaling_component[l] = data_by_levels[l][n];\n        result.mean_component[l] = level_means[l];\n        LOG4_DEBUG(\"Level \" << l << \" scaling component \" << result.scaling_component[l] << \" at position \" << n\n                            << \", mean component \" << result.mean_component[l] << \" smallest element \" << data_by_levels[l].front() << \" largest element \" << data_by_levels[l].back());\n    )\n    return result;\n#endif\n}\n\n/*\n    scaling_components get_nth_max(svr::datamodel::DataRow::container const &rows, size_t n)\n    {\n        size_t const levels = rows.begin()->second->get_values().size();\n        std::vector<std::unique_ptr<nth_max>> nth_mx;\n        std::vector<double> level_means(levels, 0.0);\n        for(size_t i = 0; i < levels; ++i)\n            nth_mx.push_back(std::unique_ptr<nth_max>(new nth_max(n)));\n\n        for(size_t i = 0; i < levels; ++i) {\n            for(auto const & row: rows) {\n                double level_value = row.second->get_values()[i];\n                nth_mx[i]->add(level_value);\n                level_means[i] += level_value;\n            }\n            if(i==0)\n                level_means[0] = 0;\n            else {\n                //level_means[i] /= double(rows.size());\n                level_means[i] = 0.;\n            }\n        }\n\n        scaling_components result;\n\n        for(auto const & nthm : nth_mx)\n            result.scaling_component.push_back(nthm->get());\n\n        for(auto const & nthm_mean : level_means)\n            result.mean_component.push_back(nthm_mean);\n\n        return result;\n    }\n     */\n}\n\n\nsvr::datamodel::dq_scaling_factor_container_t\nDQScalingFactorService::calculate(\n        const svr::datamodel::DeconQueue_ptr &p_decon_queue,\n        const size_t dataset_id,\n        const double alpha)\n{\n    LOG4_BEGIN();\n    if (p_decon_queue->get_data().empty()) {\n        LOG4_ERROR(\"Decon queue is empty\");\n        return {};\n    }\n    LOG4_DEBUG(\"Calculating \" << alpha << \" truncated mean for scaling \" << p_decon_queue->get_input_queue_table_name() << \" \" <<\n                              p_decon_queue->get_input_queue_column_name() << \" data from \" << p_decon_queue->get_data().begin()->get()->get_value_time() << \" until \" << p_decon_queue->get_data().rbegin()->get()->get_value_time());\n\n    svr::datamodel::dq_scaling_factor_container_t result;\n    const auto &dq_data = p_decon_queue->get_data();\n    const size_t pos = std::round(dq_data.size() * (1. - alpha));\n    scaling_components sfs = get_nth_max(dq_data, pos);\n    for (size_t level = 0; level < sfs.scaling_component.size(); ++level)\n        result.insert(\n                std::make_shared<svr::datamodel::DQScalingFactor>(\n                        0,\n                        dataset_id,\n                        p_decon_queue->get_input_queue_table_name(),\n                        p_decon_queue->get_input_queue_column_name(),\n                        level,\n                        sfs.scaling_component[level],\n                        sfs.mean_component[level]));\n    return result;\n}\n\nsvr::datamodel::dq_scaling_factor_container_t\nDQScalingFactorService::slice(const Dataset_ptr &p_dataset, const DeconQueue_ptr &p_decon_queue)\n{\n    return slice(p_dataset->get_dq_scaling_factors(), p_dataset->get_id(), p_decon_queue->get_input_queue_table_name(), p_decon_queue->get_input_queue_column_name());\n}\n\n\nsvr::datamodel::dq_scaling_factor_container_t\nDQScalingFactorService::slice(\n        const svr::datamodel::dq_scaling_factor_container_t &scaling_factors,\n        const size_t dataset_id,\n        const std::string &input_queue_table_name,\n        const std::string &input_queue_column_name)\n{\n    LOG4_DEBUG(\n            \"Slicing decon queue scaling factors with dataset id \" << dataset_id << \" input queue table name \"\n               << input_queue_table_name << \" input queue column name \" << input_queue_column_name);\n\n    svr::datamodel::dq_scaling_factor_container_t result;\n    for (auto &scaling_factor : scaling_factors)\n        if ((!dataset_id or scaling_factor->get_dataset_id() == dataset_id) and\n            scaling_factor->get_input_queue_table_name() == input_queue_table_name and\n            scaling_factor->get_input_queue_column_name() == input_queue_column_name)\n            result.insert(scaling_factor);\n\n    LOG4_DEBUG(\n            \"Input decon factors size is \" << scaling_factors.size() << \" filtered result size is \" << result.size());\n    return result;\n}\n\n\nvoid\nDQScalingFactorService::scale_decon_queue(\n        const svr::datamodel::DeconQueue_ptr &p_decon_queue,\n        const std::vector<double> &scaling_factors,\n        const std::vector<double> &mean_values)\n{\n    const size_t level_ct = p_decon_queue->get_data().front()->get_values().size();\n    LOG4_DEBUG(\"Scaling decon queue \" << p_decon_queue->get_table_name() << \" of \" << p_decon_queue->get_data().size()\n                                        << \" rows and \" << level_ct << \" levels.\");\n    CILK_ITER(p_decon_queue->get_data().begin(), p_decon_queue->get_data().size(), ;\n        std::vector<double> &values = _ITER->get()->get_values();\n        for (size_t level_idx = 0; level_idx < level_ct; ++level_idx) {\n            values[level_idx] -= mean_values[level_idx];\n            values[level_idx] /= scaling_factors[level_idx];\n        }\n    );\n}\n\n\nvoid\nDQScalingFactorService::unscale_decon_queue(\n        const svr::datamodel::DeconQueue_ptr &p_decon_queue,\n        const std::vector<double> &scaling_factors,\n        const std::vector<double> &mean_values)\n{\n    const size_t level_ct = p_decon_queue->get_data().front()->get_values().size();\n    LOG4_DEBUG(\"Unscaling decon queue \" << p_decon_queue->get_table_name() << \" of \" << p_decon_queue->get_data().size()\n                                        << \" rows and \" << level_ct << \" levels.\");\n    CILK_ITER(p_decon_queue->get_data().begin(), p_decon_queue->get_data().size(), ;\n        std::vector<double> &values = _ITER->get()->get_values();\n        for (size_t level_idx = 0; level_idx < level_ct; ++level_idx) {\n            values[level_idx] += mean_values[level_idx];\n            values[level_idx] *= scaling_factors[level_idx];\n        }\n    );\n}\n\n// TODO Rewrite and check with slice() for needed scaling factors\nvoid\nDQScalingFactorService::scale(\n        const Dataset_ptr &p_dataset,\n        const bool unscale,\n        Ensemble_ptr p_ensemble)\n{\n    LOG4_BEGIN();\n\n    // If scaling factors are empty try to load them from DB\n    if (p_dataset->get_dq_scaling_factors().empty())\n        p_dataset->set_dq_scaling_factors(find_all_by_dataset_id(p_dataset->get_id()));\n\n    // Otherwise calculate them and save to the DB\n    if (p_dataset->get_dq_scaling_factors().empty()) calculate_dataset_scaling_factors(p_dataset);\n\n    std::vector<Ensemble_ptr> ensembles_to_scale;\n    if (!p_ensemble) ensembles_to_scale = p_dataset->get_ensembles();\n    else ensembles_to_scale.push_back(p_ensemble);\n    std::map<std::string, DeconQueue_ptr> decon_queues_to_scale;\n    for (auto p_scaled_ensemble: ensembles_to_scale) {\n        decon_queues_to_scale[p_scaled_ensemble->get_decon_queue()->get_table_name()] = p_scaled_ensemble->get_decon_queue();\n        for (auto &p_aux_decon_queue: p_scaled_ensemble->get_aux_decon_queues())\n            decon_queues_to_scale[p_aux_decon_queue->get_table_name()] = p_aux_decon_queue;\n    }\n    for (auto decon_queue_pair: decon_queues_to_scale)\n        scale_decon_queue(p_dataset, decon_queue_pair.second, unscale);\n\n    LOG4_END();\n}\n\nvoid DQScalingFactorService::scale(\n        const Dataset_ptr &p_dataset,\n        const bool unscale,\n        svr::datamodel::DeconQueue_ptr &p_decon_queue)\n{\n    LOG4_BEGIN();\n\n    // Scale decon queue\n    scale_decon_queue(p_dataset, p_decon_queue, unscale);\n\n    LOG4_END();\n}\n\nvoid DQScalingFactorService::unscale(\n        const Dataset_ptr &p_dataset,\n        svr::datamodel::DeconQueue_ptr &p_decon_queue)\n{\n    LOG4_BEGIN();\n\n    // Scale decon queue\n    scale_decon_queue(p_dataset, p_decon_queue, true);\n\n    LOG4_END();\n}\n\nstd::mutex mx_calc_factors;\n\n// Calculate scaling factors related to decon queue\nsvr::datamodel::dq_scaling_factor_container_t\nDQScalingFactorService::calculate_dataset_scaling_factors(const Dataset_ptr &p_dataset)\n{\n    std::lock_guard<std::mutex> lg_calc_factors(mx_calc_factors);\n    const auto level_ct = p_dataset->get_transformation_levels();\n    const auto decon_queues = p_dataset->get_decon_queues();\n    if (p_dataset->get_dq_scaling_factors().size() == decon_queues.size() * level_ct) {\n        LOG4_DEBUG(\"Scaling factors already calculated.\");\n        return p_dataset->get_dq_scaling_factors();\n    }\n\n    LOG4_INFO(\"Calculating scaling factors for dataset \" << p_dataset->get_id());\n    svr::datamodel::dq_scaling_factor_container_t dq_scaling_factors;\n    std::mutex mx;\n    PFOR (ix, 0, decon_queues.size(),\n        const auto p_orig_decon_queue = std::next(decon_queues.begin(), ix)->second;\n        auto p_new_decon_queue = p_orig_decon_queue->clone();\n        const auto residual_ct = p_dataset->p_cvmd_transformer->get_residuals_length(\"DUMMY\"); // TODO Wrong use another number\n        if (p_new_decon_queue->get_data().size() < residual_ct)\n            LOG4_ERROR(\"Size \" << p_new_decon_queue->get_data().size() << \" is less than \" << residual_ct);\n        else\n            p_new_decon_queue->get_data().erase(p_new_decon_queue->get_data().begin(), std::next(p_new_decon_queue->get_data().begin(), residual_ct));\n        const auto new_dataset_scaling_factors = calculate(svr::business::DeconQueueService::decon_queue_delta(p_new_decon_queue, false), p_dataset->get_id(), PROPS.get_scaling_alpha());\n        for (const auto &scaling_factor: new_dataset_scaling_factors) {\n            const std::lock_guard<std::mutex> l(mx);\n            dq_scaling_factors.insert(scaling_factor);\n        }\n    )\n\n    if (p_dataset->get_id()) {\n        auto existing_scaling_factors = find_all_by_dataset_id(p_dataset->get_id());\n        for (auto &existing_scaling_factor: existing_scaling_factors)\n            remove(existing_scaling_factor);\n        for (const auto &scaling_factor: dq_scaling_factors)\n            save(scaling_factor);\n    } else {\n        LOG4_WARN(\"Not saving, dataset does not exist in database.\");\n    }\n    p_dataset->set_dq_scaling_factors(dq_scaling_factors);\n    LOG4_END();\n\n    return dq_scaling_factors;\n}\n\nsvr::datamodel::dq_scaling_factor_container_t\nDQScalingFactorService::prepare_decon_queue_scaling_factors(\n        const Dataset_ptr &p_dataset,\n        const std::string &input_queue_table_name,\n        const std::string &input_queue_column_name)\n{\n    const size_t all_scale_levels = p_dataset->get_transformation_levels();\n    svr::datamodel::dq_scaling_factor_container_t decon_queue_scaling_factors;\n    decon_queue_scaling_factors = slice(\n            p_dataset->get_dq_scaling_factors(),\n            p_dataset->get_id(),\n            input_queue_table_name,\n            input_queue_column_name);\n    if (decon_queue_scaling_factors.size() == all_scale_levels) goto __bail;\n\n    LOG4_WARN(\"Dataset doesn't have scaling factors, loading from database.\");\n    p_dataset->set_dq_scaling_factors(find_all_by_dataset_id(p_dataset->get_id()));\n\n    // scale main DeconQueue\n    decon_queue_scaling_factors = slice(\n            p_dataset->get_dq_scaling_factors(), p_dataset->get_id(),\n            input_queue_table_name,\n            input_queue_column_name);\n\n    if (decon_queue_scaling_factors.size() == all_scale_levels) goto __bail;\n    LOG4_DEBUG(\"Recalculating scaling factors.\");\n\n    // otherwise calculate them and save to the DB\n    if (decon_queue_scaling_factors.size() != all_scale_levels) {\n        p_dataset->set_dq_scaling_factors(calculate_dataset_scaling_factors(p_dataset));\n        decon_queue_scaling_factors = slice(\n                p_dataset->get_dq_scaling_factors(),\n                p_dataset->get_id(),\n                input_queue_table_name,\n                input_queue_column_name);\n        LOG4_DEBUG(\"Calculated scaling factors count \" << decon_queue_scaling_factors.size());\n    }\n\n__bail:\n    return decon_queue_scaling_factors;\n}\n\nsvr::datamodel::dq_scaling_factor_container_t\nDQScalingFactorService::prepare_decon_queue_scaling_factors(\n        const Dataset_ptr &p_dataset,\n        const DeconQueue_ptr &p_decon_queue)\n{\n    return prepare_decon_queue_scaling_factors(p_dataset, p_decon_queue->get_input_queue_table_name(), p_decon_queue->get_input_queue_column_name());\n}\n\nvoid\nDQScalingFactorService::scale_decon_queue(\n        const Dataset_ptr &p_dataset,\n        DeconQueue_ptr &p_decon_queue,\n        const bool unscale,\n        const bool force_recalculate)\n{\n    LOG4_BEGIN();\n\n    const size_t all_scale_levels = p_dataset->get_transformation_levels();\n    svr::datamodel::dq_scaling_factor_container_t decon_queue_scaling_factors;\n\n    // Delete the scaling factors if it is asked for\n    if (force_recalculate) {\n        decon_queue_scaling_factors = slice(\n                calculate_dataset_scaling_factors(p_dataset),\n                p_dataset->get_id(),\n                p_decon_queue->get_input_queue_table_name(),\n                p_decon_queue->get_input_queue_column_name());\n        p_dataset->set_dq_scaling_factors(decon_queue_scaling_factors);\n        LOG4_WARN(\"Recalculated scaling factors count \" << decon_queue_scaling_factors.size());\n        if (decon_queue_scaling_factors.size() != all_scale_levels)\n            THROW_EX_FS(std::logic_error, \"Failed calculating scaling factors, needed \" << all_scale_levels << \" got \" << decon_queue_scaling_factors.size());\n    } else {\n        decon_queue_scaling_factors = prepare_decon_queue_scaling_factors(p_dataset, p_decon_queue);\n        if (decon_queue_scaling_factors.size() != all_scale_levels)\n            THROW_EX_FS(std::runtime_error, \"Failed calculating scaling factors, needed \" << all_scale_levels << \" got \" << decon_queue_scaling_factors.size());\n    }\n\n    std::vector<double> scaling_factors(all_scale_levels, 1.);\n    std::vector<double> mean_values(all_scale_levels, 0.);\n    for (const auto &p_scaling_factor: decon_queue_scaling_factors) {\n        scaling_factors[p_scaling_factor->get_wavelet_level()] = p_scaling_factor->get_scaling_factor();\n        mean_values[p_scaling_factor->get_wavelet_level()] = p_scaling_factor->get_mean_value();\n    }\n#if 0 // Scaling of data is now done during preparation in ModelService because of performance reasons.\n\n    if (not unscale) scale_decon_queue(p_decon_queue, scaling_factors, mean_values);\n#endif\n    if (unscale) unscale_decon_queue(p_decon_queue, scaling_factors, mean_values);\n\n    LOG4_END();\n}\n\nvoid DQScalingFactorService::force_scale_decon_queue(const Dataset_ptr &p_dataset, DeconQueue_ptr &p_decon_queue)\n{\n    const size_t all_scale_levels = p_dataset->get_transformation_levels();\n    const auto decon_queue_scaling_factors = slice(\n            p_dataset->get_dq_scaling_factors(),\n            p_dataset->get_id(),\n            p_decon_queue->get_input_queue_table_name(),\n            p_decon_queue->get_input_queue_column_name());\n    std::vector<double> scaling_factors(all_scale_levels, 1.);\n    std::vector<double> mean_values(all_scale_levels, 0.);\n    for (const auto &p_scaling_factor: decon_queue_scaling_factors) {\n        scaling_factors[p_scaling_factor->get_wavelet_level()] = p_scaling_factor->get_scaling_factor();\n        mean_values[p_scaling_factor->get_wavelet_level()] = p_scaling_factor->get_mean_value();\n    }\n    scale_decon_queue(p_decon_queue, scaling_factors, mean_values);\n}\n\nvoid\nDQScalingFactorService::force_unscale_decon_queue(\n        const Dataset_ptr &p_dataset,\n        DeconQueue_ptr &p_decon_queue,\n        const std::string &input_table_name,\n        const std::string &input_column_name)\n{\n    const size_t all_scale_levels = p_dataset->get_transformation_levels();\n    const auto decon_queue_scaling_factors = slice(\n            p_dataset->get_dq_scaling_factors(),\n            p_dataset->get_id(),\n            input_table_name,\n            input_column_name);\n    std::vector<double> scaling_factors(all_scale_levels, 1.);\n    std::vector<double> mean_values(all_scale_levels, 0.);\n    for (const auto &p_scaling_factor: decon_queue_scaling_factors) {\n        scaling_factors[p_scaling_factor->get_wavelet_level()] = p_scaling_factor->get_scaling_factor();\n        mean_values[p_scaling_factor->get_wavelet_level()] = p_scaling_factor->get_mean_value();\n    }\n    unscale_decon_queue(p_decon_queue, scaling_factors, mean_values);\n}\n\nvoid\nDQScalingFactorService::force_unscale_decon_prediction(\n        arma::mat &prediction,\n        const size_t level_idx,\n        const svr::datamodel::dq_scaling_factor_container_t &decon_queue_scaling_factors,\n        const size_t all_scale_levels)\n{\n    LOG4_BEGIN();\n    std::map<size_t, double> scaling_factors;\n    std::map<size_t, double> mean_values;\n    for (const auto &p_scaling_factor: decon_queue_scaling_factors) {\n        scaling_factors[p_scaling_factor->get_wavelet_level()] = p_scaling_factor->get_scaling_factor();\n        mean_values[p_scaling_factor->get_wavelet_level()] = p_scaling_factor->get_mean_value();\n    }\n    LOG4_DEBUG(\"Decon scaling factor for level \" << level_idx << \", mean \" << mean_values[level_idx] << \", scaling factor \" << scaling_factors[level_idx]);\n    prediction += mean_values[level_idx];\n    prediction *= scaling_factors[level_idx];\n\n    LOG4_END();\n}\n\nvoid\nDQScalingFactorService::unscale_decon_data(\n        const Dataset_ptr &p_dataset,\n        std::vector<double> &decon_data,\n        const std::string &input_queue_column_name)\n{\n    LOG4_BEGIN();\n\n    const size_t all_scale_levels = p_dataset->get_transformation_levels();\n    if (p_dataset->get_dq_scaling_factors().empty())\n        p_dataset->set_dq_scaling_factors(find_all_by_dataset_id(p_dataset->get_id()));\n\n    // scale main DeconQueue\n    svr::datamodel::dq_scaling_factor_container_t decon_queue_scaling_factors = slice(\n            p_dataset->get_dq_scaling_factors(),\n            p_dataset->get_id(),\n            p_dataset->get_input_queue()->get_table_name(),\n            input_queue_column_name);\n\n    if (decon_queue_scaling_factors.size() != all_scale_levels) {\n        LOG4_WARN(\"Dataset doesn't have scaling factors. Loading from database.\");\n        p_dataset->set_dq_scaling_factors(find_all_by_dataset_id(p_dataset->get_id()));\n\n        // scale main DeconQueue\n        decon_queue_scaling_factors = slice(\n                p_dataset->get_dq_scaling_factors(),\n                p_dataset->get_id(),\n                p_dataset->get_input_queue()->get_table_name(),\n                input_queue_column_name);\n        if (decon_queue_scaling_factors.size() != all_scale_levels) LOG4_THROW(\"Failed loading scaling factors.\");\n    }\n\n    std::vector<double> scaling_factors(all_scale_levels, 1.);\n    std::vector<double> mean_values(all_scale_levels, 0.);\n    for (const DQScalingFactor_ptr &p_scaling_factor: decon_queue_scaling_factors) {\n        scaling_factors[p_scaling_factor->get_wavelet_level()] = p_scaling_factor->get_scaling_factor();\n        mean_values[p_scaling_factor->get_wavelet_level()] = p_scaling_factor->get_mean_value();\n    }\n\n    PFOR(level_idx, 0, decon_data.size(),\n        decon_data[level_idx] *= scaling_factors[level_idx];\n        decon_data[level_idx] += mean_values[level_idx];\n    )\n\n    LOG4_END();\n}\n\n\n}\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- SVRRoot/SVRBusiness/src/DQScalingFactorService.cpp	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ SVRRoot/SVRBusiness/src/DQScalingFactorService.cpp	(date 1672558358291)
@@ -1,9 +1,9 @@
 #include "DQScalingFactorService.hpp"
 #include "appcontext.hpp"
-#include <DAO/DQScalingFactorDAO.hpp>
-#include <spectral_transform.hpp>
-#include <cvmd.hpp>
-#include <online_emd.hpp>
+#include "DAO/DQScalingFactorDAO.hpp"
+#include "spectral_transform.hpp"
+#include "fast_cvmd.hpp"
+#include "online_emd.hpp"
 
 #ifdef CUDA_SCALING_FACTORS
 #include "dq_scaling_factors_service_impl.cuh"
Index: SVRRoot/SVRBusiness/src/DeconQueueService.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#include \"DeconQueueService.hpp\"\n\n#include <model/FramesContainer.hpp>\n#include <util/ValidationUtils.hpp>\n#include <util/math_utils.hpp>\n#include \"model/InputQueue.hpp\"\n#include \"model/DeconQueue.hpp\"\n#include \"model/Dataset.hpp\"\n#include \"DAO/DeconQueueDAO.hpp\"\n#include \"InputQueueService.hpp\"\n#include \"appcontext.hpp\"\n\n#include <modwt_transform.hpp>\n#include <online_emd.hpp>\n#include <cvmd.hpp>\n\n// #define SWT_DEBUG\n\nusing namespace std;\nusing namespace svr::datamodel;\nusing namespace svr::common;\nusing namespace bpt;\n\nnamespace svr {\nnamespace business {\n\n\nDeconQueue_ptr DeconQueueService::get_by_table_name(const std::string &table_name)\n{\n    return decon_queue_dao.get_decon_queue_by_table_name(table_name);\n}\n\nDeconQueue_ptr DeconQueueService::get_queue_metadata(const std::string &table_name)\n{\n    return decon_queue_dao.get_decon_queue_by_table_name(table_name);\n}\n\nvoid DeconQueueService::save(DeconQueue_ptr const &p_decon_queue, const boost::posix_time::ptime &start_time)\n{\n    reject_nullptr(p_decon_queue);\n    decon_queue_dao.save(p_decon_queue, start_time);\n}\n\nbool DeconQueueService::exists(DeconQueue_ptr const &p_decon_queue)\n{\n    reject_nullptr(p_decon_queue);\n    return decon_queue_dao.exists(p_decon_queue->get_table_name());\n}\n\nbool DeconQueueService::exists(const string &decon_queue_table_name)\n{\n    return decon_queue_dao.exists(decon_queue_table_name);\n}\n\nint DeconQueueService::remove(DeconQueue_ptr const &p_decon_queue)\n{\n    if (exists(p_decon_queue)) return decon_queue_dao.remove(p_decon_queue);\n    else return 0;\n}\n\n\nstd::vector<double> DeconQueueService::get_actual_values(\n        const data_row_container &data,\n        const data_row_container::const_iterator &target_iter)\n{\n    LOG4_BEGIN();\n\n    if (data.empty()) {\n        LOG4_WARN(\"Data is empty!\");\n        return {};\n    }\n    if (target_iter == data.end()) {\n        LOG4_WARN(\"Target iterator is empty.\");\n        return {};\n    }\n\n#ifndef ALL_LEVELS_DELTA\n    return target_iter->get()->get_values();\n#else\n    if (not data.begin()->get()->is_anchor()) THROW_EX_FS(std::runtime_error, \"Beginning row is not anchor.\");\n\n    std::vector<double> result = data.begin()->get()->get_values();\n    if (data.size() == 1) return result;\n    const auto end_iter = target_iter == data.end() ? data.end() : std::next(target_iter);\n    for (auto row_iter = std::next(data.begin()); row_iter != end_iter; ++row_iter) {\n        cilk_for (size_t i = 0; i < row_iter->get()->get_values().size(); ++i) {\n            result[i] = svr::common::inv_diff_return(row_iter->get()->get_value(i), result[i]);\n            result[i] = svr::common::inv_diff_return(row_iter->get()->get_value(i), result[i]);\n        }\n    }\n\n    return result;\n#endif\n}\n\n\nDeconQueue_ptr\ntrim_delta(const Dataset_ptr &p_dataset, const DeconQueue_ptr &p_decon_queue, const boost::posix_time::time_period &period)\n{\n    auto p_new_decon_queue = p_decon_queue->clone_empty();\n    for (auto row_iter = lower_bound_back(p_decon_queue->get_data(), period.begin());\n        row_iter != p_decon_queue->get_data().end() and row_iter->get()->get_value_time() <= period.end(); ++row_iter)\n        p_new_decon_queue->get_data().emplace_back(std::make_shared<DataRow>(**row_iter));\n    LOG4_DEBUG(\"Returning \" << p_new_decon_queue->get_data().size() << \" for \" << p_new_decon_queue->get_input_queue_table_name() << \" \" << p_new_decon_queue->get_input_queue_column_name() << \" from \" << p_new_decon_queue->get_data().front()->get_value_time() << \" until \" << p_new_decon_queue->get_data().back()->get_value_time());\n    return DeconQueueService::decon_queue_delta(p_new_decon_queue, true);\n}\n\n\nstd::vector<DeconQueue_ptr>\nDeconQueueService::extract_data(\n        const Dataset_ptr &p_dataset,\n        const boost::posix_time::time_period &period)\n{\n    LOG4_BEGIN();\n    const auto decon_queues = p_dataset->get_decon_queues();\n    std::vector<DeconQueue_ptr> new_decon_queues;\n    std::mutex mx;\n    TPFORi (size_t, 0, decon_queues.size(),\n        const auto p_decon_queue = std::next(decon_queues.begin(), i)->second;\n        const auto p_new_decon_queue = trim_delta(p_dataset, p_decon_queue, period);\n        const std::lock_guard<std::mutex> lg(mx);\n        new_decon_queues.emplace_back(p_new_decon_queue);\n    )\n\n    LOG4_DEBUG(\"Returning \" << new_decon_queues.size() << \" decon queues for dataset \" << p_dataset->get_id());\n\n    return new_decon_queues;\n}\n\n\nstd::vector<DeconQueue_ptr>\nDeconQueueService::deconstruct(\n        const InputQueue_ptr &p_input_queue,\n        const Dataset_ptr &p_dataset,\n        const bool get_data_from_database)\n{\n    const auto column_names = p_input_queue->get_value_columns();\n    std::vector<DeconQueue_ptr> decon_queues(column_names.size());\n    cilk_for (size_t i = 0; i < column_names.size(); ++i)\n    {\n        auto p_decon_queue = deconstruct(p_input_queue, p_dataset, column_names[i], get_data_from_database);\n        if (p_decon_queue) decon_queues[i] = p_decon_queue;\n        else decon_queues[i] = nullptr;\n    }\n    return decon_queues;\n}\n\n\nDeconQueue_ptr\nDeconQueueService::deconstruct(\n        const InputQueue_ptr &p_input_queue,\n        const Dataset_ptr &p_dataset,\n        const std::string &column_name,\n        const bool get_data_from_database)\n{\n    LOG4_BEGIN();\n    auto p_decon_queue = p_dataset->get_decon_queue(p_input_queue, column_name);\n    if (!p_decon_queue) p_decon_queue = make_shared<DeconQueue>(\n                \"\",\n                p_input_queue->get_table_name(),\n                column_name,\n                p_dataset->get_id(),\n                p_dataset->get_transformation_levels());\n\n    if (p_input_queue->is_tick_queue())\n        deconstruct_ticks(p_input_queue, p_dataset, column_name, p_decon_queue->get_data());\n    else\n        deconstruct(p_input_queue, p_dataset, column_name, p_decon_queue->get_data(), get_data_from_database);\n\n    LOG4_END();\n\n    return p_decon_queue;\n}\n\n\nvoid\nDeconQueueService::deconstruct_ticks(\n        const InputQueue_ptr &p_input_queue,\n        const Dataset_ptr &p_dataset,\n        const string &column_name,\n        data_row_container &decon_data)\n{\n    LOG4_BEGIN();\n\n    if (p_dataset->get_transformation_levels() == 0) {\n        decon_data = InputQueueService::get_column_data(p_input_queue, column_name);\n        return;\n    }\n    const auto &input_data = p_input_queue->get_data();\n    if (input_data.empty()) {\n        LOG4_ERROR(\"Data is empty.\");\n        return;\n    }\n\n    const auto input_column_index = InputQueueService::get_value_column_index(p_input_queue, column_name);\n    const auto p_decon_queue = p_dataset->get_decon_queue(p_input_queue, column_name);\n    if (input_column_index >= input_data.begin()->get()->get_values().size())\n        THROW_EX_FS(std::range_error, \"Column index out of bounds \" << input_column_index);\n    auto row_iter = p_decon_queue->get_data().empty() ? input_data.begin() : upper_bound(input_data, p_decon_queue->get_data().rbegin()->get()->get_value_time());\n    if (row_iter == input_data.end()) {\n        LOG4_DEBUG(\"No new data in input queue to deconstruct!\");\n        return;\n    }\n\n    double last_price = row_iter->get()->get_value(input_column_index);\n    const auto start_time_iter = round_second(row_iter->get()->get_value_time());\n    const auto end_time = round_second(input_data.rbegin()->get()->get_value_time());\n    std::mutex ins_mx;\n\n    TPFOR (ssize_t, tr, 0, (end_time - start_time_iter).total_seconds(),\n        const auto decon_row_time = start_time_iter + bpt::seconds(tr);\n        if (decon_row_time.date().day_of_week() != 6 and decon_row_time.date().day_of_week() != 0) {\n            bpt::ptime time_iter = decon_row_time;\n            std::vector<double> msec_prices(1000);\n            for (size_t ms = 0; ms < msec_prices.size(); ++ms) {\n                while (round_millisecond(row_iter->get()->get_value_time()) < time_iter) {\n                    last_price = row_iter->get()->get_value(input_column_index);\n                    ++row_iter;\n                }\n                if (round_millisecond(row_iter->get()->get_value_time()) == time_iter) {\n                    last_price = row_iter->get()->get_value(input_column_index);\n                    msec_prices[ms] = last_price;\n                    ++row_iter;\n                } else if (round_millisecond(row_iter->get()->get_value_time()) > time_iter) {\n                    msec_prices[ms] = last_price;\n                }\n                time_iter += bpt::milliseconds(ms);\n            }\n\n            std::vector<std::vector<double>> decon_values(msec_prices.size());\n            TPFOR (size_t, t, 0, msec_prices.size(),\n                //p_dataset->p_oemd_transformer_fat->transform(msec_prices[t], decon_values[t]); // TODO Not implemented\n                std::vector<double> decon_values_thin;\n                //p_dataset->oemd_transformer_thin->transform(decon_values[t].back(), decon_values_thin); // TODO Not implemented\n                decon_values[t].insert(decon_values[t].end(), decon_values_thin.begin(), decon_values_thin.end());\n            )\n            std::vector<double> avg_val(decon_values[0].size(), 0.);\n            TPFOR (size_t, l, 0, decon_values[0].size(),\n                for (size_t t = 0; t < decon_values.size(); ++t)\n                    avg_val[l] += decon_values[t][l];\n                avg_val[l] /= double(decon_values.size());\n            )\n            const auto row = std::make_shared<svr::datamodel::DataRow>(decon_row_time, bpt::second_clock::local_time(), 0, avg_val);\n            const std::lock_guard<std::mutex> lg(ins_mx);\n            decon_data.insert(decon_data.end(), row);\n        }\n    )\n    LOG4_END();\n}\n\n\nvoid\nDeconQueueService::deconstruct(\n        const InputQueue_ptr &p_input_queue,\n        const Dataset_ptr &p_dataset,\n        const string &column_name,\n        svr::datamodel::DataRow::container &decon_out,\n        const bool get_data_from_database)\n{\n    LOG4_BEGIN();\n\n    if (p_dataset->get_transformation_levels() == 0) {\n        decon_out = InputQueueService::get_column_data(p_input_queue, column_name);\n        return;\n    }\n    const auto input_data = get_data_from_database ? InputQueueService::get_column_data(p_input_queue, column_name) : p_input_queue->get_data();\n    if (input_data.empty()) {\n        LOG4_ERROR(\"Data is empty.\");\n        return;\n    }\n\n    const auto input_column_index = get_data_from_database ? 0 : InputQueueService::get_value_column_index(p_input_queue, column_name);\n    const auto p_decon_queue = p_dataset->get_decon_queue(p_input_queue, column_name);\n    if (!p_decon_queue) {\n        LOG4_ERROR(\"Could not find decon queue for \" << p_input_queue->get_table_name() << \" \" << column_name);\n        return;\n    }\n\n    if (input_column_index >= input_data.begin()->get()->get_values().size())\n        THROW_EX_FS(std::range_error, \"Column index out of bounds \" << input_column_index);\n\n    // TODO Rewrite CVMD data harvesting\n    const auto cvmd_residuals_ct_orig = p_dataset->p_cvmd_transformer->get_residuals_length(p_decon_queue->get_table_name());\n    auto cvmd_residuals_ct = p_decon_queue and not p_decon_queue->get_data().empty() ? 0 : p_dataset->p_cvmd_transformer->get_residuals_length(p_decon_queue->get_table_name());\n    auto oemd_residuals_ct = p_dataset->p_oemd_transformer_fat->get_residuals_length();\n    if (cvmd_residuals_ct and cvmd_residuals_ct < oemd_residuals_ct) cvmd_residuals_ct = oemd_residuals_ct; // get()->get_value_time() deconstruct\n    LOG4_DEBUG(\"OEMD residual length \" << oemd_residuals_ct << \" CVMD residuals length \" << cvmd_residuals_ct);\n    auto start_row_iter = input_data.begin();\n    if (p_decon_queue and not p_decon_queue->get_data().empty()) { // Decon queue not empty\n        start_row_iter = upper_bound(input_data, p_decon_queue->get_data().rbegin()->get()->get_value_time());\n        if (start_row_iter == input_data.end()) {\n            LOG4_DEBUG(\"No data needs to be deconstructed for \" << p_input_queue->get_table_name() << \" \" << column_name);\n            return;\n        }\n        LOG4_TRACE(\"start_row_iter \" << start_row_iter->get()->get_value_time() << \" input_data rbegin value_time \" << input_data.rbegin()->get()->get_value_time() << \" p_decon_queue->get_data().rbegin()->get()->get_value_time() \" << p_decon_queue->get_data().rbegin()->get()->get_value_time());\n        const auto input_dist_begin = std::distance(input_data.begin(), start_row_iter);\n        std::advance(start_row_iter, - std::min(ssize_t(cvmd_residuals_ct), input_dist_begin));\n        if (input_dist_begin < (ssize_t) cvmd_residuals_ct)\n            LOG4_WARN(\"Not enough data in input queue \" << input_dist_begin << \" for deconstruction residuals \" << cvmd_residuals_ct);\n    }\n\n    LOG4_DEBUG(\"Input data size \" << input_data.size() << \" columns \" << input_data.begin()->get()->get_values().size() <<\n                                  \" VMD residual count \" << cvmd_residuals_ct << \" std::distance(input_data.begin(), start_row_iter) \" << std::distance(input_data.begin(), start_row_iter) <<\n                                  \" std::distance(start_row_iter, input_data.end()) \" << std::distance(start_row_iter, input_data.end()) << \" input_column_index \" << input_column_index);\n\n    const size_t half_levels_ct = p_dataset->get_transformation_levels() / 2;\n    std::vector<std::vector<double>> cvmd_decon, oemd_decon;\n    std::vector<std::vector<double>> phase_series;\n    {\n        std::vector<double> column_values(std::distance(start_row_iter, input_data.end()));\n        CILK_ITER(start_row_iter, column_values.size(),column_values[_IX] = _ITER->get()->get_value(input_column_index); );\n\n#ifdef NO_MAIN_DECON\n        if (p_input_queue->get_resolution().total_seconds() == MAIN_DECON_QUEUE_RES_SECS) {\n            LOG4_WARN(\"Dummy decon of main input queue \" << p_input_queue->get_table_name());\n            std::vector<std::vector<double>> decon(column_values.size());\n            phase_series.resize(column_values.size() + 1);\n            cilk_for(size_t t = 0; t < column_values.size(); ++t) {\n                phase_series[t].resize(half_levels_ct / 2, 0.);\n                decon[t].resize(p_dataset->get_transformation_levels(), 0.);\n                for (size_t half_l = 0; half_l < half_levels_ct; ++half_l) {\n                    decon[t][half_l * 2] = CVMD_INPUT_MULTIPLIER * column_values[t] / double(half_levels_ct);\n                }\n            };\n            phase_series.back().resize(half_levels_ct / 2, 0.);\n            copy_decon_data_to_container(decon_out, input_data, decon, phase_series, p_input_queue->get_resolution());\n            return;\n        }\n#endif\n\n        deconstruct_cvmd(p_dataset, p_input_queue, column_name, column_values, cvmd_decon, phase_series);\n    }\n\n    std::vector<double> input_oemd(cvmd_decon.size() - cvmd_residuals_ct_orig + oemd_residuals_ct);\n    {\n        // Copy CVMD data // TODO Omit tail?\n        const size_t oemd_cvmd_input_ct = std::min(input_oemd.size(), cvmd_decon.size());\n        for (size_t i = 0; i < oemd_cvmd_input_ct; ++i)\n            input_oemd[input_oemd.size() - oemd_cvmd_input_ct + i] = cvmd_decon[cvmd_decon.size() - oemd_cvmd_input_ct + i][0];\n\n        // Copy prev decon data\n        int64_t dist_decon = input_oemd.size() - cvmd_decon.size();\n        if (dist_decon > int64_t(p_decon_queue->get_data().size()))\n            dist_decon = p_decon_queue->get_data().size();\n        if (dist_decon < 0)\n            dist_decon = 0;\n        auto iter = std::prev(p_decon_queue->get_data().end(), dist_decon);\n        for (int64_t i = 0; i < dist_decon and iter != p_decon_queue->get_data().end(); ++i, ++iter)\n            input_oemd[input_oemd.size() - dist_decon - cvmd_decon.size() + i] = iter->get()->get_value(half_levels_ct);\n\n        if (input_oemd.size() > dist_decon + cvmd_decon.size())\n#ifndef ADD_MIRROR_TAIL_OEMD\n            input_oemd.erase(input_oemd.begin(), input_oemd.begin() + (input_oemd.size() - dist_decon - cvmd_decon.size()));\n#else\n        // Add mirror tail\n        mirror_tail(input_oemd, dist_decon + cvmd_decon.size());\n#endif\n\n        // Transform\n        PROFILE_EXEC_TIME(p_dataset->p_oemd_transformer_fat->transform(input_oemd, oemd_decon, input_oemd.size()),\n                          \"OEMD fat transform of \" << input_oemd.size() << \" values.\");\n    }\n\n    int64_t decon_ct;\n    if (cvmd_residuals_ct)\n        decon_ct = std::max(oemd_decon.size(), cvmd_decon.size()); // First deconstruct include the tail\n    else\n        decon_ct = cvmd_decon.size();\n    std::vector<std::vector<double>> decon(decon_ct); // Only new are in CVMD decon data while OEMD always contains a tail\n    cilk_for (int64_t t = 0; t < decon_ct; ++t) {\n        decon[t].resize(p_dataset->get_transformation_levels());\n\n        int64_t t_oemd = -1;\n        if (decon_ct < int64_t(oemd_decon.size()))\n            t_oemd = t + oemd_decon.size() - decon_ct;\n        else if (t >= decon_ct - int64_t(oemd_decon.size()))\n            t_oemd = t - (decon_ct - int64_t(oemd_decon.size()));\n\n        int64_t t_cvmd = -1;\n        if (decon_ct < int64_t(cvmd_decon.size()))\n            t_cvmd = t + cvmd_decon.size() - decon_ct;\n        else if (t >= decon_ct - int64_t(cvmd_decon.size()))\n            t_cvmd = t - (decon_ct - int64_t(cvmd_decon.size()));\n\n        for (size_t l = 0; l < p_dataset->get_transformation_levels(); ++l) {\n            if (l == half_levels_ct) {\n                decon[t][l] = t_oemd < 0 ? 0 : input_oemd[t_oemd]; // Mirrored tail for OEMD\n            } if (l < half_levels_ct) {\n                decon[t][l] = l % 2 == 1 ? 0 : (t_oemd < 0 ? 0 : oemd_decon[t_oemd][l / 2]); // OEMD decon\n            } else {\n                decon[t][l] = t_cvmd < 0 ? 0 : cvmd_decon[t_cvmd][l - half_levels_ct]; // CVMD decon\n            }\n        }\n        if (t_cvmd >= 0 && t_cvmd < (int64_t) cvmd_decon.size()) cvmd_decon[t_cvmd].clear();\n        if (t_oemd >= 0 && t_oemd < (int64_t) oemd_decon.size()) oemd_decon[t_oemd].clear();\n    }\n    input_oemd.clear();\n    cvmd_decon.clear();\n    oemd_decon.clear();\n\n    if (input_data.size() != decon.size())\n        LOG4_WARN(\"Input data size \" << input_data.size() << \" differs from decon matrix rows count  \" << decon.size());\n\n    copy_decon_data_to_container(decon_out, input_data, decon, phase_series, p_input_queue->get_resolution());\n\n#if 0 // Debug\n    {\n        for (const auto &decon_it : decon_out) {\n            double recon_last = 0;\n            for (size_t i = 0; i < decon_it.get()->get_values().size(); ++i) {\n                if (i == decon_it.get()->get_values().size() / 2 or i % 2 != 0) continue;\n                recon_last += decon_it.get()->get_value(i) / CVMD_INPUT_MULTIPLIER;\n            }\n            const auto input_it = input_data.lower_bound(decon_it.get()->get_value_time());\n            if (input_it == input_data.end()) {\n                LOG4_ERROR(\"Could not find time \" << input_it->get()->get_value_time());\n                continue;\n            }\n            if (std::abs(recon_last - input_data.rbegin()->get()->get_value(input_column_index)) > 1e-6) {\n                LOG4_ERROR(\"recon_last \" << recon_last << \" != input_data.rbegin()->get()->get_value(input_column_index) \"\n                                         << input_it->get()->get_value(input_column_index));\n            }\n            if (decon_it.get()->get_value_time() != input_it->get()->get_value_time() or decon_it.get()->get_value_time() != input_it->get()->get_value_time() or decon_it.get()->get_value_time() != input_it->get()->get_value_time())\n                LOG4_ERROR(\"decon_out.rbegin()->get()->get_value_time() != input_data.rbegin()->get()->get_value_time()\");\n        }\n    }\n#endif\n\n    LOG4_END();\n}\n\n#if 0\nvoid\nDeconQueueService::deconstruct_batch(\n        const InputQueue_ptr &p_input_queue,\n        const Dataset_ptr &p_dataset,\n        const string &column_name,\n        svr::datamodel::DataRow::container &decon_data)\n{\n    LOG4_BEGIN();\n\n    const auto input_data = p_input_queue->get_data();\n    if (input_data.empty()) {\n        LOG4_ERROR(\"Data is empty.\");\n        return;\n    }\n    const auto input_column_index = InputQueueService::get_value_column_index(p_input_queue, column_name);\n\n    if (input_column_index >= input_data.begin()->get()->get_values().size())\n        THROW_EX_F(std::range_error, \"Column index out of bounds \" << input_column_index);\n    std::vector<double> column_values(input_data.size());\n    // TODO set times correctly when the output decon size is smaller than the input decon size.\n    CILK_ITER(input_data.begin(), column_values.size(), column_values[_IX] = _ITER->get()->get_value(input_column_index));\n    std::vector<std::vector<double>> cvmd_raw_decon_data, oemd_raw_decon_data, phase_series;\n    deconstruct_cvmd(p_dataset, p_input_queue, column_name, p_cvmd_transformer, column_values, cvmd_raw_decon_data, phase_series, true);\n\n    if (p_dataset->get_transformation_levels_cvmd() != cvmd_raw_decon_data[0].size())\n        THROW_EX_FS(std::runtime_error, \"Transformation levels CVMD \" << p_dataset->get_transformation_levels_cvmd() <<\n                                                                 \" != cvmd_raw_decon_data[0].size() \" << cvmd_raw_decon_data[0].size());\n\n    if (input_data.size() != cvmd_raw_decon_data.size())\n        LOG4_WARN(\"Input data size \" << input_data.size() << \" differs from decon matrix rows count  \" << cvmd_raw_decon_data.size());\n\n    std::vector<double> input_oemd(cvmd_raw_decon_data.size());\n    cilk_for (size_t i = 0; i < cvmd_raw_decon_data.size(); ++i) {\n        input_oemd[i] = cvmd_raw_decon_data[i][0];\n    }\n    oemd_transformer->transform(input_oemd, oemd_raw_decon_data, column_values.size());\n\n    std::vector<std::vector<double>> raw_decon_data(cvmd_raw_decon_data.size()); // Only new are in CVMD decon data while OEMD always contains a tail\n    cilk_for (size_t t = 0; t < raw_decon_data.size(); ++t) {\n        raw_decon_data[t].resize(p_dataset->get_transformation_levels());\n        cilk_for (size_t l = 0; l < p_dataset->get_transformation_levels(); ++l) {\n            if (l < p_dataset->get_transformation_levels_cvmd()) // Lower bands are OEMDed\n                raw_decon_data[t][l] = l % 2 ? 0 : oemd_raw_decon_data[oemd_raw_decon_data.size() - cvmd_raw_decon_data.size() + t][l / 2];\n            else // Upper bands are CVMDed\n                raw_decon_data[t][l] = cvmd_raw_decon_data[t][l - p_dataset->get_transformation_levels_cvmd()];\n        }\n    }\n\n    copy_decon_data_to_container(decon_data, input_data, raw_decon_data, phase_series);\n    // Erase tail, CVMD tail > oemd residuals count\n    decon_data.erase(decon_data.begin(), std::next(decon_data.begin(), svr::cvmd::get_residuals_length(p_dataset->get_transformation_levels_cvmd(), \"DUMMY TABLE\")));\n    LOG4_END();\n}\n#endif\n\nvoid\nDeconQueueService::deconstruct_cvmd(\n    const Dataset_ptr &p_dataset,\n    const InputQueue_ptr &p_input_queue,\n    const string &column_name,\n    const vector<double> &column_values,\n    vector<std::vector<double>> &raw_deconstructed_data,\n    vector<std::vector<double>> &phase_series,\n    const bool do_batch) const\n{\n    const auto p_decon_queue = p_dataset->get_decon_queue(p_input_queue, column_name);\n    const auto decon_queue_table_name = p_decon_queue->get_table_name();\n\n    if (not p_dataset->p_cvmd_transformer->initialized(decon_queue_table_name)) {\n        // Calculate omega from first PART_VMD_COUNT values\n        const auto tail_len = p_dataset->p_cvmd_transformer->get_residuals_length(\"__DUMMY__\");\n        auto p_omega_input_queue = p_input_queue->clone_empty();\n        p_omega_input_queue->set_data(APP.input_queue_service.get_queue_data(p_input_queue->get_table_name(), bpt::min_date_time, bpt::max_date_time, tail_len));\n        auto omega_column_values = p_omega_input_queue->get_column_values(column_name, 0, tail_len);\n        if (omega_column_values.size() < tail_len)\n            LOG4_ERROR(\"Not enough \" << omega_column_values.size() << \" values for VMD frequency bands calculation.\");\n        PROFILE_EXEC_TIME(p_dataset->p_cvmd_transformer->initialize(omega_column_values, decon_queue_table_name, /* load state */ true), \"CVMD initialize\");\n    }\n\n    // Do batch\n    if (do_batch or p_decon_queue->get_data().empty()) {\n        const auto start_input_pos = test_start_cvmd_pos ? test_start_cvmd_pos : APP.input_queue_service.get_count_from_start(p_input_queue, p_input_queue->get_data().begin()->get()->get_value_time());\n        PROFILE_EXEC_TIME(p_dataset->p_cvmd_transformer->transform(column_values, raw_deconstructed_data, decon_queue_table_name, phase_series, start_input_pos), \"CVMD batch transform\");\n    // Do online\n    } else {\n        const auto last_decon_values_iter = p_decon_queue->get_data().rbegin();\n        for (const auto &p_row: p_decon_queue->get_data()) LOG4_DEBUG(\"Row at \" << p_row->get_value_time() << \" phases \" << svr::common::deep_to_string(p_row->get_phases()));\n        std::vector<double> u_v_values(std::next(last_decon_values_iter->get()->get_values().begin(), last_decon_values_iter->get()->get_values().size() / 2), last_decon_values_iter->get()->get_values().end());\n        const auto start_phases = last_decon_values_iter->get()->get_phases().empty() ? p_dataset->p_cvmd_transformer->calculate_phases(2 + APP.input_queue_service.get_count_from_start(p_input_queue, p_decon_queue->get_data().rbegin()->get()->get_value_time()), decon_queue_table_name) : last_decon_values_iter->get()->get_phases();\n        LOG4_TRACE(\"Start phases for time \" << last_decon_values_iter->get()->get_value_time() << \" \" << decon_queue_table_name << \" \"\": \" << svr::common::deep_to_string(start_phases));\n        LOG4_TRACE(\"Unscaled U V Values for time \" << last_decon_values_iter->get()->get_value_time()  << decon_queue_table_name << \" \" \": \" << svr::common::deep_to_string(u_v_values));\n        PROFILE_EXEC_TIME(p_dataset->p_cvmd_transformer->transform(column_values, raw_deconstructed_data, decon_queue_table_name, u_v_values, phase_series, start_phases), \"CVMD online transform\");\n#if 0 // DEBUG\n        for (size_t t = 0; t < phase_series[0].size(); ++t) {\n            std::stringstream st;\n            st.precision(std::numeric_limits<double>::max_digits10);\n            for (size_t l = 0; l < phase_series.size(); ++l) {\n                st << l << \":\" << phase_series[l][t] << \", \";\n            }\n            st << std::endl;\n            LOG4_TRACE(\"Phase series \" << decon_queue_table_name << \" \" << t << \" \" << st.str());\n        }\n#endif\n    }\n}\n\n\ninline void\nDeconQueueService::copy_decon_data_to_container(\n        DataRow::container &decon_out,\n        const DataRow::container &input_data,\n        std::vector<std::vector<double>> &decon,\n        std::vector<std::vector<double>> &phase_series,\n        const boost::posix_time::time_duration &resolution)\n{\n    auto input_data_row_iter = input_data.size() > decon.size() ? std::next(input_data.begin(), input_data.size() - decon.size()) : input_data.begin();\n\n    LOG4_DEBUG(\"Deconstructed size \" << decon.size() << \" using input data rows count \" << std::distance(input_data_row_iter, input_data.end()) <<\n                                     \" from \" << input_data_row_iter->get()->get_value_time() << \" to \" << input_data.rbegin()->get()->get_value_time() << \" phase series size \" << phase_series.size() << \"x\" << (phase_series.empty() ? 0 : phase_series.front().size()));\n#ifdef SAVE_TAIL\n    if (decon.size() > input_data.size()) {\n        const bpt::ptime time_iter = input_data.begin()->get()->get_value_time() - resolution;\n        for (size_t t = 0; t < decon.size() - input_data.size(); ++t) {\n            decon_out[time_iter - resolution * t] = std::make_shared<DataRow>(\n                    time_iter - resolution * t,\n                    boost::posix_time::second_clock::local_time(),\n                    0,\n                    decon[decon.size() - 1 - t],\n                    phase_series.empty() ? std::vector<double>{} : std::vector<double>(phase_series.front().size(), 0.));\n        }\n    }\n#endif\n    const auto start_decon_row_ix = input_data.size() >= decon.size() ? 0 : decon.size() - input_data.size();\n    const auto end_row_pos = decon.size();\n    auto ins_it = lower_bound(decon_out, input_data_row_iter->get()->get_value_time());\n    if (ins_it != decon_out.end()) decon_out.erase(ins_it, decon_out.end());\n    if (phase_series.empty()) {\n        for (size_t decon_row_ix = start_decon_row_ix;\n             decon_row_ix < end_row_pos && input_data_row_iter != input_data.end();\n             ++decon_row_ix, ++input_data_row_iter) {\n            decon_out.push_back(std::make_shared<DataRow>(\n                    input_data_row_iter->get()->get_value_time(),\n                    boost::posix_time::second_clock::local_time(),\n                    input_data_row_iter->get()->get_tick_volume(),\n                    decon[decon_row_ix],\n                    std::vector<double>{}));\n            decon[decon_row_ix].clear();\n        }\n    } else {\n        for (size_t decon_row_ix = start_decon_row_ix;\n             decon_row_ix < end_row_pos && input_data_row_iter != input_data.end();\n             ++decon_row_ix, ++input_data_row_iter) {\n            const int64_t phase_row = phase_series.size() - decon.size() + decon_row_ix/* - start_decon_row_ix*/;\n            //LOG4_DEBUG(\"const int64_t phase_row \" << phase_row << \"= phase_series.size() \" << phase_series.size() << \" - decon.size() \" << decon.size() << \" + decon_row_ix \" << decon_row_ix << \" /* - start_decon_row_ix \" << start_decon_row_ix);\n            decon_out.push_back(std::make_shared<DataRow>(\n                    input_data_row_iter->get()->get_value_time(),\n                    boost::posix_time::second_clock::local_time(),\n                    input_data_row_iter->get()->get_tick_volume(),\n                    decon[decon_row_ix],\n                    phase_row < 0 ? std::vector<double>(phase_series.front().size(), 0.) : phase_series[phase_row]));\n            if (phase_row >= 0 && phase_row < (int64_t) phase_series.size()) phase_series[phase_row].clear();\n            decon[decon_row_ix].clear();\n        }\n    }\n    LOG4_DEBUG(\"Output decon data from \" << decon_out.begin()->get()->get_value_time() << \" to \" << decon_out.rbegin()->get()->get_value_time() << \" size \" << decon_out.size());\n}\n\n\nvoid\nDeconQueueService::copy_recon_frame_to_container(\n        const svr::datamodel::DataRow::container &decon_data,\n        const std::set<ptime> &times,\n        DataRow::container &recon_data,\n        const vector<double> &reconstructed_values,\n        const size_t limit)\n{\n    if (reconstructed_values.size() != times.size()) LOG4_THROW(\n        \"Reconstructed data size \" << reconstructed_values.size() << \" does not equal times size \" << times.size());\n\n    LOG4_DEBUG(\"Copying \" << (limit < reconstructed_values.size() ? limit : reconstructed_values.size()) <<\n                          \" rows with starting value time \" << *times.begin() << \" ending value time \" << *times.rbegin());\n    auto ins_it = lower_bound(recon_data, *times.begin());\n    if (ins_it != recon_data.end()) recon_data.erase(ins_it, recon_data.end());\n\n    auto time_iter = times.begin();\n    for (size_t j = 0; j < reconstructed_values.size() && time_iter != times.end() && j < limit; ++j, ++time_iter) {\n        const auto row_iter = find(decon_data, *time_iter);\n        if (row_iter == decon_data.end()) LOG4_THROW(\"Time \" << *time_iter << \" not found in decon data.\");\n        recon_data.push_back(std::make_shared<DataRow>(\n                *time_iter, bpt::second_clock::local_time(), row_iter->get()->get_tick_volume(), std::vector<double>{reconstructed_values[j]}));\n    }\n    LOG4_END();\n}\n\n\ndata_row_container DeconQueueService::reconstruct(\n        const svr::datamodel::datarow_range &data,\n        const string &transformation_name,\n        const size_t n_decomposition_levels)\n{\n    data_row_container out_data_container;\n    reconstruct(data, transformation_name, n_decomposition_levels, out_data_container);\n    return out_data_container;\n}\n\n\nvoid DeconQueueService::reconstruct(\n        const svr::datamodel::datarow_range &data,\n        const string &transformation_name,\n        const size_t n_decomposition_levels,\n        data_row_container &out_data_container)\n{\n    LOG4_BEGIN();\n    if (data.distance() < 1) LOG4_THROW(\"No data to reconstruct.\");\n    const auto count = data.distance();\n    LOG4_DEBUG(\"Reconstructing \" << count << \" rows of \" << n_decomposition_levels << \" levels.\");\n    std::set<bpt::ptime> times;\n    std::mutex mx;\n    std::vector<double> recon_values(count);\n    // TODO: set times correctly when the output decon size is smaller than the input decon size.\n    CILK_ITER (data.begin(), count, ;\n        double row_val = 0;\n        for (size_t half_level_ix = 0; half_level_ix < n_decomposition_levels / 2; ++half_level_ix) {\n            if (half_level_ix * 2 != n_decomposition_levels / 2)\n                row_val += _ITER->get()->get_value(half_level_ix * 2) / CVMD_INPUT_MULTIPLIER;\n        }\n        recon_values[_IX] = row_val;\n        LOG4_TRACE(\"Reconstructed value \" << row_val << \" for \" << _ITER->get()->get_value_time());\n        const std::lock_guard<std::mutex> l(mx);\n        times.insert(_ITER->get()->get_value_time());\n    );\n\n    copy_recon_frame_to_container(data.get_container(), times, out_data_container, recon_values);\n\n#if 0\n    {\n        static size_t call_ct = 0;\n        {\n            std::stringstream ss;\n            for (auto row_iter = out_data_container.begin(); row_iter != out_data_container.end(); ++row_iter) {\n                ss << row_iter->get()->to_string() << std::endl;\n            }\n            std::stringstream ss_name;\n            ss_name << \"/mnt/faststore/recon_\" << call_ct << \"_out_data_container.csv\";\n            LOG4_FILE(ss_name.str(), ss.str());\n        }\n        {\n            std::stringstream ss;\n            for (auto row_iter = data.get_container().begin(); row_iter != data.get_container().end(); ++row_iter) {\n                ss << row_iter->get()->to_string() << std::endl;\n            }\n            std::stringstream ss_name;\n            ss_name << \"/mnt/faststore/recon_\" << call_ct << \"_in_data_container.csv\";\n            LOG4_FILE(ss_name.str(), ss.str());\n        }\n        call_ct++;\n    }\n#endif\n\n    LOG4_END();\n}\n\n\nsize_t\nDeconQueueService::load_decon_data(const DeconQueue_ptr &decon_queue, const ptime &time_from, const ptime &time_to, const size_t limit)\n{\n    reject_nullptr(decon_queue);\n    deque<DataRow_ptr> new_data = decon_queue_dao.get_data(decon_queue->get_table_name(), time_from, time_to, limit);\n    data_row_container &decon_queue_data = decon_queue->get_data();\n    if (!new_data.empty() and !decon_queue_data.empty() and new_data.front()->get_value_time() <= decon_queue_data.back()->get_value_time())\n        decon_queue_data.erase(lower_bound(decon_queue_data, new_data.front()->get_value_time()), decon_queue_data.end());\n    decon_queue_data.insert(decon_queue_data.end(), new_data.begin(), new_data.end());\n    return new_data.size();\n}\n\n\nsize_t DeconQueueService::load_latest_decon_data(const DeconQueue_ptr &decon_queue, const ptime &time_to, const size_t limit)\n{\n    LOG4_DEBUG(\"Loading \" << limit << \" values until \" << time_to << \" from decon queue \" << decon_queue->get_table_name());\n    reject_nullptr(decon_queue);\n    deque<DataRow_ptr> new_data;\n    try {\n        new_data = decon_queue_dao.get_latest_data(decon_queue->get_table_name(), time_to, limit);\n    } catch (const std::exception &ex) {\n        LOG4_WARN(\"Error loading data from decon queue \" << decon_queue->get_table_name() << \". \" << ex.what());\n        return 0;\n    }\n    data_row_container &decon_queue_data = decon_queue->get_data();\n    if (!new_data.empty() and !decon_queue_data.empty() and new_data.front()->get_value_time() <= decon_queue_data.back()->get_value_time())\n        decon_queue_data.erase(lower_bound(decon_queue_data, new_data.front()->get_value_time()), decon_queue_data.end());\n    decon_queue_data.insert(decon_queue_data.end(), new_data.begin(), new_data.end());\n    LOG4_DEBUG(\"Retrieved \" << new_data.size() << \" rows.\");\n    return new_data.size();\n}\n\nint DeconQueueService::clear(const DeconQueue_ptr &decon_queue)\n{\n    reject_nullptr(decon_queue);\n    return decon_queue_dao.clear(decon_queue);\n}\n\nlong DeconQueueService::count(const DeconQueue_ptr &decon_queue)\n{\n    reject_nullptr(decon_queue);\n    return decon_queue_dao.count(decon_queue);\n}\n\n\n\nDeconQueue_ptr &DeconQueueService::find_decon_queue(\n        std::vector<DeconQueue_ptr> &decon_queues,\n        const std::string &input_queue_table_name,\n        const std::string &input_queue_column_name)\n{\n    LOG4_BEGIN();\n    auto p_decon_queue_iter = find_if(\n            decon_queues.begin(),\n            decon_queues.end(),\n            [&input_queue_table_name, &input_queue_column_name](const DeconQueue_ptr &p_decon_queue)\n            {\n                return p_decon_queue->get_input_queue_table_name() == input_queue_table_name &&\n                       p_decon_queue->get_input_queue_column_name() == input_queue_column_name;\n            }\n    );\n\n    if (p_decon_queue_iter == decon_queues.end())\n        THROW_EX_F(std::invalid_argument, \"Couldn't not find decon queue for table name \" << input_queue_table_name <<\n        \" column \" << input_queue_column_name << \" decon queues count \" << decon_queues.size());\n\n    return *p_decon_queue_iter;\n}\n\nconst DeconQueue_ptr &DeconQueueService::find_decon_queue(\n        const std::vector<DeconQueue_ptr> &decon_queues,\n        const std::string &input_queue_table_name,\n        const std::string &input_queue_column_name)\n{\n    LOG4_DEBUG(\"Looking for \" << input_queue_table_name << \" \" << input_queue_column_name);\n\n    auto p_decon_queue_iter = find_if(\n            decon_queues.begin(),\n            decon_queues.end(),\n            [&input_queue_table_name, &input_queue_column_name](const DeconQueue_ptr &p_decon_queue)\n            {\n                return p_decon_queue->get_input_queue_table_name() == input_queue_table_name &&\n                       p_decon_queue->get_input_queue_column_name() == input_queue_column_name;\n            }\n    );\n\n    if (p_decon_queue_iter == decon_queues.end())\n        THROW_EX_F(std::invalid_argument, \"Couldn't not find decon queue for table name \" << input_queue_table_name <<\n                                                                                          \" column \" << input_queue_column_name << \" decon queues count \" << decon_queues.size());\n\n    return *p_decon_queue_iter;\n}\n\nconst DeconQueue_ptr DeconQueueService::decon_queue_delta(const DeconQueue_ptr &p_original_decon_queue, const bool leave_anchor)\n{\n    LOG4_BEGIN();\n#ifndef ALL_LEVELS_DELTA\n    return p_original_decon_queue;//->clone();\n#endif\n\n    if (p_original_decon_queue->get_data().empty()) return svr::datamodel::DeconQueue_ptr();\n    auto p_delta_decon_queue = p_original_decon_queue->clone_empty();\n    // TODO Use CILK_ITER\n    auto row_iter = p_original_decon_queue->data_.begin();\n    for (size_t row_ix = 0; row_ix < p_original_decon_queue->data_.size(); ++row_ix, ++row_iter) {\n        auto row_ptr = std::make_shared<DataRow>(**row_iter);\n        if (row_ix == 0) {\n            row_ptr->set_anchor(true);\n        } else {\n            TPFOR(size_t, l, 0, row_ptr->get_values().size(),\n                row_ptr->set_value(l, svr::common::diff_return(row_ptr->get_value(l), std::prev(row_iter)->get()->get_value(l)));\n            )\n            row_ptr->set_anchor(false);\n        }\n        p_delta_decon_queue->data_.push_back(row_ptr);\n    }\n\n    if (not leave_anchor) p_delta_decon_queue->data_.erase(p_delta_decon_queue->data_.begin());\n\n    return p_delta_decon_queue;\n}\n\nDeconQueue_ptr DeconQueueService::decon_queue_undelta(const DeconQueue_ptr &p_delta_decon_queue)\n{\n    LOG4_BEGIN();\n#ifndef ALL_LEVELS_DELTA\n    return p_delta_decon_queue;\n#endif\n\n    if (p_delta_decon_queue->get_data().empty()) return svr::datamodel::DeconQueue_ptr();\n    //LOG4_DEBUG(p_delta_decon_queue->data_to_string());\n    auto p_decon_queue = p_delta_decon_queue->clone_empty();\n    auto row_iter_delta = p_delta_decon_queue->data_.begin();\n    for (size_t row_ix = 0; row_ix < p_delta_decon_queue->data_.size(); ++row_ix, ++row_iter_delta) {\n        auto cur_row_ptr = std::make_shared<DataRow>(**row_iter_delta);\n        if (row_ix == 0) {\n            if (not cur_row_ptr->is_anchor()) LOG4_THROW(\"First row should be anchor!\");\n        } else {\n            const auto prev_row_iter = std::next(p_decon_queue->data_.begin(), row_ix - 1);\n            if (not prev_row_iter->get()->is_anchor()) LOG4_THROW(\"Previous row \" << row_ix - 1 << \" not an anchor!\");\n            cilk_for (size_t l = 0; l < cur_row_ptr->get_values().size(); ++l) {\n                const auto prev_anch_val = prev_row_iter->get()->get_value(l);\n                cur_row_ptr->set_value(l, svr::common::inv_diff_return(cur_row_ptr->get_value(l), prev_anch_val));\n            }\n            cur_row_ptr->set_anchor(true);\n        }\n        p_decon_queue->data_.push_back(cur_row_ptr);\n    }\n    //LOG4_DEBUG(p_decon_queue->data_to_string());\n    return p_decon_queue;\n}\n\n} // business\n} // svr\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- SVRRoot/SVRBusiness/src/DeconQueueService.cpp	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ SVRRoot/SVRBusiness/src/DeconQueueService.cpp	(date 1672580107112)
@@ -1,8 +1,8 @@
 #include "DeconQueueService.hpp"
 
-#include <model/FramesContainer.hpp>
-#include <util/ValidationUtils.hpp>
-#include <util/math_utils.hpp>
+#include "model/FramesContainer.hpp"
+#include "util/ValidationUtils.hpp"
+#include "util/math_utils.hpp"
 #include "model/InputQueue.hpp"
 #include "model/DeconQueue.hpp"
 #include "model/Dataset.hpp"
@@ -10,9 +10,9 @@
 #include "InputQueueService.hpp"
 #include "appcontext.hpp"
 
-#include <modwt_transform.hpp>
-#include <online_emd.hpp>
-#include <cvmd.hpp>
+#include "modwt_transform.hpp"
+#include "online_emd.hpp"
+#include "fast_cvmd.hpp"
 
 // #define SWT_DEBUG
 
@@ -355,6 +355,8 @@
         // Add mirror tail
         mirror_tail(input_oemd, dist_decon + cvmd_decon.size());
 #endif
+        if (PROPS.get_oemd_find_fir_coefficients() and not p_dataset->p_oemd_transformer_fat->get_fir_coefs_initialized())
+            p_dataset->p_oemd_transformer_fat->find_fir_coefficients(input_oemd, cvmd_decon.size() - cvmd_residuals_ct_orig);
 
         // Transform
         PROFILE_EXEC_TIME(p_dataset->p_oemd_transformer_fat->transform(input_oemd, oemd_decon, input_oemd.size()),
@@ -429,61 +431,6 @@
     LOG4_END();
 }
 
-#if 0
-void
-DeconQueueService::deconstruct_batch(
-        const InputQueue_ptr &p_input_queue,
-        const Dataset_ptr &p_dataset,
-        const string &column_name,
-        svr::datamodel::DataRow::container &decon_data)
-{
-    LOG4_BEGIN();
-
-    const auto input_data = p_input_queue->get_data();
-    if (input_data.empty()) {
-        LOG4_ERROR("Data is empty.");
-        return;
-    }
-    const auto input_column_index = InputQueueService::get_value_column_index(p_input_queue, column_name);
-
-    if (input_column_index >= input_data.begin()->get()->get_values().size())
-        THROW_EX_F(std::range_error, "Column index out of bounds " << input_column_index);
-    std::vector<double> column_values(input_data.size());
-    // TODO set times correctly when the output decon size is smaller than the input decon size.
-    CILK_ITER(input_data.begin(), column_values.size(), column_values[_IX] = _ITER->get()->get_value(input_column_index));
-    std::vector<std::vector<double>> cvmd_raw_decon_data, oemd_raw_decon_data, phase_series;
-    deconstruct_cvmd(p_dataset, p_input_queue, column_name, p_cvmd_transformer, column_values, cvmd_raw_decon_data, phase_series, true);
-
-    if (p_dataset->get_transformation_levels_cvmd() != cvmd_raw_decon_data[0].size())
-        THROW_EX_FS(std::runtime_error, "Transformation levels CVMD " << p_dataset->get_transformation_levels_cvmd() <<
-                                                                 " != cvmd_raw_decon_data[0].size() " << cvmd_raw_decon_data[0].size());
-
-    if (input_data.size() != cvmd_raw_decon_data.size())
-        LOG4_WARN("Input data size " << input_data.size() << " differs from decon matrix rows count  " << cvmd_raw_decon_data.size());
-
-    std::vector<double> input_oemd(cvmd_raw_decon_data.size());
-    cilk_for (size_t i = 0; i < cvmd_raw_decon_data.size(); ++i) {
-        input_oemd[i] = cvmd_raw_decon_data[i][0];
-    }
-    oemd_transformer->transform(input_oemd, oemd_raw_decon_data, column_values.size());
-
-    std::vector<std::vector<double>> raw_decon_data(cvmd_raw_decon_data.size()); // Only new are in CVMD decon data while OEMD always contains a tail
-    cilk_for (size_t t = 0; t < raw_decon_data.size(); ++t) {
-        raw_decon_data[t].resize(p_dataset->get_transformation_levels());
-        cilk_for (size_t l = 0; l < p_dataset->get_transformation_levels(); ++l) {
-            if (l < p_dataset->get_transformation_levels_cvmd()) // Lower bands are OEMDed
-                raw_decon_data[t][l] = l % 2 ? 0 : oemd_raw_decon_data[oemd_raw_decon_data.size() - cvmd_raw_decon_data.size() + t][l / 2];
-            else // Upper bands are CVMDed
-                raw_decon_data[t][l] = cvmd_raw_decon_data[t][l - p_dataset->get_transformation_levels_cvmd()];
-        }
-    }
-
-    copy_decon_data_to_container(decon_data, input_data, raw_decon_data, phase_series);
-    // Erase tail, CVMD tail > oemd residuals count
-    decon_data.erase(decon_data.begin(), std::next(decon_data.begin(), svr::cvmd::get_residuals_length(p_dataset->get_transformation_levels_cvmd(), "DUMMY TABLE")));
-    LOG4_END();
-}
-#endif
 
 void
 DeconQueueService::deconstruct_cvmd(
@@ -506,22 +453,22 @@
         auto omega_column_values = p_omega_input_queue->get_column_values(column_name, 0, tail_len);
         if (omega_column_values.size() < tail_len)
             LOG4_ERROR("Not enough " << omega_column_values.size() << " values for VMD frequency bands calculation.");
-        PROFILE_EXEC_TIME(p_dataset->p_cvmd_transformer->initialize(omega_column_values, decon_queue_table_name, /* load state */ true), "CVMD initialize");
+        PROFILE_EXEC_TIME(p_dataset->p_cvmd_transformer->initialize(omega_column_values, decon_queue_table_name), "CVMD initialize");
     }
 
     // Do batch
     if (do_batch or p_decon_queue->get_data().empty()) {
-        const auto start_input_pos = test_start_cvmd_pos ? test_start_cvmd_pos : APP.input_queue_service.get_count_from_start(p_input_queue, p_input_queue->get_data().begin()->get()->get_value_time());
-        PROFILE_EXEC_TIME(p_dataset->p_cvmd_transformer->transform(column_values, raw_deconstructed_data, decon_queue_table_name, phase_series, start_input_pos), "CVMD batch transform");
+        // const auto start_input_pos = test_start_cvmd_pos ? test_start_cvmd_pos : APP.input_queue_service.get_count_from_start(p_input_queue, p_input_queue->get_data().begin()->get()->get_value_time());
+        PROFILE_EXEC_TIME(p_dataset->p_cvmd_transformer->transform(column_values, raw_deconstructed_data, decon_queue_table_name), "CVMD batch transform");
     // Do online
     } else {
         const auto last_decon_values_iter = p_decon_queue->get_data().rbegin();
         for (const auto &p_row: p_decon_queue->get_data()) LOG4_DEBUG("Row at " << p_row->get_value_time() << " phases " << svr::common::deep_to_string(p_row->get_phases()));
         std::vector<double> u_v_values(std::next(last_decon_values_iter->get()->get_values().begin(), last_decon_values_iter->get()->get_values().size() / 2), last_decon_values_iter->get()->get_values().end());
-        const auto start_phases = last_decon_values_iter->get()->get_phases().empty() ? p_dataset->p_cvmd_transformer->calculate_phases(2 + APP.input_queue_service.get_count_from_start(p_input_queue, p_decon_queue->get_data().rbegin()->get()->get_value_time()), decon_queue_table_name) : last_decon_values_iter->get()->get_phases();
-        LOG4_TRACE("Start phases for time " << last_decon_values_iter->get()->get_value_time() << " " << decon_queue_table_name << " "": " << svr::common::deep_to_string(start_phases));
+        //const auto start_phases = last_decon_values_iter->get()->get_phases().empty() ? p_dataset->p_cvmd_transformer->calculate_phases(2 + APP.input_queue_service.get_count_from_start(p_input_queue, p_decon_queue->get_data().rbegin()->get()->get_value_time()), decon_queue_table_name) : last_decon_values_iter->get()->get_phases();
+        //LOG4_TRACE("Start phases for time " << last_decon_values_iter->get()->get_value_time() << " " << decon_queue_table_name << " "": " << svr::common::deep_to_string(start_phases));
         LOG4_TRACE("Unscaled U V Values for time " << last_decon_values_iter->get()->get_value_time()  << decon_queue_table_name << " " ": " << svr::common::deep_to_string(u_v_values));
-        PROFILE_EXEC_TIME(p_dataset->p_cvmd_transformer->transform(column_values, raw_deconstructed_data, decon_queue_table_name, u_v_values, phase_series, start_phases), "CVMD online transform");
+        PROFILE_EXEC_TIME(p_dataset->p_cvmd_transformer->transform(column_values, raw_deconstructed_data, decon_queue_table_name, u_v_values), "CVMD online transform");
 #if 0 // DEBUG
         for (size_t t = 0; t < phase_series[0].size(); ++t) {
             std::stringstream st;
Index: SVRRoot/OnlineSVR/test/cvmd_tests.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>//\n// Created by zarko on 30.12.20 г..\n//\n#include <gtest/gtest.h>\n#include <fstream>\n#include \"../include/spectral_transform.hpp\"\n#include \"../include/cvmd.hpp\"\n#include <chrono>\n#include \"test_harness.hpp\"\n#include \"util/StringUtils.hpp\"\n#include <fstream>\n#include <DQScalingFactorService.hpp>\n#include \"DeconQueueService.hpp\"\n#include \"model/DataRow.hpp\"\n\n#define DECON_LEVELS 64\n#define TEST_TOL 1e-6\n\nconst std::string transform_input_filename = \"cvmd_test_data/transform_input\";\nconst std::string transform_result_filename = \"cvmd_test_data/transform_output_real\";\n\n// TODO Add real EURSUD data and complete test\nnamespace {\n\nclass cvmd_transform_test : public testing::Test\n{\npublic:\n    cvmd_transform_test()\n    {\n    }\n    ~cvmd_transform_test() = default;\n\n    virtual\n    void SetUp(\n            const std::string &input_filename,\n            const std::string &exp_output_filename,\n            const size_t levels = DECON_LEVELS)\n    {\n        this->transformer = svr::spectral_transform::create(std::string(\"cvmd\"), levels - 1);\n        auto input_f = open_data_file(input_filename);\n        EXPECT_TRUE(input_f.good());\n        std::string line;\n        while(not input_f.eof()) {\n            std::getline(input_f, line);\n            if (line.empty()) continue;\n            input.push_back(std::atof(line.c_str()));\n        }\n        EXPECT_TRUE(input_f.eof());\n    }\n\n    //virtual void TearDown(){}\n    std::vector<double> input;\n    std::ifstream result_f;\n    std::unique_ptr<svr::spectral_transform> transformer;\n};\n\nTEST_F(cvmd_transform_test, test_transform_correctness)\n{\n    SetUp(transform_input_filename, transform_result_filename);\n    std::vector<std::vector<double>> decon, phase_series;\n    std::vector<double> recon;\n    auto start = std::chrono::steady_clock::now();\n    const auto p_cvmd_transformer = dynamic_cast<svr::cvmd *>(transformer.get());\n    std::vector<double> input_trimmed(input.begin() + input.size() - 40400, input.end());\n    PROFILE_EXEC_TIME(p_cvmd_transformer->initialize(input_trimmed, \"Test table\"), \"VMD initialize\");\n    PROFILE_EXEC_TIME(p_cvmd_transformer->transform(input_trimmed, decon, \"Test table\", phase_series, 0), \"VMD batch transform\");\n/*\n    data_row_container decon_data;\n    data_row_container input_data;\n    for (size_t i = 0; i < input_trimmed.size(); ++i) {\n        const boost::posix_time::ptime row_time = boost::posix_time::second_clock::local_time() + boost::posix_time::hours(4 * i);\n        input_data.insert({row_time, std::make_shared<svr::datamodel::DataRow>(row_time, row_time, 0, std::vector<double>(input_trimmed[i]))});\n    }\n    //svr::business::DeconQueueService::copy_decon_data_to_container(decon_data, input_data, decon, phase_series);\n    const std::vector<double> scaling_factors(DECON_LEVELS, .0001);\n    const std::vector<double> mean_values(DECON_LEVELS, 0);\n    //auto delta_data = svr::business::DeconQueueService::decon_queue_delta(decon_data, true);\n//    svr::business::DQScalingFactorService::scale_decon_queue(delta_data, scaling_factors, mean_values);\n*/\n    LOG4_INFO(\"Transformation took: \" << std::chrono::duration<float>(std::chrono::steady_clock::now() - start).count() << \" seconds, decon size \" << decon.size() << \" x \" << decon[0].size());\n    std::vector<double> decon_flat(decon.size() * decon[0].size());\n    PFOR(r, 0, decon.size(),\n        for (size_t l = 0; l < decon[r].size(); ++l) {\n            decon_flat[r + l * decon.size()] = decon[r][l];\n        }\n    )\n    p_cvmd_transformer->inverse_transform(decon_flat, recon, 0);\n    double total_diff = 0.;\n    double highest_diff = 0.;\n    for (size_t i = p_cvmd_transformer->get_residuals_length(\"Test table\"); i < recon.size(); ++i) {\n        const auto diff = std::abs(input_trimmed[i] - recon[i]);\n        if (diff > highest_diff) highest_diff = diff;\n        EXPECT_NEAR(input_trimmed[i], recon[i], TEST_TOL);\n        if (diff > TEST_TOL) LOG4_WARN(\"Input value \" << input_trimmed[i] << \" differs \" << diff << \" from recon value \" << recon[i] << \" at index \" << i);\n        total_diff += diff;\n    }\n    LOG4_INFO(\"Test took: \" << std::chrono::duration<float>(std::chrono::steady_clock::now() - start).count() << \" seconds, total error \" << total_diff << \", average error \" << total_diff / double(input_trimmed.size()));\n}\n\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- SVRRoot/OnlineSVR/test/cvmd_tests.cpp	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ SVRRoot/OnlineSVR/test/cvmd_tests.cpp	(date 1672562172991)
@@ -3,19 +3,21 @@
 //
 #include <gtest/gtest.h>
 #include <fstream>
-#include "../include/spectral_transform.hpp"
-#include "../include/cvmd.hpp"
 #include <chrono>
+
+#include "../include/spectral_transform.hpp"
+#include "../include/fast_cvmd.hpp"
 #include "test_harness.hpp"
 #include "util/StringUtils.hpp"
-#include <fstream>
 #include <DQScalingFactorService.hpp>
 #include "DeconQueueService.hpp"
 #include "model/DataRow.hpp"
 
+
 #define DECON_LEVELS 64
 #define TEST_TOL 1e-6
 
+
 const std::string transform_input_filename = "cvmd_test_data/transform_input";
 const std::string transform_result_filename = "cvmd_test_data/transform_output_real";
 
@@ -60,10 +62,10 @@
     std::vector<std::vector<double>> decon, phase_series;
     std::vector<double> recon;
     auto start = std::chrono::steady_clock::now();
-    const auto p_cvmd_transformer = dynamic_cast<svr::cvmd *>(transformer.get());
+    const auto p_cvmd_transformer = dynamic_cast<svr::fast_cvmd *>(transformer.get());
     std::vector<double> input_trimmed(input.begin() + input.size() - 40400, input.end());
     PROFILE_EXEC_TIME(p_cvmd_transformer->initialize(input_trimmed, "Test table"), "VMD initialize");
-    PROFILE_EXEC_TIME(p_cvmd_transformer->transform(input_trimmed, decon, "Test table", phase_series, 0), "VMD batch transform");
+    PROFILE_EXEC_TIME(p_cvmd_transformer->transform(input_trimmed, decon, "Test table"), "VMD batch transform");
 /*
     data_row_container decon_data;
     data_row_container input_data;
Index: SVRRoot/SVRBusiness-tests/test/DeconQueueServiceTests.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#include \"include/DaoTestFixture.h\"\n#include <model/User.hpp>\n#include \"include/InputQueueRowDataGenerator.hpp\"\n#include \"../../OnlineSVR/test/test_harness.hpp\"\n#include \"online_emd.hpp\"\n\nTEST_F(DaoTestFixture, DeconQueueWorkflow)\n{\n    User_ptr user1 = std::make_shared<svr::datamodel::User>\n            (bigint(), \"DeconQueueTestUser\", \"DeconQueueTestUser@email\", \"DeconQueueTestUser\", \"DeconQueueTestUser\",\n             svr::datamodel::ROLE::ADMIN, svr::datamodel::Priority::High);\n\n    aci.user_service.save(user1);\n\n    InputQueue_ptr iq = std::make_shared<svr::datamodel::InputQueue>(\n            \"tableName\", \"logicalName\", user1->get_name(), \"description\", bpt::seconds(60), bpt::seconds(5),\n            \"UTC\",\n            std::vector<std::string>{\"up\", \"down\", \"left\", \"right\"});\n    aci.input_queue_service.save(iq);\n\n    Dataset_ptr ds = std::make_shared<svr::datamodel::Dataset>\n            (0, \"DeconQueueTestDataset\", user1->get_user_name(), iq, std::vector<InputQueue_ptr>{}, svr::datamodel::Priority::Normal, \"\", 4, \"sym7\");\n    ds->set_is_active(true);\n    aci.dataset_service.save(ds);\n\n    DeconQueue_ptr dq = std::make_shared<svr::datamodel::DeconQueue>(\"DeconQueuetableName\", iq->get_table_name(), \"up\", ds->get_id(), ds->get_transformation_levels());\n\n    // The decon queue is saved with saving the dataset\n    //aci.decon_queue_service.save(dq);\n\n    aci.dataset_service.remove(ds);\n    aci.decon_queue_service.remove(dq);\n    aci.input_queue_service.remove(iq);\n    aci.user_service.remove(user1);\n}\n\n#define TEST_SAVE_DECON\n//#define TEST_INPUT_ONLY\n#define TEST_DECON_LEVELS 64\n#define TEST_LAG_COUNT 400\n#define TEST_MAX_RECON_DIFF 1e-7\n\n#define ONLINE_BATCH_LEN 3600\n#define ONLINE_LEN 5\n\n#define CORRUPTION_TEST // disables time invariance test\n#define TIME_INVARIANCE_OFFSET 150\n\n#define TEST_FIRST_BATCH_PADDING 1000\n#define TEST_RESIDUALS_COUNT(p_dataset) ((p_dataset)->get_residuals_count(\"__DUMMY__\")/2)\n#define TEST_FIRST_BATCH_SIZE(p_dataset) (TEST_RESIDUALS_COUNT(p_dataset) + TEST_FIRST_BATCH_PADDING)\n#define TEST_INPUT_QUEUE_LIMIT(p_dataset) (TEST_FIRST_BATCH_SIZE(p_dataset) + ONLINE_BATCH_LEN + ONLINE_LEN)\n\nvoid\nload_input_queue(const Dataset_ptr &p_dataset, const std::string &file_name, InputQueue_ptr &p_input_queue)\n{\n    LOG4_DEBUG(\"Loading input queue from \" << file_name);\n    std::ifstream ifstream(file_name);\n    if (not ifstream or not ifstream.good()) LOG4_THROW(\"Input stream not ready.\");\n    std::string line;\n    size_t ctr = 0;\n#if !defined(TEST_INPUT_ONLY) and !defined(TEST_SAVE_DECON)\n    const auto limit = TEST_INPUT_QUEUE_LIMIT(p_dataset);\n#endif\n    while (not ifstream.eof()) {\n        std::getline(ifstream, line);\n        std::vector<std::string> fields;\n        if (line.empty()) continue;\n        svr::common::split(line, '\\t', fields);\n        if (fields.size() != 4) continue;\n        const auto row_time = bpt::time_from_string(fields[0]);\n        const auto p_row = std::make_shared<svr::datamodel::DataRow>(\n                row_time,\n                boost::posix_time::second_clock::local_time(),\n                std::atof(fields[2].c_str()),\n                std::vector<double>(1, std::atof(fields[3].c_str())));\n        p_input_queue->get_data().push_back(p_row);\n        ++ctr;\n#if !defined(TEST_INPUT_ONLY) and !defined(TEST_SAVE_DECON)\n        if (ctr >= limit / p_input_queue->get_resolution().total_seconds()) break;\n#endif\n    }\n    LOG4_DEBUG(\"Loaded \" << ctr << \" rows from \" << file_name);\n}\n\n\nTEST_F(DaoTestFixture, testDeconRecon)\n{\n    User_ptr p_user = std::make_shared<svr::datamodel::User>(\n            bigint(), \"DeconQueueTestUser\", \"DeconQueueTestUser@email\", \"DeconQueueTestUser\", \"DeconQueueTestUser\", svr::datamodel::ROLE::ADMIN, svr::datamodel::Priority::High) ;\n    // Test of Save and Load to database is disabled for now, TODO enable in future\n    aci.user_service.save(p_user);\n\n    InputQueue_ptr p_all_data_inputqueue = std::make_shared<svr::datamodel::InputQueue>(\n            \"EURUSD1S\", \"EURUSD1S\", p_user->get_name(), \"EURUSD1S\", bpt::seconds(1), bpt::seconds(0), \"Europe/Zurich\", std::vector<std::string>{\"eurusd_avg_bid\"} );\n    InputQueue_ptr p_all_data_inputqueue_1h = std::make_shared<svr::datamodel::InputQueue>(\n            \"EURUSD1H\", \"EURUSD1H\", p_user->get_name(), \"EURUSD1H\", bpt::seconds(3600), bpt::seconds(5), \"Europe/Zurich\", std::vector<std::string>{\"eurusd_avg_bid\"} );\n    aci.input_queue_service.save(p_all_data_inputqueue);\n    aci.input_queue_service.save(p_all_data_inputqueue_1h);\n    auto p_inputq = p_all_data_inputqueue->clone_empty();\n    Dataset_ptr p_dataset = std::make_shared<svr::datamodel::Dataset>(\n            bigint(0), \"DeconQueueTestDataset\", p_user->get_user_name(), p_inputq, std::vector<InputQueue_ptr>{p_all_data_inputqueue_1h}, svr::datamodel::Priority::Normal, \"dsDescription\", TEST_DECON_LEVELS, \"cvmd\");\n    APP.ensemble_service.init_ensembles(p_dataset);\n    p_dataset->set_is_active(true);\n    aci.dataset_service.save(p_dataset);\n\n    load_input_queue(p_dataset, \"../SVRRoot/OnlineSVR/test/online_emd_test_data/0.98_eurusd_avg_1_test_data.sql\", p_all_data_inputqueue);\n    load_input_queue(p_dataset, \"../SVRRoot/OnlineSVR/test/online_emd_test_data/0.98_eurusd_avg_3600_test_data.sql\", p_all_data_inputqueue_1h);\n#ifdef TEST_DECON_SAVE\n    svr::datamodel::DeconQueue_ptr p_1h_decon_queue;\n    PROFILE_EXEC_TIME(p_1h_decon_queue = aci.decon_queue_service.deconstruct(p_all_data_inputqueue_1h, p_dataset, false).at(0),\n                      \"Deconstruction of 1H single column containing \" << p_all_data_inputqueue_1h->get_data().size() << \" rows.\");\n    APP.decon_queue_service.save(p_1h_decon_queue);\n    return;\n#endif\n\n    double total_input_diff = 0;\n    size_t compared_ct = 0;\n    for (const auto &row_1h: p_all_data_inputqueue_1h->get_data()) {\n        const auto it_row_1s = lower_bound_before(p_all_data_inputqueue->get_data(), row_1h->get_value_time());\n        // const auto it_row_1s = p_all_data_inputqueue->get_data().find(row_1h->get_value_time());\n        if (it_row_1s == p_all_data_inputqueue->get_data().end()) {\n            LOG4_DEBUG(\"Row not found in hires data for \" << row_1h->get_value_time());\n            continue;\n        }\n        const auto twap_1h = calc_twap(\n                it_row_1s, p_all_data_inputqueue->get_data().end(),\n                row_1h->get_value_time(), row_1h->get_value_time() + p_all_data_inputqueue_1h->get_resolution(),\n                p_all_data_inputqueue->get_resolution(), 0);\n        if (std::isnan(twap_1h)) continue;\n        const auto diff_twap = std::abs(twap_1h - row_1h.get()->get_value(0));\n        total_input_diff += diff_twap;\n        ++compared_ct;\n        if (diff_twap > std::numeric_limits<double>::epsilon())\n            LOG4_WARN(\"Input data inconsistent at \" << row_1h->get_value_time() << \" difference \" << diff_twap << \" 1h price \" << row_1h.get()->get_value(0) << \" mean 1s \" << twap_1h << \" last 1s iter time \" << it_row_1s->get()->get_value_time() << \" 1s prices\");\n        else\n            LOG4_TRACE(\"Data is OK at \" << row_1h->get_value_time() << \" difference \" << diff_twap);\n    }\n    LOG4_DEBUG(\"Average input diff \" << (total_input_diff/double(compared_ct)) << \" out of \" << compared_ct << \" comparisons.\");\n#ifdef TEST_INPUT_ONLY\n    return;\n#endif\n\n    p_inputq->get_data().insert(p_inputq->get_data().end(),\n            p_all_data_inputqueue->get_data().begin(),\n            TEST_FIRST_BATCH_SIZE(p_dataset) == INT_MAX ? p_all_data_inputqueue->get_data().end() : std::next(p_all_data_inputqueue->get_data().begin(), TEST_FIRST_BATCH_SIZE(p_dataset)));\n\n    PROFILE_EXEC_TIME(ASSERT_EQ(p_inputq->get_data().size(), (size_t) aci.input_queue_service.save(p_inputq)), \"Saving input queue with \" << p_inputq->get_data().size() << \" rows\");\n    bpt::ptime start_time = aci.input_queue_service.find_oldest_record(p_inputq)->get_value_time();\n    bpt::ptime end_time = aci.input_queue_service.find_newest_record(p_inputq)->get_value_time();\n    ASSERT_FALSE(start_time.is_special());\n    ASSERT_FALSE(end_time.is_special());\n    APP.ensemble_service.init_ensembles(p_dataset);\n    DeconQueue_ptr p_online_decon_queue;\n    const auto residuals_length = p_dataset->get_residuals_count();\n    LOG4_DEBUG(\"Residuals length \" << residuals_length);\n    APP.input_queue_service.clear(p_inputq);\n    APP.input_queue_service.save(p_inputq);\n    PROFILE_EXEC_TIME(p_online_decon_queue = aci.decon_queue_service.deconstruct(p_inputq, p_dataset, false).at(0),\n                      \"Deconstruction of single column containing \" << p_inputq->get_data().size() << \" rows.\");\n\n    ASSERT_EQ(p_online_decon_queue->get_data().size(), p_inputq->get_data().size() % 2 ? p_inputq->get_data().size() - 1 : p_inputq->get_data().size()) << \"InputQueue size and deconstracted data size aren't equal\";\n    for (auto &it : p_online_decon_queue->get_data())\n    {\n        ASSERT_EQ(it.get()->get_values().size(), (size_t) TEST_DECON_LEVELS) << \"Decon queue data at \" << it->get_value_time() << \" have wrong deconstructed levels\";\n    }\n\n    svr::business::EnsembleService::update_ensemble_decon_queues(p_dataset->get_ensembles(), {p_online_decon_queue});\n    size_t ctr = 0;\n    for (auto row_iter = std::next(p_all_data_inputqueue->get_data().begin(), TEST_FIRST_BATCH_SIZE(p_dataset));\n            row_iter != p_all_data_inputqueue->get_data().end(); ++row_iter) {\n        p_inputq->get_data().push_back(*row_iter);\n        if (++ctr < ONLINE_BATCH_LEN) continue;\n        PROFILE_EXEC_TIME(p_online_decon_queue = aci.decon_queue_service.deconstruct(p_inputq, p_dataset, false).at(0),\n                          \"Deconstruction of single column containing \" << (ctr == ONLINE_BATCH_LEN ? ONLINE_BATCH_LEN : 1) << \" rows.\");\n        svr::business::EnsembleService::update_ensemble_decon_queues(p_dataset->get_ensembles(), {p_online_decon_queue});\n    }\n    APP.dq_scaling_factor_service.calculate_dataset_scaling_factors(p_dataset);\n    p_online_decon_queue = p_dataset->get_ensemble(0)->get_decon_queue()->clone();\n    p_dataset->get_ensemble(0)->get_decon_queue()->get_data().clear();\n// Corruption test\n#ifdef CORRUPTION_TEST\n    p_dataset->p_cvmd_transformer->uninitialize(false);\n#else\n// Time invariance test\n    p_inputq->get_data().erase(p_inputq->get_data().begin(), std::next(p_inputq->get_data().begin(), TIME_INVARIANCE_OFFSET));\n    APP.decon_queue_service.test_start_cvmd_pos = TIME_INVARIANCE_OFFSET;\n#endif\n    APP.input_queue_service.clear(p_inputq);\n    APP.input_queue_service.save(p_inputq);\n    const auto p_batch_decon_queue = aci.decon_queue_service.deconstruct(p_inputq, p_dataset, false).at(0);\n    p_batch_decon_queue->set_input_queue_column_name(\"bid\");\n    size_t row_ix = 0;\n    double time_variance = 0;\n    for (auto batch_row_iter = std::next(p_batch_decon_queue->get_data().begin(), TEST_RESIDUALS_COUNT(p_dataset));\n        batch_row_iter != p_batch_decon_queue->get_data().end();\n        ++batch_row_iter) {\n\n        const auto online_row_iter = find(p_online_decon_queue->get_data(), batch_row_iter->get()->get_value_time());\n        if (online_row_iter == p_online_decon_queue->get_data().end()) {\n            LOG4_WARN(\"Batch time \" << batch_row_iter->get()->get_value_time() << \" row \" << row_ix <<  \" not found in online decon queue.\");\n            continue;\n        }\n        double total_diff = 0;\n        double total_phase_diff = 0;\n        for (size_t col_ix = 0; col_ix < batch_row_iter->get()->get_values().size(); ++col_ix) {\n            const auto diff = std::abs(batch_row_iter->get()->get_value(col_ix) - online_row_iter->get()->get_value(col_ix));\n            total_diff += diff;\n            if (diff > std::numeric_limits<double>::epsilon())\n                LOG4_WARN(\"Row \" << row_ix << \" at \" << batch_row_iter->get()->get_value_time() << \" col \" << col_ix << \" value difference \" << diff);\n        }\n        for (size_t col_ix = 0; col_ix < batch_row_iter->get()->get_phases().size(); ++col_ix) {\n            const auto diff = batch_row_iter->get()->get_phase(col_ix) - online_row_iter->get()->get_phase(col_ix);\n            total_phase_diff += std::abs(diff);\n            if (diff > std::numeric_limits<double>::epsilon())\n                LOG4_WARN(\"Row \" << row_ix << \" at \" << batch_row_iter->get()->get_value_time() << \" col \" << col_ix << \" phase difference \" << diff);\n        }\n        time_variance += total_diff;\n        if (total_diff > std::numeric_limits<double>::epsilon())\n            LOG4_WARN(\"Row \" << row_ix << \" at \" << batch_row_iter->get()->get_value_time() << \" col ix total value difference \" << total_diff / CVMD_INPUT_MULTIPLIER);\n        if (total_phase_diff > std::numeric_limits<double>::epsilon())\n            LOG4_WARN(\"Row \" << row_ix << \" at \" << batch_row_iter->get()->get_value_time() << \" col ix total phase difference \" << total_phase_diff);\n        ++row_ix;\n    }\n    time_variance /= double(row_ix);\n    LOG4_INFO(\"Average total time variance \" << time_variance);\n    aci.input_queue_service.clear(p_inputq);\n    aci.input_queue_service.save(p_inputq);\n\n    auto p_delta_online_dq = APP.decon_queue_service.decon_queue_delta(p_online_decon_queue, true);\n    APP.dq_scaling_factor_service.force_scale_decon_queue(p_dataset, p_delta_online_dq);\n    auto p_delta_batch_dq = APP.decon_queue_service.decon_queue_delta(p_batch_decon_queue, true);\n    APP.dq_scaling_factor_service.force_scale_decon_queue(p_dataset, p_delta_batch_dq);\n\n//    LOG4_FILE(\"p_delta_online_dq.csv\", p_delta_online_dq->data_to_string(INT_MAX));\n//    LOG4_FILE(\"p_delta_batch_dq.csv\", p_delta_batch_dq->data_to_string(INT_MAX));\n\n    APP.dq_scaling_factor_service.unscale(p_dataset, p_delta_online_dq);\n    const auto p_undelta_online_dq = svr::business::DeconQueueService::decon_queue_undelta(p_delta_online_dq);\n    for (const auto &decon_row: p_online_decon_queue->get_data()) {\n        const auto undelta_row = find(p_undelta_online_dq->get_data(), decon_row->get_value_time());\n        if (undelta_row == p_undelta_online_dq->get_data().end()) {\n            LOG4_WARN(\"Time \" << decon_row->get_value_time() << \" not found in undelta!\");\n            continue;\n        }\n        //LOG4_TRACE(\"undelta_row->second->get_values().size()\" << undelta_row->second->get_values().size() <<\n        //        \" decon_row.second->get_values().size() \" << decon_row.second->get_values().size());\n        for (size_t i = 0; i < undelta_row->get()->get_values().size(); ++i) {\n            if (std::isnan(undelta_row->get()->get_value(i)) and std::isnan(decon_row.get()->get_value(i))) {\n                //LOG4_TRACE(\"Col \" << i << \" at \" << decon_row->get_value_time() << \" is NaN, skipping.\");\n                continue;\n            }\n            const auto diff = std::abs(undelta_row->get()->get_value(i) - decon_row.get()->get_value(i));\n            if (diff > std::numeric_limits<float>::epsilon())\n                LOG4_WARN(\"Decon value \"  << decon_row.get()->get_value(i) << \" at \" << decon_row->get_value_time() << \" differs \" << diff << \" from undelta_row \" << undelta_row->get()->get_value(i));\n        }\n    }\n\n    InputQueue_ptr recon_queue = p_inputq->clone_empty();\n    PROFILE_EXEC_TIME(APP.decon_queue_service.reconstruct(\n            {p_undelta_online_dq->get_data()},\n            p_dataset->get_transformation_name(), p_dataset->get_transformation_levels(),\n            recon_queue->get_data()),\n                      \"Reconstruction of \" << TEST_DECON_LEVELS << \" levels containing \" << p_inputq->get_data().size() << \" rows.\");\n\n    double total_diff = 0;\n    size_t diff_ct = 0;\n    for (const auto &p_iq_row: p_inputq->get_data()) {\n        const auto &i_rq_row = find(recon_queue->get_data(), p_iq_row->get_value_time());\n        if (i_rq_row == recon_queue->get_data().end()) {\n            LOG4_WARN(\"Row with time \" << p_iq_row->get_value_time() << \" not found in recon queue!\");\n            continue;\n        }\n        const auto diff = std::abs(i_rq_row->get()->get_value(0) - p_iq_row.get()->get_value(0));\n\n        ++diff_ct;\n        if (diff_ct <= residuals_length) continue;\n\n        total_diff += diff;\n        if (diff > TEST_MAX_RECON_DIFF)\n            LOG4_WARN(\"Difference of \" << diff << \" at \" << diff_ct << \": \" << p_iq_row->get_value_time() << \" input price \" << p_iq_row.get()->get_value(0) << \" recon price \" << i_rq_row->get()->get_value(0) << \" is too big!\");\n    }\n    const double avg_diff = total_diff / double(diff_ct - residuals_length);\n\n    LOG4_DEBUG(\"Average diff is \" << avg_diff << \" total diff is \" << total_diff << \" compared rows count \" << diff_ct - residuals_length);\n    ASSERT_LE(avg_diff, TEST_MAX_RECON_DIFF);\n    LOG4_DEBUG(\"p_undelta_online_dq->get_data().begin()->second->get_values().size() \" << p_undelta_online_dq->get_data().begin()->get()->get_values().size());\n    aci.decon_queue_service.save(p_undelta_online_dq);\n    DeconQueue_ptr p_deconqueue2 = aci.decon_queue_service.get_by_table_name(p_undelta_online_dq->get_table_name());\n\n    aci.decon_queue_service.load_decon_data(p_deconqueue2);\n\n    ASSERT_EQ(*p_delta_online_dq, *p_deconqueue2);\n\n    aci.dataset_service.remove(p_dataset);\n\n    //aci.decon_queue_service.remove(p_online_decon_queue);\n\n    aci.input_queue_service.remove(p_inputq);\n    aci.user_service.remove(p_user);\n}\n\n\nTEST_F(DaoTestFixture, TestSaveDQIntegrity)\n{\n    User_ptr user1 = std::make_shared<svr::datamodel::User>(\n            bigint(), \"JamesBond\", \"JamesBond@email\", \"JamesBond\", \"JamesBond\", svr::datamodel::ROLE::ADMIN,\n            svr::datamodel::Priority::High);\n\n    aci.user_service.save(user1);\n\n    InputQueue_ptr iq = std::make_shared<svr::datamodel::InputQueue>(\n            \"SomeInputQueue\", \"SomeInputQueue\", user1->get_name(), \"SomeInputQueue\", bpt::seconds(60), bpt::seconds(5),\n            \"UTC\", std::vector<std::string>{\"up\", \"down\", \"left\", \"right\"});\n    aci.input_queue_service.save(iq);\n\n    Dataset_ptr ds = std::make_shared<svr::datamodel::Dataset>(0, \"SomeTestDataset\", user1->get_user_name(), iq, std::vector<InputQueue_ptr>{}, svr::datamodel::Priority::Normal, \"\", 2, \"sym7\");\n    ds->set_is_active(true);\n    aci.dataset_service.save(ds);\n\n    DeconQueue_ptr dq = std::make_shared<svr::datamodel::DeconQueue>(\"SomeDeconQueuetableName\", iq->get_table_name(), \"up\", ds->get_id(), ds->get_transformation_levels());\n\n    bpt::ptime nw = bpt::second_clock::local_time();\n\n    DataRow_ptr row = DataRow_ptr(new svr::datamodel::DataRow(nw));\n    row->set_values({0, 1, 2});\n    dq->get_data().push_back(row);\n\n    aci.decon_queue_service.save(dq);\n    aci.decon_queue_service.save(dq);\n\n    DataRow_ptr row1 = DataRow_ptr(new svr::datamodel::DataRow(nw + bpt::seconds(1)));\n    row1->set_values({0, 1, 2});\n    dq->get_data().push_back(row1);\n\n    DeconQueue_ptr dq1 = std::make_shared<svr::datamodel::DeconQueue>(\"SomeDeconQueuetableName\", iq->get_table_name(), \"up\", ds->get_id(), ds->get_transformation_levels());\n\n    aci.decon_queue_service.load_decon_data(dq1, nw - bpt::hours(1), nw + bpt::hours(1), 1000);\n\n    ASSERT_EQ(1UL, dq1->get_data().size());\n\n    aci.dataset_service.remove(ds);\n\n    aci.decon_queue_service.remove(dq);\n\n    aci.input_queue_service.remove(iq);\n    aci.user_service.remove(user1);\n}\n\nTEST_F(DaoTestFixture, TestDQUpdates)\n{\n    User_ptr user1 = std::make_shared<svr::datamodel::User>(\n            bigint(), \"WarrenBuffett\", \"WarrenBuffett@email\", \"WarrenBuffett\", \"WarrenBuffett\",\n            svr::datamodel::ROLE::ADMIN, svr::datamodel::Priority::High);\n\n    aci.user_service.save(user1);\n\n    InputQueue_ptr iq = std::make_shared<svr::datamodel::InputQueue>(\n            \"GatesFoundationIQ\", \"GatesFoundationIQ\", user1->get_name(), \"GatesFoundationIQ\", bpt::seconds(60),\n            bpt::seconds(5), \"UTC\", std::vector<std::string>{\"up\", \"down\", \"left\", \"right\"});\n    aci.input_queue_service.save(iq);\n\n    Dataset_ptr ds = std::make_shared<svr::datamodel::Dataset>(0, \"GatesFoundationDS\", user1->get_user_name(), iq, std::vector<InputQueue_ptr>{}, svr::datamodel::Priority::Normal, \"\", 2, \"sym7\");\n    ds->set_is_active(true);\n    aci.dataset_service.save(ds);\n\n    DeconQueue_ptr dq = std::make_shared<svr::datamodel::DeconQueue>(\"GatesFoundationDQ\", iq->get_table_name(), \"up\", ds->get_id(), ds->get_transformation_levels());\n\n    bpt::ptime nw = bpt::second_clock::local_time();\n\n    DataRow_ptr row = DataRow_ptr(new svr::datamodel::DataRow(nw));\n    row->set_values({0, 1, 2});\n    dq->get_data().push_back(row);\n\n    aci.decon_queue_service.save(dq);\n\n    ///////////// No decon queue table recreation\n    dq->get_data().clear();\n\n    DataRow_ptr row1 = DataRow_ptr(new svr::datamodel::DataRow(nw + bpt::seconds(60)));\n    row1->set_values({0, 1, 2});\n    dq->get_data().push_back(row1);\n    aci.decon_queue_service.save(dq);\n\n    DeconQueue_ptr dq_test1 = aci.decon_queue_service.get_by_table_name(dq->get_table_name());\n    aci.decon_queue_service.load_decon_data(dq_test1, nw, nw + bpt::seconds(61), 10);\n\n    ASSERT_EQ(2UL, dq_test1->get_data().size());\n    ASSERT_EQ(3UL, dq_test1->get_data().begin()->get()->get_values().size());\n\n    ///////////// Table should be recreated;\n\n    dq->get_data().clear();\n\n    DataRow_ptr row2 = DataRow_ptr(new svr::datamodel::DataRow(nw + bpt::seconds(2*60) ));\n    row2->set_values({3, 4, 5});\n    dq->get_data().push_back(row2);\n\n    aci.decon_queue_service.save(dq);\n\n    DeconQueue_ptr dq_test2 = aci.decon_queue_service.get_by_table_name(dq->get_table_name());\n    aci.decon_queue_service.load_decon_data(dq_test2, nw, nw + bpt::seconds(2 * 60 + 1), 10);\n\n    ASSERT_EQ(3UL, dq_test2->get_data().size());\n    ASSERT_EQ(3UL, dq_test2->get_data().begin()->get()->get_values().size() );\n\n    aci.dataset_service.remove(ds);\n\n    aci.decon_queue_service.remove(dq);\n\n    aci.input_queue_service.remove(iq);\n    aci.user_service.remove(user1);\n\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- SVRRoot/SVRBusiness-tests/test/DeconQueueServiceTests.cpp	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ SVRRoot/SVRBusiness-tests/test/DeconQueueServiceTests.cpp	(date 1672562061591)
@@ -179,9 +179,7 @@
     p_online_decon_queue = p_dataset->get_ensemble(0)->get_decon_queue()->clone();
     p_dataset->get_ensemble(0)->get_decon_queue()->get_data().clear();
 // Corruption test
-#ifdef CORRUPTION_TEST
-    p_dataset->p_cvmd_transformer->uninitialize(false);
-#else
+#ifndef CORRUPTION_TEST
 // Time invariance test
     p_inputq->get_data().erase(p_inputq->get_data().begin(), std::next(p_inputq->get_data().begin(), TIME_INVARIANCE_OFFSET));
     APP.decon_queue_service.test_start_cvmd_pos = TIME_INVARIANCE_OFFSET;
Index: SVRRoot/SVRCommon/include/util/PropertiesFileReader.hpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#pragma once\n\n#include <common/types.hpp>\n\nnamespace svr {\nnamespace common {\n\nenum class ConcreteDaoType { PgDao, AsyncDao };\n\nclass PropertiesFileReader\n{\n    bool is_autotune_running_ = false;\n\n    MessageProperties property_files;\n    char delimiter;\n    std::string property_files_location;\n    ConcreteDaoType dao_type;\n    bool set_thread_affinity_;\n    bool dont_update_r_matrix_;\n    bool main_columns_aux_;\n    size_t max_smo_iterations_;\n    double cascade_reduce_ratio_;\n    size_t cascade_max_segment_size_;\n    size_t cascade_branches_count_;\n    bool disable_cascaded_svm_;\n    size_t multistep_len;\n    std::string svr_paramtune_column;\n    std::string svr_paramtune_level;\n    size_t online_iters_limit_mult_;\n    size_t online_learn_iter_limit_;\n    double smo_epsilon_divisor_;\n    double smo_cost_divisor_;\n    size_t stabilize_iterations_count_;\n    size_t default_number_variations_;\n    double error_tolerance_;\n    double scaling_alpha_;\n    std::string online_svr_log_file_;\n    size_t max_variations_;\n    size_t comb_train_count_;\n    size_t comb_validate_count_;\n    size_t comb_validate_limit_;\n    bool enable_comb_validate_;\n    bool tune_parameters_;\n    size_t future_predict_count_;\n    size_t slide_count_;\n    size_t tune_run_limit_;\n    bool all_aux_levels_;\n\n    size_t read_property_file(std::string property_file_name);\n    void set_global_log_level(const std::string& log_level_value);\n    bool is_comment(const std::string &line);\n    bool is_multiline(const std::string &line);\n\n    std::string get_property_value(\n            const std::string &property_file, const std::string &key, std::string default_value);\n\npublic:\n    virtual ~PropertiesFileReader() {}\n\n    explicit PropertiesFileReader(const std::string& app_config_file, char delimiter = '=');\n    const MessageProperties::mapped_type& read_properties(const std::string &property_file);\n\n    template<typename T>\n    T get_property(const std::string &property_file, const std::string &key, std::string default_value = \"\") {\n        return boost::lexical_cast<T>(get_property_value(property_file, key, default_value));\n    }\n\n    ConcreteDaoType get_dao_type() const;\n\n    bool get_set_thread_affinity() const { return set_thread_affinity_; }\n    bool get_dont_update_r_matrix() const { return dont_update_r_matrix_; }\n    bool get_main_columns_aux() const { return main_columns_aux_; }\n    size_t get_max_smo_iterations() const { return max_smo_iterations_; }\n    double get_cascade_reduce_ratio() const { return cascade_reduce_ratio_; }\n    size_t get_max_segment_size() const { return cascade_max_segment_size_; }\n    bool get_disable_cascaded_svm() const { return disable_cascaded_svm_; }\n    size_t get_cascade_branches_count() const { return cascade_branches_count_; }\n\n    size_t get_multistep_len() const { return multistep_len; }\n    std::string get_svr_paramtune_level() const {return svr_paramtune_level;}\n    std::vector<size_t> get_svr_paramtune_levels() const;\n    std::string get_svr_paramtune_column() const {return svr_paramtune_column;}\n    size_t get_online_iters_limit_mult() const { return online_iters_limit_mult_; }\n    size_t get_online_learn_iter_limit() const { return online_learn_iter_limit_; }\n    double get_smo_epsilon_divisor() const { return smo_epsilon_divisor_; }\n    double get_smo_cost_divisor() const { return smo_cost_divisor_; }\n    size_t get_stabilize_iterations_count() const { return stabilize_iterations_count_; }\n    size_t get_default_number_variations() const { return default_number_variations_; }\n    double get_error_tolerance() const { return error_tolerance_; }\n    double get_scaling_alpha() const { return scaling_alpha_; }\n    std::string get_online_svr_logfile() const { return online_svr_log_file_;}\n    size_t get_max_variations() const { return max_variations_;}\n    bool get_autotune_running() const { return is_autotune_running_; } // TODO Remove\n    size_t get_comb_train_count() const { return comb_train_count_; }\n    size_t get_comb_validate_count() const { return comb_validate_count_; }\n    size_t get_comb_validate_limit() const { return comb_validate_limit_; }\n    bool get_enable_comb_validate() const { return enable_comb_validate_; }\n    bool get_tune_parameters() const { return tune_parameters_; }\n    size_t get_future_predict_count() const { return future_predict_count_; }\n    size_t get_slide_count() const { return slide_count_; }\n    size_t get_tune_run_limit() const { return tune_run_limit_; }\n    bool get_all_aux_levels() const { return all_aux_levels_; }\n\n    // TODO Befriend with CLI class and mark private\n    void set_autotune_running(const bool running) { is_autotune_running_ = running; }\nprivate:\n    static const std::string SQL_PROPERTIES_DIR_KEY;\n    static const std::string LOG_LEVEL_KEY;\n    static const std::string COMMENT_CHARS;\n    static const std::string DAO_TYPE_KEY;\n    static const std::string DONT_UPDATE_R_MATRIX;\n    static const std::string MAIN_COLUMNS_AUX;\n    static const std::string MAX_SMO_ITERATIONS;\n    static const std::string CASCADE_REDUCE_RATIO;\n    static const std::string CASCADE_MAX_SEGMENT_SIZE;\n    static const std::string DISABLE_CASCADED_SVM;\n    static const std::string CASCADE_BRANCHES_COUNT;\n    static const std::string SET_THREAD_AFFINITY;\n    static const std::string MULTISTEP_LEN;\n    static const std::string SVR_PARAMTUNE_COLUMN;\n    static const std::string SVR_PARAMTUNE_LEVEL;\n    static const std::string ONLINE_LEARN_ITER_LIMIT;\n    static const std::string ONLINE_ITERS_LIMIT_MULT;\n    static const std::string SMO_EPSILON_DIVISOR;\n    static const std::string SMO_COST_DIVISOR;\n    static const std::string STABILIZE_ITERATIONS_COUNT;\n    static const std::string DEFAULT_NUMBER_VARIATIONS;\n    static const std::string ERROR_TOLERANCE;\n    static const std::string SCALING_ALPHA;\n    static const std::string ONLINESVR_LOG_FILE;\n    static const std::string MAX_VARIATIONS;\n    static const std::string COMB_TRAIN_COUNT;\n    static const std::string COMB_VALIDATE_COUNT;\n    static const std::string COMB_VALIDATE_LIMIT;\n    static const std::string ENABLE_COMB_VALIDATE;\n    static const std::string ALL_AUX_LEVELS;\n    static const std::string TUNE_PARAMETERS;\n    static const std::string FUTURE_PREDICT_COUNT;\n    static const std::string SLIDE_COUNT;\n    static const std::string TUNE_RUN_LIMIT;\n};\n\n\n} /* namespace common */\n} /* namespace svr */\n\nusing MessageSource_ptr = std::shared_ptr<svr::common::PropertiesFileReader>;\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- SVRRoot/SVRCommon/include/util/PropertiesFileReader.hpp	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ SVRRoot/SVRCommon/include/util/PropertiesFileReader.hpp	(date 1672578849352)
@@ -45,6 +45,7 @@
     size_t slide_count_;
     size_t tune_run_limit_;
     bool all_aux_levels_;
+    bool oemd_find_fir_coefficients_;
 
     size_t read_property_file(std::string property_file_name);
     void set_global_log_level(const std::string& log_level_value);
@@ -100,6 +101,7 @@
     size_t get_slide_count() const { return slide_count_; }
     size_t get_tune_run_limit() const { return tune_run_limit_; }
     bool get_all_aux_levels() const { return all_aux_levels_; }
+    bool get_oemd_find_fir_coefficients() const { return oemd_find_fir_coefficients_; }
 
     // TODO Befriend with CLI class and mark private
     void set_autotune_running(const bool running) { is_autotune_running_ = running; }
@@ -138,6 +140,7 @@
     static const std::string FUTURE_PREDICT_COUNT;
     static const std::string SLIDE_COUNT;
     static const std::string TUNE_RUN_LIMIT;
+    static const std::string OEMD_FIND_FIR_COEFFICIENTS;
 };
 
 
Index: SVRRoot/SVRModel/include/model/Dataset.hpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#pragma once\n\n#include \"model/Entity.hpp\"\n#include \"model/Priority.hpp\"\n#include \"model/Ensemble.hpp\"\n#include \"model/InputQueue.hpp\"\n#include \"model/IQScalingFactor.hpp\"\n#include \"model/DQScalingFactor.hpp\"\n#include \"util/StringUtils.hpp\"\n#include <algorithm>\n#include <unordered_map>\n#include \"relations/iq_relation.hpp\"\n#include <mutex>\n#include <spectral_transform.hpp>\n#include <cvmd.hpp>\n#include <online_emd.hpp>\n\nnamespace svr {\nnamespace business {\n    class DatasetService;\n}\n\nnamespace datamodel {\n\nstatic const std::vector<std::string> transformation_names {\n        // 0 - 14\n        \"db1\", \"db2\", \"db3\", \"db4\", \"db5\", \"db6\", \"db7\", \"db8\", \"db9\", \"db10\", \"db11\", \"db12\", \"db13\", \"db14\", \"db15\",\n        // 15 - 29\n        \"bior1.1\", \"bior1.3\", \"bior1.5\", \"bior2.2\", \"bior2.4\", \"bior2.6\", \"bior2.8\",\n        \"bior3.1\", \"bior3.3\", \"bior3.5\", \"bior3.7\", \"bior3.9\", \"bior4.4\", \"bior5.5\", \"bior6.8\",\n        // 30 - 34\n        \"coif1\", \"coif2\", \"coif3\", \"coif4\", \"coif5\",\n        // 35 - 44\n        \"sym1\", \"sym2\", \"sym3\", \"sym4\", \"sym5\", \"sym6\", \"sym7\", \"sym8\", \"sym9\", \"sym10\",\n        // 45 - 55\n        \"sym11\", \"sym12\", \"sym13\", \"sym14\", \"sym15\", \"sym16\", \"sym17\", \"sym18\", \"sym19\", \"sym20\",\n        \"stft\", \"oemd\", \"cvmd\"\n};\n\nclass Dataset : public Entity\n{\n    friend svr::business::DatasetService;\n\n    void init_transform();\n\npublic:\n    Dataset() : Entity()\n    {\n        is_active_ = false;\n        transformation_levels_ = 0;\n    }\n\n    Dataset(\n        bigint id,\n        const std::string &dataset_name,\n        const std::string &user_name,\n        InputQueue_ptr p_input_queue,\n        const std::vector<InputQueue_ptr> &aux_input_queues,\n        const Priority &priority,\n        const std::string &description,\n        const size_t transformation_levels,\n        const std::string &transformation_name,\n        const bpt::time_duration &max_lookback_time_gap = bpt::hours(23),\n        const std::vector<Ensemble_ptr> &ensembles = std::vector<Ensemble_ptr>(),\n        bool is_active = false,\n        const std::vector<IQScalingFactor_ptr> iq_scaling_factors = std::vector<IQScalingFactor_ptr>(),\n        const dq_scaling_factor_container_t dq_scaling_factors = dq_scaling_factor_container_t()\n    );\n\n    Dataset(\n            bigint id,\n            const std::string &dataset_name_,\n            const std::string &user_name_,\n            const std::string &input_queue_table_name,\n            const std::vector<std::string> &aux_input_queues_table_names,\n            const Priority &priority_,\n            const std::string &description_,\n            const size_t transformation_levels,\n            const std::string &transformation_name,\n            const bpt::time_duration &max_lookback_time_gap_ = bpt::hours(23),\n            const std::vector<Ensemble_ptr> &ensembles_ = std::vector<Ensemble_ptr>(),\n            bool is_active_ = false,\n            const std::vector<IQScalingFactor_ptr> iq_scaling_factors = std::vector<IQScalingFactor_ptr>(),\n            const dq_scaling_factor_container_t dq_scaling_factors = dq_scaling_factor_container_t()\n    );\n\n    std::unique_ptr<svr::online_emd> p_oemd_transformer_fat, oemd_transformer_thin;\n    std::unique_ptr<svr::cvmd> p_cvmd_transformer;\n\n    Dataset(Dataset const &dataset);\n\n    bool operator==(const Dataset &other) const;\n\n    std::string get_dataset_name() const;\n    void set_dataset_name(const std::string &dataset_name);\n\n    std::string get_user_name() const;\n    void set_user_name(const std::string &user_name);\n\n//  const InputQueue_ptr &get_input_queue() const ;\n\n    InputQueue_ptr get_input_queue() ;\n    void set_input_queue(InputQueue_ptr p_input_queue) ;\n\n    Priority const &get_priority() const;\n    void set_priority(Priority const &priority);\n\n    std::string get_description() const;\n    void set_description(const std::string &description);\n\n    size_t get_transformation_levels() const;\n    size_t get_transformation_levels_cvmd() const;\n    size_t get_transformation_levels_oemd() const;\n    void set_transformation_levels(const size_t transformation_levels);\n\n    std::string get_transformation_name() const;\n    void set_transformation_name(const std::string& transformation_name);\n    bool validate_transformation_name(const std::string& transformation_name) const;\n\n    const bpt::time_duration& get_max_lookback_time_gap() const;\n    void set_max_lookback_time_gap(const bpt::time_duration& max_lookback_time_gap);\n\n    std::vector<Ensemble_ptr>& get_ensembles();\n    Ensemble_ptr get_ensemble(const std::string &column_name);\n    DeconQueue_ptr get_decon_queue(const InputQueue_ptr &p_input_queue, const std::string &column_name);\n    const std::map<std::pair<std::string, std::string>, DeconQueue_ptr> get_decon_queues() const;\n    void clear_data();\n    Ensemble_ptr get_ensemble(const size_t idx);\n    void set_ensembles(const std::vector<Ensemble_ptr> &ensembles);\n\n    bool get_is_active() const ;\n    void set_is_active(bool is_active);\n\n    std::vector<IQScalingFactor_ptr> get_iq_scaling_factors();\n    void set_iq_scaling_factors(const std::vector<IQScalingFactor_ptr>& iq_scaling_factors);\n\n    dq_scaling_factor_container_t get_dq_scaling_factors() ;\n    void set_dq_scaling_factors(const dq_scaling_factor_container_t& dq_scaling_factors);\n    const double get_dq_scaling_factor_mul(const std::string &input_queue_table_name, const std::string &input_queue_column_name, const size_t decon_level) const;\n    const double get_dq_scaling_factor_add(const std::string &input_queue_table_name, const std::string &input_queue_column_name, const size_t decon_level) const;\n\n    ensemble_svr_parameters_t get_ensemble_svr_parameters() const;\n    SVRParameters_ptr get_svr_parameters(\n            const std::string &table_name, const std::string &column_name, const size_t level_number) const;\n    void set_ensemble_svr_parameters(ensemble_svr_parameters_t ensemble_svr_parameters);\n    void set_ensemble_svr_parameters_deep(ensemble_svr_parameters_t ensemble_svr_parameters);\n\n    std::vector<InputQueue_ptr> get_aux_input_queues() const;\n    InputQueue_ptr get_aux_input_queue(const size_t idx) const;\n    std::vector<std::string> get_aux_input_table_names() const;\n\n    void set_tuned_svr_parameters(\n        const std::vector<double> &parameter_values,\n        const size_t model_number,\n        const std::vector<datamodel::Bounds> &bounds,\n        const std::string &column_name);\n\n    virtual std::string to_string() const override;\n\n    std::string parameters_to_string() const;\n\n    size_t get_max_lag_count();\n    size_t get_max_decrement();\n    size_t calculate_max_residuals_count() const;\n    size_t get_residuals_count(const std::string &decon_queue_table_name = {}) const;\n\nprivate:\n    Ensemble_ptr null_ensemble = std::shared_ptr<Ensemble>(nullptr);\n    size_t max_lag_count_cache_ = 0;\n    size_t max_decremental_distance_cache_ = 0;\n    std::string dataset_name_;\n    std::string user_name_;\n    iq_relation input_queue_;\n    std::vector<iq_relation> aux_input_queues_;\n    Priority priority_;\n    std::string description_;\n    size_t transformation_levels_;\n    std::string transformation_name_;\n    bpt::time_duration max_lookback_time_gap_;\n    std::vector<Ensemble_ptr> ensembles_;\n    bool is_active_;\n    std::vector<IQScalingFactor_ptr> iq_scaling_factors_;\n    svr::datamodel::dq_scaling_factor_container_t dq_scaling_factors_;\n    ensemble_svr_parameters_t ensemble_svr_parameters_;\n\n    std::mutex dq_scaling_factors_mutex;\n    std::mutex mutable svr_params_mutex;\n\n    void on_set_id() override;\n};\n\n\n}\n}\n\nusing Dataset_ptr = std::shared_ptr<svr::datamodel::Dataset>;\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- SVRRoot/SVRModel/include/model/Dataset.hpp	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ SVRRoot/SVRModel/include/model/Dataset.hpp	(date 1672558853063)
@@ -1,5 +1,9 @@
 #pragma once
 
+#include <algorithm>
+#include <unordered_map>
+#include <mutex>
+
 #include "model/Entity.hpp"
 #include "model/Priority.hpp"
 #include "model/Ensemble.hpp"
@@ -7,13 +11,10 @@
 #include "model/IQScalingFactor.hpp"
 #include "model/DQScalingFactor.hpp"
 #include "util/StringUtils.hpp"
-#include <algorithm>
-#include <unordered_map>
 #include "relations/iq_relation.hpp"
-#include <mutex>
-#include <spectral_transform.hpp>
-#include <cvmd.hpp>
-#include <online_emd.hpp>
+#include "spectral_transform.hpp"
+#include "fast_cvmd.hpp"
+#include "online_emd.hpp"
 
 namespace svr {
 namespace business {
@@ -85,7 +86,7 @@
     );
 
     std::unique_ptr<svr::online_emd> p_oemd_transformer_fat, oemd_transformer_thin;
-    std::unique_ptr<svr::cvmd> p_cvmd_transformer;
+    std::unique_ptr<svr::fast_cvmd> p_cvmd_transformer;
 
     Dataset(Dataset const &dataset);
 
Index: config/daemon.config
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>SQL_PROPERTIES_DIR = ../SVRRoot/SVRPersist/postgres/\n#To enable Unix socket set md5 authentication in /etc/postgresql/9.5/main/pg_hba.conf for local connections\n#CONNECTION_STRING = dbname=svrwave user=svrwave password=svrwave host=/var/run/postgresql port=5432\nCONNECTION_STRING = dbname=svrwave user=svrwave password=svrwave host=localhost\nLOG_LEVEL = debug\nLOOP_INTERVAL_MS = 100\nDAO_TYPE = postgres\nDAEMONIZE = 0\nDISABLE_CASCADED_SVM = 1\nMULTISTEP_LEN = 1\nDONT_UPDATE_R_MATRIX = 1\nMAX_LOOP_COUNT = -1\nMAX_SMO_ITERATIONS = 2147483647\nMAIN_COLUMNS_AUX = 1\nSCALING_ALPHA = 0.01\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- config/daemon.config	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ config/daemon.config	(date 1672580765580)
@@ -13,3 +13,4 @@
 MAX_SMO_ITERATIONS = 2147483647
 MAIN_COLUMNS_AUX = 1
 SCALING_ALPHA = 0.01
+#OEMD_FIND_FIR_COEFFICIENTS = 1
Index: SVRRoot/SVRCommon/src/PropertiesFileReader.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#include \"util/PropertiesFileReader.hpp\"\n#include \"common/Logging.hpp\"\n#include <boost/algorithm/string/predicate.hpp>\n#include <cilk/cilk_api.h>\n#include \"util/StringUtils.hpp\"\n#include <common/constants.hpp>\n\nusing namespace std;\n\n// this is inherited dependency for logging output level\nint SVR_LOG_LEVEL;\n\nnamespace svr {\nnamespace common {\n\nconst string PropertiesFileReader::SQL_PROPERTIES_DIR_KEY = \"SQL_PROPERTIES_DIR\";\nconst string PropertiesFileReader::LOG_LEVEL_KEY = \"LOG_LEVEL\";\nconst string PropertiesFileReader::DAO_TYPE_KEY = \"DAO_TYPE\";\nconst string PropertiesFileReader::COMMENT_CHARS = \"#\";\nconst string PropertiesFileReader::DONT_UPDATE_R_MATRIX = \"DONT_UPDATE_R_MATRIX\";\nconst string PropertiesFileReader::MAIN_COLUMNS_AUX = \"MAIN_COLUMNS_AUX\";\nconst string PropertiesFileReader::MAX_SMO_ITERATIONS = \"MAX_SMO_ITERATIONS\";\nconst string PropertiesFileReader::CASCADE_REDUCE_RATIO = \"CASCADE_REDUCE_RATIO\";\nconst string PropertiesFileReader::CASCADE_MAX_SEGMENT_SIZE = \"CASCADE_MAX_SEGMENT_SIZE\";\nconst string PropertiesFileReader::DISABLE_CASCADED_SVM = \"DISABLE_CASCADED_SVM\";\nconst string PropertiesFileReader::CASCADE_BRANCHES_COUNT = \"CASCADE_BRANCHES_COUNT\";\nconst string PropertiesFileReader::SET_THREAD_AFFINITY = \"SET_THREAD_AFFINITY\";\nconst string PropertiesFileReader::MULTISTEP_LEN = \"MULTISTEP_LEN\";\nconst string PropertiesFileReader::SVR_PARAMTUNE_LEVEL = \"SVR_PARAMTUNE_LEVEL\";\nconst string PropertiesFileReader::SVR_PARAMTUNE_COLUMN = \"SVR_PARAMTUNE_COLUMN\";\nconst string PropertiesFileReader::ONLINE_ITERS_LIMIT_MULT = \"ONLINE_ITERS_LIMIT_MULT\";\nconst string PropertiesFileReader::ONLINE_LEARN_ITER_LIMIT = \"ONLINE_LEARN_ITER_LIMIT\";\nconst string PropertiesFileReader::SMO_EPSILON_DIVISOR = \"SMO_EPSILON_DIVISOR\";\nconst string PropertiesFileReader::SMO_COST_DIVISOR = \"SMO_COST_DIVISOR\";\nconst string PropertiesFileReader::STABILIZE_ITERATIONS_COUNT = \"STABILIZE_ITERATIONS_COUNT\";\nconst string PropertiesFileReader::DEFAULT_NUMBER_VARIATIONS = \"DEFAULT_NUMBER_VARIATIONS\";\nconst string PropertiesFileReader::ERROR_TOLERANCE = \"ERROR_TOLERANCE\";\nconst string PropertiesFileReader::SCALING_ALPHA = \"SCALING_ALPHA\";\nconst string PropertiesFileReader::ONLINESVR_LOG_FILE = \"ONLINESVR_LOG_FILE\";\nconst string PropertiesFileReader::MAX_VARIATIONS = \"MAX_VARIATIONS\";\nconst string PropertiesFileReader::COMB_TRAIN_COUNT = \"COMB_TRAIN_COUNT\";\nconst string PropertiesFileReader::COMB_VALIDATE_COUNT = \"COMB_VALIDATE_COUNT\";\nconst string PropertiesFileReader::COMB_VALIDATE_LIMIT = \"COMB_VALIDATE_LIMIT\";\nconst string PropertiesFileReader::ENABLE_COMB_VALIDATE = \"ENABLE_COMB_VALIDATE\";\nconst string PropertiesFileReader::FUTURE_PREDICT_COUNT = \"FUTURE_PREDICT_COUNT\";\nconst string PropertiesFileReader::SLIDE_COUNT = \"SLIDE_COUNT\";\nconst string PropertiesFileReader::TUNE_RUN_LIMIT = \"TUNE_RUN_LIMIT\";\nconst string PropertiesFileReader::TUNE_PARAMETERS = \"TUNE_PARAMETERS\";\nconst string PropertiesFileReader::ALL_AUX_LEVELS = \"ALL_AUX_LEVELS\";\n\n\nsize_t PropertiesFileReader::read_property_file(string property_file_name)\n{\n    LOG4_DEBUG(\"Reading properties from file: \" << property_file_name);\n\tMessageProperties::mapped_type params;\n\n\tifstream is_file(property_files_location + property_file_name);\n\n\tif(!is_file.is_open()) {\n\t\tthrow std::invalid_argument(\"Cannot read properties file: \" + property_files_location + property_file_name);\n\t}\n\tstring line;\n\tstring multi_line;\n\tbool is_multi_line = false;\n\n\twhile (getline(is_file, line)) {\n\t\ttrim(line);\n\t\tif(line.size() == 0) {\n\t\t\tis_multi_line = false;\n\t\t\tmulti_line.clear();\n\t\t\tcontinue;\n\t\t};\n\n\t\tif(is_comment(line)){\n\t\t\tcontinue;\n\t\t}\n\n\t\tif(is_multiline(line)){\n\t\t\tis_multi_line = true;\n\t\t\tmulti_line += line.substr(0, line.size()-1);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif(is_multi_line){ // final line of multiline property\n\t\t\tline = multi_line + line;\n\t\t\tis_multi_line = false;\n\t\t\tmulti_line.clear();\n\t\t}\n\t\tistringstream is_line(line);\n\t\tstring key;\n\t\tif (getline(is_line, key, this->delimiter)) {\n\t\t\tstring value;\n\t\t\tif (getline(is_line, value)){\n\t\t\t\tparams[trim(key)] = trim(value);\n\t\t\t}\n\t\t}\n\t}\n\n\tsize_t items = params.size();\n\tthis->property_files[property_file_name] = params;\n\tLOG4_DEBUG(\"Read total of \" << items << \" from property file \" << property_files_location << property_file_name);\n\treturn items;\n}\n\n// TODO Move hardcoded values to header file\nPropertiesFileReader::PropertiesFileReader(const string& app_config_file, char delimiter):\n\t\tdelimiter(delimiter), dao_type(ConcreteDaoType::PgDao)\n{\n#ifndef NDEBUG\n\t//__cilkrts_set_param(\"nworkers\", \"1\");\n#endif\n\tread_property_file(app_config_file);\n\tproperty_files_location = get_property<string>(app_config_file, SQL_PROPERTIES_DIR_KEY, DEFAULT_SQL_PROPERTIES_DIR_KEY);\n\tset_global_log_level(get_property<string>(app_config_file, LOG_LEVEL_KEY, DEFAULT_LOG_LEVEL_KEY));\n\tstd::string sdao_type = get_property<std::string>(app_config_file, DAO_TYPE_KEY, DEFAULT_DAO_TYPE_KEY);\n\tif (sdao_type == \"async\") dao_type = ConcreteDaoType::AsyncDao;\n\tdont_update_r_matrix_ = get_property<bool>(app_config_file, DONT_UPDATE_R_MATRIX, DEFAULT_DONT_UPDATE_R_MATRIX);\n    main_columns_aux_ = get_property<bool>(app_config_file, MAIN_COLUMNS_AUX, DEFAULT_MAIN_COLUMNS_AUX);\n\tmax_smo_iterations_ = get_property<size_t>(app_config_file, MAX_SMO_ITERATIONS, DEFAULT_MAX_SMO_ITERATIONS);\n\tcascade_reduce_ratio_ = get_property<double>(app_config_file, CASCADE_REDUCE_RATIO, DEFAULT_CASCADE_REDUCE_RATIO);\n    cascade_branches_count_ = get_property<size_t>(app_config_file, CASCADE_BRANCHES_COUNT, DEFAULT_CASCADE_BRANCHES_COUNT);\n    disable_cascaded_svm_ = get_property<size_t>(app_config_file, DISABLE_CASCADED_SVM, DEFAULT_DISABLE_CASCADED_SVM);\n\tcascade_max_segment_size_ = get_property<size_t>(app_config_file, CASCADE_MAX_SEGMENT_SIZE, DEFAULT_CASCADE_MAX_SEGMENT_SIZE);\n    set_thread_affinity_ = get_property<bool>(app_config_file, SET_THREAD_AFFINITY, \"0\");\n    multistep_len = get_property<size_t>(app_config_file, MULTISTEP_LEN, DEFAULT_MULTISTEP_LEN);\n    svr_paramtune_column = get_property<std::string>(app_config_file, SVR_PARAMTUNE_COLUMN, DEFAULT_SVR_PARAMTUNE_COLUMN);\n    svr_paramtune_level = get_property<std::string>(app_config_file, SVR_PARAMTUNE_LEVEL, DEFAULT_SVR_PARAMTUNE_LEVEL);\n    online_iters_limit_mult_ = get_property<size_t>(app_config_file, ONLINE_ITERS_LIMIT_MULT, DEFAULT_ONLINE_ITERS_LIMIT_MULT);\n    online_learn_iter_limit_ = get_property<size_t>(app_config_file, ONLINE_LEARN_ITER_LIMIT, DEFAULT_LEARN_ITER_LIMIT);\n    smo_epsilon_divisor_ = get_property<double>(app_config_file, SMO_EPSILON_DIVISOR, DEFAULT_SMO_EPSILON_DIVISOR);\n    smo_cost_divisor_ = get_property<double>(app_config_file, SMO_COST_DIVISOR, DEFAULT_SMO_COST_DIVISOR);\n    stabilize_iterations_count_ = get_property<size_t>(app_config_file, STABILIZE_ITERATIONS_COUNT, DEFAULT_STABILIZE_ITERATIONS_COUNT);\n    default_number_variations_ = get_property<size_t>(app_config_file, DEFAULT_NUMBER_VARIATIONS, DEFAULT_DEFAULT_NUMBER_VARIATIONS);\n    error_tolerance_ = get_property<double>(app_config_file, ERROR_TOLERANCE, DEFAULT_ERROR_TOLERANCE);\n    online_svr_log_file_ = get_property<string>(app_config_file, ONLINESVR_LOG_FILE, DEFAULT_ONLINESVR_LOG_FILE);\n    max_variations_ = get_property<size_t>(app_config_file, MAX_VARIATIONS, DEFAULT_MAX_VARIATIONS);\n\tcomb_train_count_ = get_property<size_t>(app_config_file, COMB_TRAIN_COUNT, DEFAULT_COMB_TRAIN_COUNT);\n\tcomb_validate_count_ = get_property<size_t>(app_config_file, COMB_VALIDATE_COUNT, DEFAULT_COMB_VALIDATE_COUNT);\n\tcomb_validate_limit_ = get_property<size_t>(app_config_file, COMB_VALIDATE_LIMIT, DEFAULT_COMB_VALIDATE_LIMIT);\n\tenable_comb_validate_ = get_property<bool>(app_config_file, ENABLE_COMB_VALIDATE, DEFAULT_ENABLE_COMB_VALIDATE);\n    tune_parameters_ = get_property<bool>(app_config_file, TUNE_PARAMETERS, DEFAULT_TUNE_PARAMETERS);\n    future_predict_count_ = get_property<size_t>(app_config_file, FUTURE_PREDICT_COUNT, DEFAULT_FUTURE_PREDICT_COUNT);\n    slide_count_ = get_property<size_t>(app_config_file, SLIDE_COUNT, DEFAULT_SLIDE_COUNT);\n\ttune_run_limit_ = get_property<size_t>(app_config_file, TUNE_RUN_LIMIT, DEFAULT_TUNE_RUN_LIMIT);\n\tscaling_alpha_ = get_property<double>(app_config_file, SCALING_ALPHA, DEFAULT_SCALING_ALPHA);\n\tall_aux_levels_ = get_property<bool>(app_config_file, ALL_AUX_LEVELS, DEFAULT_ALL_AUX_LEVELS);\n}\n\nConcreteDaoType PropertiesFileReader::get_dao_type() const\n{\n    return dao_type;\n}\n\nconst MessageProperties::mapped_type& PropertiesFileReader::read_properties(const string &property_file)\n{\n    if(this->property_files.count(property_file) || read_property_file(property_file))\n        return this->property_files[property_file];\n    static MessageProperties::mapped_type empty;\n    return empty;\n}\n\n\nvoid PropertiesFileReader::set_global_log_level(const std::string &log_level_value)\n{\n    if(strcasecmp(log_level_value.c_str(), \"ALL\") == 0)\n        SVR_LOG_LEVEL = LOG_LEVEL_T::TRACE;\n    else if(strcasecmp(log_level_value.c_str(), \"TRACE\") == 0)\n        SVR_LOG_LEVEL = LOG_LEVEL_T::TRACE;\n    else if(strcasecmp(log_level_value.c_str(), \"DEBUG\") == 0)\n        SVR_LOG_LEVEL = LOG_LEVEL_T::DEBUG;\n    else if(strcasecmp(log_level_value.c_str(), \"INFO\") == 0)\n        SVR_LOG_LEVEL = LOG_LEVEL_T::INFO;\n    else if(strcasecmp(log_level_value.c_str(), \"WARN\") == 0)\n        SVR_LOG_LEVEL = LOG_LEVEL_T::WARN;\n    else if(strcasecmp(log_level_value.c_str(), \"ERROR\") == 0)\n        SVR_LOG_LEVEL = LOG_LEVEL_T::ERR;\n    else if(strcasecmp(log_level_value.c_str(), \"FATAL\") == 0)\n        SVR_LOG_LEVEL = LOG_LEVEL_T::FATAL;\n}\n\nbool PropertiesFileReader::is_comment(const std::string& line)\n{\n\treturn boost::starts_with(line, COMMENT_CHARS);\n}\n\nbool PropertiesFileReader::is_multiline(const std::string &line)\n{\n\tif(line.size() == 0){\n\t\treturn false;\n\t}\n\n\tbool even_slash_count = true;\n\tauto c = line.rbegin();\n\twhile(c != line.rend() && *c == '\\\\'){\n\t\teven_slash_count = !even_slash_count;\n\t\tc++;\n\t}\n\treturn !even_slash_count;\n}\n\nstd::string PropertiesFileReader::get_property_value(\n\t\tconst std::string &property_file, const std::string &key, std::string default_value)\n{\n\tLOG4_BEGIN();\n\n\tif(this->property_files.count(property_file) == 0 && read_properties(property_file).size() == 0) return default_value;\n\tif(this->property_files.count(property_file) && this->property_files[property_file].count(key))\n\t\tdefault_value = this->property_files[property_file][key];\n\tLOG4_TRACE(\"Found property \" << property_file << \" \" << key << \" is \" << default_value);\n\n\tLOG4_END();\n\n\treturn default_value;\n}\n\nstd::vector<size_t> PropertiesFileReader::get_svr_paramtune_levels() const\n{\n    LOG4_BEGIN();\n\n    std::stringstream iss(svr_paramtune_level);\n    std::vector<size_t> result;\n    size_t num;\n    while (iss >> num) result.push_back(num);\n    return result;\n}\n} /* namespace common */\n} /* namespace svr */\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- SVRRoot/SVRCommon/src/PropertiesFileReader.cpp	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ SVRRoot/SVRCommon/src/PropertiesFileReader.cpp	(date 1672580817680)
@@ -45,6 +45,7 @@
 const string PropertiesFileReader::FUTURE_PREDICT_COUNT = "FUTURE_PREDICT_COUNT";
 const string PropertiesFileReader::SLIDE_COUNT = "SLIDE_COUNT";
 const string PropertiesFileReader::TUNE_RUN_LIMIT = "TUNE_RUN_LIMIT";
+const string PropertiesFileReader::OEMD_FIND_FIR_COEFFICIENTS = "OEMD_FIND_FIR_COEFFICIENTS";
 const string PropertiesFileReader::TUNE_PARAMETERS = "TUNE_PARAMETERS";
 const string PropertiesFileReader::ALL_AUX_LEVELS = "ALL_AUX_LEVELS";
 
@@ -144,6 +145,7 @@
 	tune_run_limit_ = get_property<size_t>(app_config_file, TUNE_RUN_LIMIT, DEFAULT_TUNE_RUN_LIMIT);
 	scaling_alpha_ = get_property<double>(app_config_file, SCALING_ALPHA, DEFAULT_SCALING_ALPHA);
 	all_aux_levels_ = get_property<bool>(app_config_file, ALL_AUX_LEVELS, DEFAULT_ALL_AUX_LEVELS);
+    oemd_find_fir_coefficients_ = get_property<bool>(app_config_file, OEMD_FIND_FIR_COEFFICIENTS, DEFAULT_OEMD_FIND_FIR_COEFFICIENTS);
 }
 
 ConcreteDaoType PropertiesFileReader::get_dao_type() const
Index: SVRRoot/OnlineSVR/src/fast_cvmd.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>//\n// Created by zarko on 7/5/22.\n//\n\n#include \"fast_cvmd.hpp\"\n#include \"common/compatibility.hpp\"\n#include \"common/Logging.hpp\"\n\nnamespace svr {\n\n\n#ifdef COMPARE_TWO_ALGORITHMS\n//useful for test\ndouble loss_func_quadratic(const size_t K, const size_t len, const double *UV, const double *cos_phases, const double *sin_phases)\n{\n    double result = 0;\n    for (size_t ii = 0; ii < len - 1; ii++) {\n        for (size_t jj = 0; jj < K; jj++) {\n            std::complex<double> left(UV[2 * jj + 0 + ii * 2 * K], UV[2 * jj + 1 + 0 + ii * 2 * K]);\n            std::complex<double> right(UV[2 * jj + 0 + (ii + 1) * 2 * K], UV[2 * jj + 1 + 0 + (ii + 1) * 2 * K]);\n            std::complex<double> phase(cos_phases[jj], -sin_phases[jj]);\n            result += std::norm(left - right * phase);\n        }\n    }\n    return result;\n}\n#endif\n\nstatic void compute_cos_sin(const std::vector<double> &omega, std::vector<double> &phase_cos, std::vector<double> &phase_sin, const double step = 1)\n{\n    PFORi(0, omega.size(),\n        phase_cos[i] = cos(2 * M_PI * step * omega[i]);\n        phase_sin[i] = sin(2 * M_PI * step * omega[i]);\n    )\n}\n\n\nstatic void\ncreate_solve_problem(\n        const size_t K,\n        const std::vector<double> &previous,\n        const std::vector<double> &values,\n        const std::vector<double> &phase_cos,\n        const std::vector<double> &phase_sin,\n        arma::mat &H,\n        arma::mat &f,\n        arma::mat &A)\n{\n    const size_t n = values.size();\n    A = arma::zeros(n, n * 2 * K);\n    PFORi(0, n, for (size_t j = 0; j < K; ++j) A(i, 2 * j + i * 2 * K) = 1)\n\n    H = arma::zeros(n * 2 * K, n * 2 * K);\n    f = arma::zeros(n * 2 * K, 1);\n    for (size_t i = 0; i < n; ++i) {\n        if (i == 0) {\n            PFOR(j, 0, K,\n                const double prev_ui = previous[2 * j];\n                const double prev_vi = previous[2 * j + 1];\n                const double CC = phase_cos[j];\n                const double SS = phase_sin[j];\n\n                //%u_i+1, u_i+1\n                H(2 * j + i * 2 * K, 2 * j + i * 2 * K) += 1.;\n                H(2 * j + 1 + i * 2 * K, 2 * j + 1 + i * 2 * K) += 1.;\n                //%f for u_i+1 u_i\n                f(2 * j + i * 2 * K, 0) += -CC * prev_ui;\n                //%f for v_i+1 u_i\n                f(2 * j + 1 + i * 2 * K, 0) += -SS * prev_ui;\n\n                //%f for v_i+1 v_i\n                f(2 * j + 1 + i * 2 * K, 0) += -CC * prev_vi;\n                //%f for u_i+1 v_i\n                f(2 * j + i * 2 * K) += SS * prev_vi;\n            )\n        } else {\n            PFOR(j, 0, K,\n                const double CC = phase_cos[j];\n                const double SS = phase_sin[j];\n\n                H(2 * j + (i - 1) * 2 * K, 2 * j + (i - 1) * 2 * K) += 1.;\n                H(2 * j + 1 + (i - 1) * 2 * K, 2 * j + 1 + (i - 1) * 2 * K) += 1.;\n                H(2 * j + i * 2 * K, 2 * j + i * 2 * K) += 1.;\n                H(2 * j + 1 + i * 2 * K, 2 * j + 1 + i * 2 * K) += 1.;\n\n                H(2 * j + (i - 1) * 2 * K, 2 * j + i * 2 * K) += (-CC);\n                H(2 * j + i * 2 * K, 2 * j + (i - 1) * 2 * K) += (-CC);\n\n                H(2 * j + (i - 1) * 2 * K, 2 * j + 1 + i * 2 * K) += (-SS);\n                H(2 * j + 1 + i * 2 * K, 2 * j + (i - 1) * 2 * K) += (-SS);\n\n                H(2 * j + 1 + (i - 1) * 2 * K, 2 * j + 1 + i * 2 * K) += (-CC);\n                H(2 * j + 1 + i * 2 * K, 2 * j + 1 + (i - 1) * 2 * K) += (-CC);\n\n                H(2 * j + 1 + (i - 1) * 2 * K, 2 * j + i * 2 * K) += SS;\n                H(2 * j + i * 2 * K, 2 * j + 1 + (i - 1) * 2 * K) += SS;\n            )\n        }\n    }\n}\n\n\nvoid\nfast_cvmd::step_decompose_matrix(\n    const std::vector<double> &omega,\n    const std::vector<double> &values,\n    const std::vector<double> &previous,\n    std::vector<std::vector<double>> &decomposition)\n{\n    const size_t len = values.size();\n    std::vector<double> phase_cos, phase_sin;\n    compute_cos_sin(omega, phase_cos, phase_sin, 1);\n    const size_t K = phase_cos.size();\n    // const size_t N = 2 * K;\n    if (decomposition.size() != len) decomposition.resize(len);\n    PFORi(0, len, if (decomposition[i].size() != 2 * K) decomposition[i].resize(2 * K));\n\n    arma::mat H, f, A;\n    create_solve_problem(K, previous, values, phase_cos, phase_sin, H, f, A);\n#ifdef USE_SLOWER_ALGORITHM\n    const arma::mat big_matrix = arma::join_cols(arma::join_rows(H, A.t()), arma::join_rows(A, arma::zeros(len, len)));\n\n    arma::mat rhs = arma::join_cols(-f,b);\n    arma::mat solution2 = arma::solve (big_matrix, rhs);\n    std::memcpy(decomposition.data(),solution2.memptr(),2*K*len*sizeof(double));\n#else\n//use faster algorithm\n    {\n        const arma::mat lambda = -arma::solve( A * arma::solve(H, A.t()), A * arma::solve(H, f) + arma::mat(values.data(), len, 1) ); //     PROFILE_EXEC_TIME(solved = call_gpu_oversolve(a, b), \"call_gpu_oversolve \" << arma::size(a) << \", \" << arma::size(b)); // Emo's IRWLS solver\n        const arma::mat solution = arma::solve(H, -A.t() * lambda - f);\n\n        LOG4_DEBUG(\"Solution size \" << arma::mat(solution));\n\n        PFOR(l, 0, 2 * K, for (size_t t = 0; t < len; ++t) decomposition[t][l] = solution.memptr()[t * 2 * K + l] )\n        //std::memcpy(decomposition.data(), solution.memptr(), 2 * K * len * sizeof(double));\n    }\n#endif\n\n#ifdef COMPARE_TWO_ALGORITHMS\n    double sum = 0;\n    for(int i=0;i<2*K*len;i++) sum+=fabs(solution2(i,0)-solution(i,0));\n    //std::cout << \" difference between two algorithms, should be almost 0.\" << sum<< std::endl;\n#endif\n}\n\n\nfast_cvmd::fast_cvmd(const size_t _levels)\n        : spectral_transform(std::string(\"fast_cvmd\"), _levels), levels(_levels)\n{\n    if (levels < 2 or levels % 2) LOG4_THROW(\"Invalid number of levels \" << levels);\n}\n\n\nfast_cvmd::~fast_cvmd()\n{\n}\n\n\nstatic void\ndo_vmd_freqs(\n    const arma::mat &signal, const double alpha, const double tau, const int K, const int DC, const int init,\n    const double tol, /* outputs */ arma::mat &u, arma::cx_mat &u_hat, std::vector<double> &omega_plus)\n{\n    //Initialize u, w, lambda, n\n    //\n    const int save_T = signal.n_elem;\n\n    int T = save_T;\n    if (T & 1) LOG4_THROW(\"Input data size \" << T << \" must be even!\");\n\n    //create the mirrored signal\n    arma::mat f_mirror = arma::zeros(1,2 * T);\n\n    PFORi(0, T / 2, f_mirror(0, i) = signal(0, T / 2 - 1 - i))\n    PFORi(0, T, f_mirror(0, T / 2 + i) = signal(0, i))\n    PFORi(0, T / 2, f_mirror(0, 3 * T / 2 + i) = signal(0, T - 1 - i))\n\n    arma::mat f = f_mirror;\n    T = 2 * T;\n\n    arma::mat Alpha = alpha * arma::ones(1, K); //provision to use different alpha for the different frequences, at a later stage\n\n    const double fs = 1. / double(save_T); //step\n\n    const int N_max = MAX_VMD_ITERATIONS; //max number of iterations\n\n    u = arma::zeros(T,K);\n    const double eps = 2.220446049250313e-16;\n    //this may or may not work instead. double eps=std::numeric_limits<T>::epsilon();\n\n    // Time Domain 0 to T (of mirrored signal)\n    arma::mat t(1, T);\n    PFORi(0, T, t(0,i) = (double(i) + 1.) / double(T))\n    // Spectral Domain discretization\n    arma::mat freqs = t - 0.5 - 1. / double(T);\n    omega_plus.resize(K);\n    memset(omega_plus.data(), 0, omega_plus.size() * sizeof(double));\n    arma::cx_mat f_hat = common::fftshift(common::matlab_fft(f));\n    arma::cx_mat f_hat_plus = f_hat;\n\n    PFORi(0, T / 2, f_hat_plus(0, i) = 0)\n\n    switch (init) {\n        case 1:{\n            PFORi(0, K, omega_plus[i] = 0.5 / K * i);\n            break;\n        }\n        case 2:{\n            arma::mat real_ran (K,1);\n            PFORi(0, K, real_ran(i, 0) = exp(log(fs) + (log(0.5) - log(fs)) * common::randouble()));\n            real_ran = arma::sort(real_ran);\n            PFORi(0, K, omega_plus[i] = real_ran(i, 0));\n            break;\n        }\n        case 0:{\n            //PFORi(0, K, omega_plus[i] = 0);\n            break;\n        }\n        default:{\n            LOG4_THROW(\"Init should be 0,1 or 2!\");\n        }\n    }\n    if (DC == 1) { //if DC component, then first frequency is 0!\n        omega_plus[0] = 0;\n    }\n    /* completed initialization of frequencies */\n    arma::cx_mat lambda_hat( arma::zeros(1, freqs.n_elem), arma::zeros(1, freqs.n_elem)); // keeping track of the evolution of lambda_hat with the iterations\n    arma::cx_mat u_hat_plus(arma::zeros(T,K),arma::zeros(T,K));\n    arma::cx_mat u_hat_plus_old = u_hat_plus;\n\n#ifdef DEBUG_CVMD\n    double uDiff{tol+eps};\n#else\n    double uDiff = tol + eps; //tol+eps must be different from just tol, that is why eps should not be too small\n#endif\n\n    arma::cx_mat sum_uk(arma::zeros(1, T),arma::zeros(1, T));\n    int n_iter = 0;\n#ifdef DEBUG_CVMD\n    while  ((n_iter < N_max) && (uDiff > tol)) {\n#else\n    while (n_iter < N_max && uDiff > tol) {\n#endif\n        //% update first mode accumulator\n        PFORi(0, T, sum_uk(0, i) = u_hat_plus_old(i, K-1) + sum_uk(0, i) - u_hat_plus_old(i, 0));\n\n        //% update spectrum of first mode through Wiener filter of residuals\n        int k = 0;\n        PFORi(0, T,\n              u_hat_plus(i, k) = (f_hat_plus(0, i) - sum_uk(0, i) - lambda_hat(0, i) / 2.) / (1. + Alpha(0, k) * std::pow((freqs(0, i) - omega_plus[k]), 2)) )\n\n        if (DC == 0) {\n            //when DC==1, the first frequency can not be changed. that is why this cycle only for DC==0.\n#ifdef DEBUG_CVMD\n            double sum_up = 0.;\n            double sum_down = 0.;\n            for (int i=0; i < T/2; ++i) {\n                sum_up += freqs(0,T/2+i)*std::norm(u_hat_plus(T/2+i,k));\n                sum_down += std::norm(u_hat_plus(T/2+i,k));\n            }\n            omega_plus(0,0) = sum_up / sum_down;\n#else\n            double clk_sum_up = 0;\n            double clk_sum_down = 0;\n            for (int i = 0; i < T / 2; ++i) {\n                const auto norm_uhat_plus = std::norm(u_hat_plus(T / 2 + i, k));\n                clk_sum_up += freqs(0,T / 2 + i) * norm_uhat_plus;\n                clk_sum_down += norm_uhat_plus;\n            }\n            omega_plus[0] = clk_sum_up / clk_sum_down;\n#endif\n        }\n\n        // update of any other mode (k from 1 to K-1), after the first\n        for (k = 1; k < K; ++k) {\n            // accumulator\n            PFORi(0, T, sum_uk(0, i) = u_hat_plus(i, k - 1) + sum_uk(0, i) - u_hat_plus_old(i, k))\n            // mode spectrum\n            PFORi(0, T, u_hat_plus(i, k) = (f_hat_plus(0, i) - sum_uk(0, i) - lambda_hat(0, i) / 2.) / (1. + Alpha(0, k) * std::pow(freqs(0, i) - omega_plus[k], 2)))\n\n            //re-compute center frequencies\n#ifdef DEBUG_CVMD\n            double sum_up = 0.;\n            double sum_down = 0.;\n            for (int i = 0; i < T / 2; ++i) {\n                sum_up += freqs(0, T / 2 + i) * std::norm(u_hat_plus(T / 2 + i, k));\n                sum_down += std::norm(u_hat_plus(T / 2 + i, k));\n            }\n            omega_plus(k, 0) = sum_up / sum_down;\n#else\n            double clk_sum_up = 0;\n            double clk_sum_down = 0;\n            for (int i = 0; i < T / 2; ++i) {\n                const double u_hat_plus_norm = std::norm(u_hat_plus(T / 2 + i, k));\n                clk_sum_up += freqs(0, T / 2 + i) * u_hat_plus_norm;\n                clk_sum_down += u_hat_plus_norm;\n            }\n            omega_plus[k] = clk_sum_up / clk_sum_down;\n#endif\n        }\n        // Dual ascent\n        arma::cx_mat sum_u_hat_plus = arma::sum(u_hat_plus.t());\n\n        PFORi(0, T, lambda_hat(0, i) += tau * (sum_u_hat_plus(0, i) - f_hat_plus(0, i)) )\n        // loop counter\n        ++n_iter;\n\n        //compute uDiff\n#ifdef DEBUG_CVMD\n        uDiff = 0.;\n#else\n        uDiff = 0;\n#endif\n        for (int i = 0; i < K; ++i) {\n            double s = 0;\n            double s_norm_old = 0;\n            for (int j = 0; j < T; ++j) {\n                s += std::norm(u_hat_plus(j,i) - u_hat_plus_old(j,i));\n                s_norm_old += std::norm(u_hat_plus_old(j,i));\n            }\n            uDiff += (s / s_norm_old);\n        }\n        u_hat_plus_old = u_hat_plus;\n    }\n    //%------ Postprocessing and cleanup\n    //% discard empty space if converged early - this step is not used here\n    //N = min(N,n);\n    //omega = omega_plus(1:N,:);\n    // - this not needed, since we do not keep all omega, only the latest!\n\n    // Signal reconstruction\n    arma::cx_mat zmat(arma::zeros(T, K), arma::zeros(T, K));\n    u_hat = zmat;\n    PFORi(0, T / 2,\n          for (int k = 0; k < K; ++k) u_hat(T / 2 + i, k) = u_hat_plus(T / 2 + i, k) )\n    // here it is not clear why, but T/2 is set both above and below. Instead, the 0 is set to conj of T-1\n    PFORi(0, T / 2, for (int k=0; k < K; ++k) u_hat(T / 2 - i, k) = std::conj(u_hat_plus(T / 2 + i, k)) )\n    for (int k = 0; k < K; ++k) u_hat(0, k) = std::conj(u_hat(T - 1, k));\n\n    arma::mat u_big = arma::zeros(K, t.n_elem);\n    PFOR(k, 0, K, u_big.rows(k, k) = arma::trans( arma::real(common::matlab_ifft(common::ifftshift(u_hat.cols(k, k))))) )\n    u = arma::zeros(K,T / 2);\n    PFORi(0, T / 2, for (int k = 0; k < K; ++k) u(k, i) = u_big(k, T / 4 + i) )\n    //recompute spectrum\n    //clear u_hat;\n    u_hat = arma::cx_mat(arma::zeros(K,T / 2),arma::zeros(K,T / 2));\n    PFOR(k, 0, K,\n         u_hat.rows(k,k) = common::fftshift(common::matlab_fft(u.rows(k,k)));\n         omega_plus[k] /= CVMD_FREQ_ADJUST; )\n\n    LOG4_TRACE(\"Omega is \" << common::deep_to_string(omega_plus));\n}\n\n\nstatic fcvmd_frequency_outputs\ncalculate_vmd_frequencies(const std::vector<double> &input, const size_t levels_half)\n{\n    LOG4_DEBUG(\"Calculating VMD frequencies for \" << levels_half << \" half levels.\");\n\n    arma::rowvec x_signal;\n    if (input.size() % 2) LOG4_WARN(\"Odd signal length \" << input.size() << \", trimming first value.\");\n    x_signal = input.size() % 2 ? arma::rowvec(&*std::next(input.begin()), input.size() - 1) : input;\n\n    /* constants */\n    const double alpha = ALPHA_BINS; //bands\n    const double tau = TAU_FIDELITY; //fidelity - 0 means no strict enforcement of decomposition. In reality we should use something like 0.1 or higher.\n    const int DC = 0; //has a DC component or not.\n    const int K = levels_half; //number of modes/frequencies. because of DC=1 we use 1 more than the natural number of frequencies (3 in the signal above).\n    const int init = 1; //kind of initialization, let's use 1 for now.\n    const double tol = 1e-7; //some tolerance\n    /* end constants */\n    /* outputs */\n    arma::mat u;\n    arma::cx_mat u_hat;\n    std::vector<double> omega;\n    /* end outputs*/\n\n    do_vmd_freqs(x_signal, alpha, tau, K, DC, init, tol, u, u_hat, omega);\n#ifdef DEBUG_CVMD\n    {\n        std::stringstream ss_input;\n        for (size_t i = 0; i < T; ++i) ss_input << x_signal(0, i) << \", \";\n        LOG4_FILE(\"cvmd_input.csv\", ss_input.str());\n    }\n    {\n        std::stringstream ss_omega;\n        for (size_t i = 0; i < omega.n_rows; ++i) ss_omega << omega(i, 0) << \", \";\n        LOG4_FILE(\"cvmd_omega.csv\", ss_omega.str());\n    }\n#endif\n\n    return {omega};\n}\n\n\nbool\nfast_cvmd::initialized(const std::string &decon_queue_table_name)\n{\n    const auto freq_key = freq_key_t(decon_queue_table_name, levels);\n    return not vmd_frequencies.empty() and vmd_frequencies.find(freq_key) != vmd_frequencies.end();\n}\n\n\nvoid\nfast_cvmd::initialize(const std::vector<double> &input, const std::string &decon_queue_table_name)\n{\n    LOG4_DEBUG(\"Initializing omega on \" << input.size() << \" rows, for \" << levels << \" levels, \" << decon_queue_table_name << \" table.\");\n    const auto freq_key = freq_key_t(decon_queue_table_name, levels);\n    static std::mutex mx;\n    if (vmd_frequencies.empty() or vmd_frequencies.find(freq_key) == vmd_frequencies.end()) {\n        const auto freqs = calculate_vmd_frequencies(input, levels / 2);\n        const std::lock_guard<std::mutex> lg(mx);\n        vmd_frequencies[freq_key] = freqs;\n    }\n}\n\n\nvoid\nfast_cvmd::transform(\n        const std::vector<double> &input,\n        std::vector<std::vector<double>> &decon,\n        const size_t padding = 0)\n{\n    THROW_EX_FS(std::logic_error, \"Not implemented!\");\n}\n\n\n// Online VMD transform\nvoid\nfast_cvmd::transform(\n        const std::vector<double> &input,\n        std::vector<std::vector<double>> &decon,\n        const std::string &decon_queue_table_name,\n        const std::vector<double> &prev_decon)\n{\n    if (vmd_frequencies.empty()) LOG4_THROW(\"VMD frequencies empty!\");\n    const auto found_freqs = vmd_frequencies.find(freq_key_t(decon_queue_table_name, levels));\n    if (found_freqs == vmd_frequencies.end()) LOG4_THROW(\"VMD frequencies not found!\");\n\n    const auto &omega = found_freqs->second.omega;\n    step_decompose_matrix(omega, input, prev_decon, decon);\n}\n\n\n// Batch transform\nvoid\nfast_cvmd::transform(\n        const std::vector<double> &input,\n        std::vector<std::vector<double>> &decon,\n        const std::string &table_name)\n{\n    if (vmd_frequencies.empty()) THROW_EX_FS(std::runtime_error, \"Empty VMD frequencies!\");\n\n    const auto found_freqs = vmd_frequencies.find({table_name, levels});\n    if (found_freqs == vmd_frequencies.end()) THROW_EX_FS(std::runtime_error, \"VMD frequencies not found!\");\n\n    const auto &omega = found_freqs->second.omega;\n    step_decompose_matrix(omega, input, std::vector<double>(levels, 0.), decon);\n}\n\n\nvoid\nfast_cvmd::inverse_transform(\n        const std::vector<double> &decon,\n        std::vector<double> &recon,\n        const size_t padding) const\n{\n    const size_t input_size = decon.size() / levels;\n    recon.resize(input_size, 0);\n    PFOR(t, 0, input_size,\n        recon[t] = 0;\n        for (size_t l = 0; l < levels / 2; ++l) recon[t] += decon[t + 2 * l * input_size];\n    )\n}\n\n\nsize_t\nfast_cvmd::get_residuals_length(const std::string &decon_queue_table_name)\n{\n    LOG4_DEBUG(\"Getting residuals length for \" << decon_queue_table_name << \" \" << levels << \" levels.\");\n\n    const auto freq_key = freq_key_t(decon_queue_table_name, levels);\n    const auto vmd_freq_iter = vmd_frequencies.find(freq_key);\n    if (vmd_freq_iter != vmd_frequencies.end()) return std::pow(levels / 2, 2);\n    else {\n        size_t res_len = std::pow(levels / 2, 4);\n        if (res_len % 2) ++res_len;\n        return res_len;\n    }\n}\n\n\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- SVRRoot/OnlineSVR/src/fast_cvmd.cpp	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ SVRRoot/OnlineSVR/src/fast_cvmd.cpp	(date 1672559513347)
@@ -380,12 +380,12 @@
     {
         std::stringstream ss_input;
         for (size_t i = 0; i < T; ++i) ss_input << x_signal(0, i) << ", ";
-        LOG4_FILE("cvmd_input.csv", ss_input.str());
+        LOG4_FILE("fcvmd_input.csv", ss_input.str());
     }
     {
         std::stringstream ss_omega;
         for (size_t i = 0; i < omega.n_rows; ++i) ss_omega << omega(i, 0) << ", ";
-        LOG4_FILE("cvmd_omega.csv", ss_omega.str());
+        LOG4_FILE("fcvmd_omega.csv", ss_omega.str());
     }
 #endif
 
Index: SVRRoot/OnlineSVR/include/fast_cvmd.hpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>//\n// Created by zarko on 7/5/22.\n//\n\n#ifndef SVR_FAST_CVMD_HPP\n#define SVR_FAST_CVMD_HPP\n\n#include <vector>\n#include <armadillo>\n\n#include \"spectral_transform.hpp\"\n\n#define TAU_FIDELITY 0\n#define ALPHA_BINS 2000\n#define MAX_VMD_ITERATIONS 500\n\nnamespace svr {\n\ntypedef std::tuple<\n        std::string /* decon queue table_name */,\n        size_t /* levels */> freq_key_t;\n\nstruct fcvmd_frequency_outputs {\n    std::vector<double>       omega;\n};\n\n#define FVMD_ONLINE_TAIL 0\n\nclass fast_cvmd : public spectral_transform\n{\n    size_t levels = 0;\n    std::map<freq_key_t, fcvmd_frequency_outputs> vmd_frequencies;\n\n    void\n    step_decompose_matrix(\n            const std::vector<double> &omega, const std::vector<double> &values,\n            const std::vector<double> &previous, std::vector<std::vector<double>> &decomposition);\n\npublic:\n    explicit fast_cvmd(const size_t levels);\n\n    virtual ~fast_cvmd() final;\n\n    virtual void transform(\n            const std::vector<double> &input,\n            std::vector<std::vector<double>> &decon,\n            const size_t padding /* = 0 */) override;\n\n    void transform(\n            const std::vector<double> &input,\n            std::vector<std::vector<double>> &decon,\n            const std::string &table_name,\n            const std::vector<double> &prev_decon);\n\n    void transform(\n            const std::vector<double> &input,\n            std::vector<std::vector<double>> &decon,\n            const std::string &table_name);\n\n    virtual void inverse_transform(\n            const std::vector<double> &decon,\n            std::vector<double> &recon,\n            const size_t padding /* = 0 */) const override;\n\n    size_t get_residuals_length(const std::string &decon_queue_table_name);\n\n    bool initialized(const std::string &decon_queue_table_name);\n    void initialize(const std::vector<double> &input, const std::string &decon_queue_table_name);\n};\n\n}\n\n#endif //SVR_FAST_CVMD_HPP\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- SVRRoot/OnlineSVR/include/fast_cvmd.hpp	(revision 9236923769d99278c0b99e82c10472697ff7f87e)
+++ SVRRoot/OnlineSVR/include/fast_cvmd.hpp	(date 1672561263207)
@@ -14,6 +14,8 @@
 #define ALPHA_BINS 2000
 #define MAX_VMD_ITERATIONS 500
 
+#define CVMD_INPUT_MULTIPLIER 1 // Not used, leave at 1
+
 namespace svr {
 
 typedef std::tuple<
