//
// Created by zarko on 6/24/21.
//

#include <utility>
#include <algorithm>
#include <common/rtp_thread_pool.hpp>
#include <common/thread_pool.hpp>
#include <bitset>

#include "appcontext.hpp"
#include "onlinesvr.hpp"
#include "util/ValidationUtils.hpp"
#include "util/TimeUtils.hpp"
#include "spectral_transform.hpp"
#include "model/User.hpp"
#include "SVRParametersService.hpp"
#include "DAO/DatasetDAO.hpp"
#include "DatasetService.hpp"
#include "InputQueueService.hpp"


using namespace svr::common;
using namespace svr::datamodel;
using namespace svr::context;


namespace svr {
namespace business {

#include <memory_resource>

// TODO port to CUDA kernel
void DatasetService::recombine_params(predictions_t &tune_predictions, std::vector<SVRParameters_ptr> &ensemble_params, const size_t half_levct)
{
    if (tune_predictions.empty()) return;
    bool empty_preds = true; 
    for (size_t i = 0; i < tune_predictions.size(); ++i) empty_preds &= tune_predictions[i].empty();
    if (empty_preds) return;

    const double C_filter_combos = std::pow<double>(C_tune_keep_preds, half_levct - 1) / double(C_num_combos);
    std::vector<std::vector<t_param_preds *>> combined_predictions(half_levct - 1, std::vector<t_param_preds *>(C_num_combos, nullptr));
    uint64_t target_col_ix = 0;
    LOG4_DEBUG("Predictions filtered out " << C_filter_combos << ", total prediction rows " << C_num_combos);
    for (auto &tuniter: tune_predictions) { // Do not parallelize!
        if (tuniter.empty()) continue;
        const auto prev_row_ct = std::pow<uint64_t>(C_tune_keep_preds, target_col_ix);
        const uint64_t new_row_ct = prev_row_ct * C_tune_keep_preds;
        const uint64_t rand_offset = 0; // std::rand() % std::fmod(new_row_ct - 1, C_filter_combos);
        LOG4_DEBUG("Existing matrix size " << prev_row_ct << "x" << half_levct - 1 << ", adding set of size " << tuniter.size() << ", at level " << target_col_ix << ", filter out " << C_filter_combos << " combinations, new row count " << new_row_ct << ", rand offset " << rand_offset);
#pragma omp parallel for
        for (int64_t col_ix = target_col_ix; col_ix >= 0; --col_ix) {
            for (double row_ix = new_row_ct - 1 /* rand_offset + ((new_row_ct - 1) - std::fmod(new_row_ct - 1, C_filter_combos)) */; row_ix >= 0; row_ix -= C_filter_combos) {
                uint64_t target_row_ix = std::round(row_ix / C_filter_combos);
                if (uint64_t(col_ix) == target_col_ix && combined_predictions[col_ix][target_row_ix] != nullptr && target_row_ix < new_row_ct - 1) ++target_row_ix;
                combined_predictions[col_ix][target_row_ix] = col_ix < int64_t(target_col_ix) ? combined_predictions[col_ix][(prev_row_ct * row_ix / new_row_ct) / C_filter_combos] : std::next(tuniter.begin(), target_row_ix % C_tune_keep_preds)->get();
            }
        }
        ++target_col_ix;
    }

    double best_score = std::numeric_limits<double>::max();
    std::mutex mx_comb;
#pragma omp parallel for
    for (uint64_t pred_ix = 0; pred_ix < C_num_combos; ++pred_ix) {
//    __tbb_pfor(pred_ix, 0, C_num_combos, 
        bool predictions_good = true;
        std::vector<t_param_preds *> level_preds(half_levct - 1, nullptr);
        for (uint64_t levix = 0; levix < half_levct - 1; ++levix) {
            if (combined_predictions[levix][pred_ix]) {
                level_preds[levix] = combined_predictions[levix][pred_ix];
                continue;
            }
            int64_t prev_pred_ix = pred_ix;
            while (!(combined_predictions[levix][prev_pred_ix]) && prev_pred_ix >= 0) --prev_pred_ix;
            if (prev_pred_ix < 0) {
                prev_pred_ix = pred_ix;
                while (!(combined_predictions[levix][prev_pred_ix]) && prev_pred_ix < int64_t(C_num_combos)) ++prev_pred_ix;
                if (prev_pred_ix >= int64_t(C_num_combos)) {
                    predictions_good = false;
                    break;
                }
            }
            level_preds[levix] = combined_predictions[levix][prev_pred_ix];
        }
        if (!predictions_good) {
            LOG4_DEBUG("Predictions at " << pred_ix << " empty.");
            continue;
        }
        double score = std::numeric_limits<double>::max();
        arma::mat this_preds(arma::size(level_preds.front()->p_predictions->front()));
        arma::mat this_labels(arma::size(this_preds)), this_last_knowns(arma::size(this_preds));
        for (uint64_t j = 0; j < EMO_MAX_J; ++j) {
            this_preds.fill(0);
            this_labels.fill(0);
            this_last_knowns.fill(0);
            for (size_t levix = 0; levix < half_levct - 1; ++levix) {
                if (!level_preds[levix]) {
                    LOG4_DEBUG("Level " << levix << " predictions at " << pred_ix << " are missing!");
                    score += BAD_VALIDATION;
                    continue;
                }
                this_preds += level_preds[levix]->p_predictions->at(j);
                this_labels += level_preds[levix]->p_labels->at(j);
                this_last_knowns += level_preds[levix]->p_last_knowns->at(j);
            }
            score += arma::sum(arma::abs(arma::vectorise(arma::sign(arma::sign(this_preds - this_last_knowns) - arma::sign(this_labels - this_last_knowns)))));
        }
        this_preds.clear();
        this_labels.clear();
        this_last_knowns.clear();
//        const std::scoped_lock lk(mx_comb);
#pragma omp critical
        if (score < best_score) {
            LOG4_DEBUG("Found best score " << score << " at combination " << pred_ix);
            best_score = score;
            uint64_t levix = 0;
            for (uint64_t l = 0; l < ensemble_params.size(); l += 2) {
                if (l == half_levct) continue;
                ensemble_params[l] = level_preds[levix]->p_params;
                ++levix;
            }
        }
    }
#pragma omp parallel for
    for (auto &tune_prediction: tune_predictions) {
        for (auto &tune_params: tune_prediction)
            tune_params->clear();
        tune_prediction.clear();
    }
    tune_predictions.clear();
}


void DatasetService::process_dataset_test_tune(
        Dataset_ptr &p_dataset,
        Ensemble_ptr &p_ensemble,
        std::vector<SVRParameters_ptr> &ensemble_params,
        std::vector<std::vector<matrix_ptr>> &features,
        std::vector<std::vector<matrix_ptr>> &labels,
        std::vector<std::vector<bpt::ptime>> &last_row_time,
        const size_t lev_ct,
        const size_t ens_ix)
{
    LOG4_BEGIN();

    bool train_ret = true;
    if (p_ensemble->get_aux_decon_queues().size() > 1) LOG4_ERROR("More than one aux decon queue is not supported!");
    const std::string save_column_name = p_ensemble->get_decon_queue()->get_input_queue_column_name();
    const auto p_decon = p_ensemble->get_decon_queue();
    const auto p_aux_decon = p_ensemble->get_aux_decon_queue(0);
#ifdef CACHED_FEATURE_ITER
    APP.model_service.aux_decon_hint = p_aux_decon->get_data().begin(); // lower_bound(p_aux_decon->get_data(), p_decon->get_data()[std::max<size_t>(0, p_decon->get_data().size() - p_dataset->get_max_lag_count() - p_dataset->get_max_decrement() - EMO_TUNE_VALIDATION_WINDOW - MANIFOLD_TEST_VALIDATION_WINDOW - DATA_LUFTA)]->get_value_time());
#endif
#ifndef NEW_SCALING
    const auto dq_scaling_factors = APP.dq_scaling_factor_service.prepare_decon_queue_scaling_factors(p_dataset, p_decon);
    const auto dq_aux_scaling_factors = APP.dq_scaling_factor_service.prepare_decon_queue_scaling_factors(p_dataset, p_aux_decon);
#endif
    const auto resolution_factor = double(p_dataset->get_input_queue()->get_resolution().total_microseconds()) /
                                   double(p_dataset->get_aux_input_queue(0)->get_resolution().total_microseconds());
    std::vector<bpt::ptime> label_times;
    const size_t half_levct = lev_ct / 2;
    std::vector<arma::mat> level_features(half_levct), level_labels(half_levct), level_last_knowns(half_levct);
    std::vector<double> predicted_values, actual_values, last_knowns;
    std::mutex mx;
    predictions_t tune_predictions(lev_ct);
    std::vector<double> level_lin_pred_values, level_predicted_values, level_actual_values;
    __tbb_spfor(lev_ix, 0, lev_ct, 2,
                if (lev_ix == half_levct) continue;
                const auto half_levix = lev_ix / 2;
                const auto p_model = p_ensemble->get_model(lev_ix);
                auto p_params = ensemble_params[lev_ix];
                train_ret = APP.model_service.get_training_data(
                        level_features[half_levix],
                        level_labels[half_levix],
                        level_last_knowns[half_levix],
                        label_times,
                        { svr::business::EnsembleService::get_start(
                                p_decon->get_data(),
                                p_params->get_svr_decremental_distance() + EMO_TUNE_TEST_SIZE + MANIFOLD_TEST_VALIDATION_WINDOW,
                                0,
                                p_model->get_last_modeled_value_time(),
                                p_dataset->get_input_queue()->get_resolution()),
                                p_decon->get_data().end() - MODEL_TRAIN_OFFSET,
                                p_decon->get_data() },
                        p_aux_decon->get_data(),
                        p_params->get_lag_count(),
                        p_model->get_learning_levels(),
                        p_dataset->get_max_lookback_time_gap(),
                        lev_ix,
                        resolution_factor,
                        p_model->get_last_modeled_value_time(),
                        p_dataset->get_input_queue()->get_resolution());
                APP.dq_scaling_factor_service.scale(p_dataset, p_aux_decon, p_params, p_model->get_learning_levels(), level_features[half_levix], level_labels[half_levix], level_last_knowns[half_levix]);
                const size_t full_validation_sz = p_params->get_svr_decremental_distance() + EMO_TUNE_TEST_SIZE;
                if (!p_params->get_svr_kernel_param())
                PROFILE_EXEC_TIME(OnlineMIMOSVR::tune_kernel_params(
                tune_predictions[p_params->get_decon_level()], p_params, level_features[half_levix].rows(0, full_validation_sz - 1), level_labels[half_levix].rows(0, full_validation_sz - 1),
                    level_last_knowns[half_levix].rows(0, full_validation_sz - 1)), "Tune kernel params for model " << p_params->get_decon_level());
    )

    PROFILE_EXEC_TIME(recombine_params(tune_predictions, ensemble_params, half_levct), "Recombine parameters");

    __tbb_spfor(lev_ix, 0, lev_ct, 2,
                if (lev_ix == half_levct) continue;
                        const auto half_levix = lev_ix / 2;
                        const auto p_model = p_ensemble->get_model(lev_ix);
                        const auto p_params = ensemble_params[lev_ix];
                        const size_t full_validation_sz = p_params->get_svr_decremental_distance() + EMO_TUNE_TEST_SIZE;
                        svr::OnlineMIMOSVR svr_model(
                                p_params,
                                std::make_shared<arma::mat>(level_features[half_levix].rows(0, full_validation_sz - 1)),
                                std::make_shared<arma::mat>(level_labels[half_levix].rows(0, full_validation_sz - 1)),
                                false, svr::matrices_ptr{}, false, svr::MimoType::single, level_labels[half_levix].n_cols);
                        APP.svr_parameters_service.remove(p_params);
                        APP.svr_parameters_service.save(p_params);

                        while (label_times.size() != level_labels[half_levix].n_rows) usleep(10);
                        double level_mae, level_mape, level_lin_mape;
                        std::vector<double> level_lin_pred_values, level_predicted_values, level_actual_values;
                        double scale_label = p_dataset->get_dq_scaling_factor_labels(p_aux_decon->get_input_queue_table_name(),
                                                                                     p_aux_decon->get_input_queue_column_name(), lev_ix);
                        const double dc_offset = lev_ix ? 0 : p_dataset->get_dq_scaling_factor_labels(p_aux_decon->get_input_queue_table_name(),
                                                                                                      p_aux_decon->get_input_queue_column_name(), DC_DQ_SCALING_FACTOR);
                        std::tie(level_mae, level_mape, level_predicted_values, level_actual_values, level_lin_mape, level_lin_pred_values) =
                                OnlineMIMOSVR::future_validate(full_validation_sz, svr_model, level_features[half_levix], level_labels[half_levix],
                                                               level_last_knowns[half_levix], label_times, false, scale_label, dc_offset);

                        std::unique_lock lk(mx);
                        if (predicted_values.size() != level_predicted_values.size()) predicted_values.resize(level_predicted_values.size(), 0.);
                        if (actual_values.size() != level_actual_values.size()) actual_values.resize(level_actual_values.size(), 0.);
                        if (last_knowns.size() != level_lin_pred_values.size()) last_knowns.resize(level_lin_pred_values.size(), 0.);
                        lk.unlock();
                        // Unscale and add
                        for (size_t i = 0; i < std::min<size_t>(level_predicted_values.size(), level_actual_values.size()); ++i) {
                            predicted_values[i] += level_predicted_values[i];
                            actual_values[i] += level_actual_values[i];
                            last_knowns[i] += level_lin_pred_values[i];
                        }
    )

    double mae = 0, mae_lk = 0;
    size_t pos_mae = 0, pos_direct = 0;
    const auto compared_values_ct = std::min<size_t>(actual_values.size(), predicted_values.size());
    for (size_t i = 0; i < compared_values_ct; ++i) {
        const double cur_mae = std::abs(predicted_values[i] - actual_values[i]);
        const double cur_mae_lk = std::abs(last_knowns[i] - actual_values[i]);
        const double cur_alpha_pct = 100. * (cur_mae_lk / cur_mae - 1.);
        if (cur_mae < cur_mae_lk) {
            LOG4_DEBUG("Positive alpha " << cur_alpha_pct << " pct., at " << i);
            ++pos_mae;
        }
        if (std::signbit(predicted_values[i] - last_knowns[i]) == std::signbit(actual_values[i] - last_knowns[i])) {
            LOG4_DEBUG("Direction correct at " << i);
            ++pos_direct;
        }
        mae += cur_mae;
        mae_lk += cur_mae_lk;
        const auto cml_alpha_pct = 100. * (mae_lk / mae - 1.);
        if (mae < mae_lk) LOG4_DEBUG("Positive cumulative alpha at " << i << ", " << cml_alpha_pct << " pct.");
        const auto i_ct = double(i + 1);
        LOG4_DEBUG(
                "Position " << i <<
                            ", price time " << label_times[label_times.size() - compared_values_ct + i] <<
                            ", actual price " << actual_values[i] <<
                            ", predicted price " << predicted_values[i] <<
                            ", last known " << last_knowns[i] <<
                            ", total MAE " << mae / i_ct <<
                            ", total MAE last known " << mae_lk / i_ct <<
                            ", positive directions " << 100. * double(pos_direct) / i_ct <<
                            " pct., positive errors " << 100. * double(pos_mae) / i_ct <<
                            " pct., current MAE " << cur_mae <<
                            ", current MAE last known " << cur_mae_lk <<
                            ", predicted movement " << predicted_values[i] - last_knowns[i] <<
                            ", actual movement " << actual_values[i] - last_knowns[i] <<
                            ", current alpha " << cur_alpha_pct << " pct."
                                                                   ", cumulative alpha " << cml_alpha_pct << " pct.");
        if (i < common::C_forecast_focus)
            APP.request_service.save(
                    std::make_shared<MultivalResponse>(0, 0, label_times[label_times.size() - compared_values_ct + i], save_column_name, predicted_values[i]));
    }
    mae /= double(compared_values_ct);
    mae_lk /= double(compared_values_ct);
#ifdef EMO_DIFF
    const arma::mat recon_actuals = common::operator+(actual_values, p_last_knowns);
    const double labels_meanabs = common::meanabs(actual_values);
#else
    const double labels_meanabs = common::meanabs(actual_values);
#endif
    const double mape = 100. * mae / labels_meanabs;
    const double mape_lk = 100. * mae_lk / labels_meanabs;
    const double alpha_pct = 100. * (mape_lk / mape - 1.);
    LOG4_INFO(
            "Total MAE of " << compared_values_ct << " compared values is " << mae << ", MAPE is " << mape << " pct., last known MAE " << mae_lk <<
                            ", last known MAPE " << mape_lk << ", alpha " << alpha_pct << " pct., positive direction "
                            << 100. * double(pos_direct) / double(compared_values_ct) <<
                            " pct., positive error " << 100. * double(pos_mae) / double(compared_values_ct) << " pct.");

    exit(0);
}

}
}
